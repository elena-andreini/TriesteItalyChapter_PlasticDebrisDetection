{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9438808,"sourceType":"datasetVersion","datasetId":5735509},{"sourceId":11885707,"sourceType":"datasetVersion","datasetId":7401788}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import multiprocessing as mp\n# mp.set_start_method('spawn')  # Set before any other imports or operations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:00.641899Z","iopub.execute_input":"2025-05-25T19:00:00.642060Z","iopub.status.idle":"2025-05-25T19:00:00.646326Z","shell.execute_reply.started":"2025-05-25T19:00:00.642045Z","shell.execute_reply":"2025-05-25T19:00:00.645782Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#bands 4.6.8.11","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:00.648030Z","iopub.execute_input":"2025-05-25T19:00:00.648346Z","iopub.status.idle":"2025-05-25T19:00:00.670078Z","shell.execute_reply.started":"2025-05-25T19:00:00.648325Z","shell.execute_reply":"2025-05-25T19:00:00.669372Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"! ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:00.670894Z","iopub.execute_input":"2025-05-25T19:00:00.671078Z","iopub.status.idle":"2025-05-25T19:00:00.803763Z","shell.execute_reply.started":"2025-05-25T19:00:00.671063Z","shell.execute_reply":"2025-05-25T19:00:00.802922Z"}},"outputs":[{"name":"stdout","text":"best_model.pth\nglobal_stats.npz\nlitter_rows_df_invalid_info.csv\nlitter_rows_val_df_invalid_info.csv\nmarida_df_invalid_info.csv\nmarida_test_df_invalid_info.csv\nmarida_val_df_invalid_info.csv\nmodel_30_epochs_ratio_1_20_bs16_iou_081.pth\nmodel_30_epochs_ratio_1_40_bs16_iou_0819.pth\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#%%capture\n! pip install rasterio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:00.804688Z","iopub.execute_input":"2025-05-25T19:00:00.804907Z","iopub.status.idle":"2025-05-25T19:00:05.980900Z","shell.execute_reply.started":"2025-05-25T19:00:00.804884Z","shell.execute_reply":"2025-05-25T19:00:05.980216Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\nDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.4.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport sys\nimport shutil\nimport re\nfrom PIL import Image\nimport rasterio\nimport matplotlib.pyplot as plt\nimport dask.array as da\nfrom scipy.ndimage import binary_dilation\nfrom skimage.morphology import disk  # For circular structuring elements\nimport torch\nfrom torchvision import transforms\nimport torchvision.transforms.functional as vF\nimport torch.nn.functional as F\nimport gdown\nfrom tqdm import tqdm\nimport random\n\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, jaccard_score, hamming_loss, label_ranking_loss, coverage_error, classification_report\nimport sklearn.metrics as metr\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:05.981810Z","iopub.execute_input":"2025-05-25T19:00:05.982062Z","iopub.status.idle":"2025-05-25T19:00:16.928767Z","shell.execute_reply.started":"2025-05-25T19:00:05.982025Z","shell.execute_reply":"2025-05-25T19:00:16.928000Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", None)  # Show full column values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:16.929606Z","iopub.execute_input":"2025-05-25T19:00:16.930129Z","iopub.status.idle":"2025-05-25T19:00:16.934213Z","shell.execute_reply.started":"2025-05-25T19:00:16.930103Z","shell.execute_reply":"2025-05-25T19:00:16.933640Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nfrom torch.utils.data import DataLoader, Dataset\n\ndef set_seed(seed):\n    \"\"\"\n    Set random seeds for NumPy, PyTorch (CPU and GPU), and Python's random module.\n    \n    Args:\n        seed (int): Seed value for RNGs\n    \"\"\"\n    # Python random\n    random.seed(seed)\n    \n    # NumPy\n    np.random.seed(seed)\n    \n    # PyTorch CPU\n    torch.manual_seed(seed)\n    \n    # PyTorch GPU (CUDA)\n    torch.cuda.manual_seed(seed)  # Current GPU\n    torch.cuda.manual_seed_all(seed)  # All GPUs\n    \n    # Ensure deterministic behavior\n    #torch.use_deterministic_algorithms(True)\n    #torch.backends.cudnn.deterministic = True\n    #torch.backends.cudnn.benchmark = False\n\ndef worker_init_fn(worker_id):\n    \"\"\"\n    Initialize random seed for DataLoader workers.\n    Ensures each worker has a unique but reproducible RNG state.\n    \n    Args:\n        worker_id (int): Worker ID\n    \"\"\"\n    max_seed = 2**32 - 1  # NumPy seed limit\n    worker_seed = (torch.initial_seed() + worker_id) % max_seed\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:16.936236Z","iopub.execute_input":"2025-05-25T19:00:16.936780Z","iopub.status.idle":"2025-05-25T19:00:16.952973Z","shell.execute_reply.started":"2025-05-25T19:00:16.936762Z","shell.execute_reply":"2025-05-25T19:00:16.952440Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_LR_dataframe(splits_path, mode='train'):\n    split_images_files = {'train' : 'train_X.txt', 'val' : 'val_X.txt', 'test' : 'test_X.txt'}\n    split_masks_files = {'train' : 'train_masks.txt', 'val' : 'val_masks.txt', 'test' : 'test_masks.txt'}  \n    with open(os.path.join(splits_path, split_images_files[mode]), \"r\") as file:\n        images = file.readlines()  # Reads all lines into a list\n        images = [image.strip() for image in images]  # Remove any trailing newline characters\n    with open(os.path.join(splits_path, split_masks_files[mode]), \"r\") as file:\n        masks = file.readlines()  # Reads all lines into a list\n        masks = [mask.strip() for mask in masks]  # Remove any trailing newline characters\n    df = pd.DataFrame({'image' : images, 'mask' : masks})\n    return df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:16.953784Z","iopub.execute_input":"2025-05-25T19:00:16.954035Z","iopub.status.idle":"2025-05-25T19:00:16.972573Z","shell.execute_reply.started":"2025-05-25T19:00:16.954011Z","shell.execute_reply":"2025-05-25T19:00:16.972042Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# from Sagar and Navodita's code\ndef compute_fdi_from_tiff(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        # Assuming band order follows your stacked TIFF (B1–B12, skipping B10 if needed)\n        # Band indices are 1-based in rasterio\n        R665 = src.read(4)    # B4\n        R859 = src.read(9)    # B8A\n        R1610 = src.read(10)  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        return FDI\n\ndef cvt_to_fdi(images):\n    fdi_images = []\n    batch = images.copy()\n    if len(images.shape) == 3 : \n        batch = batch[None, :]\n    for i in range(batch.shape[0]):\n        im = batch[i]\n        R665 = im[3]   # B4\n        R859 = im[8]   # B8A\n        R1610 = im[0]  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        fdi_images.append(FDI)\n    return np.array(fdi_images)\n    \ndef compute_ndwi(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        Rgreen = src.read(3).astype(np.float32)  # Band 3 (Green)\n        Rnir = src.read(8).astype(np.float32)    # Band 8 (NIR)\n        ndwi = (Rgreen - Rnir) / (Rgreen + Rnir + 1e-6)  # avoid divide-by-zero\n    return ndwi\ndef plot_fdi(fdi_array, ndwi, img_path, mask_path):\n    with rasterio.open(img_path) as src:\n        rgb = src.read([4, 3, 2])\n        rgb = np.transpose(rgb, (1, 2, 0))\n    # Normalization\n    rgb = rgb.astype(np.float32)\n    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n    with rasterio.open(mask_path) as src:\n        mask = src.read(1)\n    # Create binary mask\n    mask_binary = mask > 0\n    # Plot side-by-side\n    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n    axs[0].imshow(rgb)\n    axs[0].set_title(\"RGB Patch\")\n    axs[1].imshow(mask_binary)  #, cmap='gray')\n    axs[1].set_title(\"Binary Mask (._cl.tif)\")\n    axs[2].imshow(fdi_array)\n    axs[2].set_title(\"FDI\")\n    axs[3].imshow(ndwi)\n    axs[3].set_title(\"NDWI\")\n    for ax in axs:\n        ax.axis('off')\n\n    # with rasterio.open(patch_path) as patch_src:\n    #     rgb = patch_src.read([4, 3, 2])  # Use bands B4, B3, B2 for RGB\n    #     rgb = np.transpose(rgb, (1, 2, 0))\n    #     rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n    import matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# List of image and mask file paths (replace with your file paths)\nimage_mask_pairs = [\n    ('path_to_image1.jpg', 'path_to_mask1.png'),\n    ('path_to_image2.jpg', 'path_to_mask2.png'),\n    # Add more pairs as needed\n]\n\n\ndef cvt_RGB(images):\n    rgb_images = []\n    for i in range(images.shape[0]):\n        rgb = images[i][[4-1, 3-1, 2-1]] # Use bands B4, B3, B2 for RGB\n        rgb = np.transpose(rgb, (1, 2, 0))\n        rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n        rgb_images.append(rgb)\n    return np.array(rgb_images)\n\ndef display(images, masks):\n    # Determine the number of pairs\n    num_pairs = images.shape[0]\n\n    # Calculate layout: use 2 columns per pair (image + mask), adjust rows dynamically\n    cols = 2  # One column for image, one for mask\n    rows = num_pairs  # One row per pair\n\n    # Create a figure with subplots\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n\n    # Handle case of single pair (axes is not a 2D array)\n    if num_pairs == 1:\n        axes = np.array([axes]).reshape(1, -1)\n\n    # Iterate through each pair and display image and mask\n    for idx, (image, mask) in enumerate(zip(images, masks)):\n\n        # Display the original image\n        axes[idx, 0].imshow(image)\n        axes[idx, 0].set_title(f'Image {idx + 1}')\n        axes[idx, 0].axis('off')  # Hide axes\n    \n        # Display the segmentation mask\n        axes[idx, 1].imshow(mask, cmap='gray')  # Adjust cmap if needed\n        axes[idx, 1].set_title(f'Mask {idx + 1}')\n        axes[idx, 1].axis('off')  # Hide axes\n\n    # Adjust layout to prevent overlap\n    plt.tight_layout()\n    \n    # Show the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:16.973235Z","iopub.execute_input":"2025-05-25T19:00:16.973437Z","iopub.status.idle":"2025-05-25T19:00:16.987564Z","shell.execute_reply.started":"2025-05-25T19:00:16.973423Z","shell.execute_reply":"2025-05-25T19:00:16.986712Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\ndef extract_date_tile(filename):\n    \"\"\"Extract date and tile from filename using regex.\"\"\"\n    pattern = r'^(\\d{1,2}-\\d{1,2}-\\d{2})_([A-Z0-9]+)_\\d+$'\n    match = re.match(pattern, filename)\n    if not match:\n        raise ValueError(f\"Invalid filename format: {filename}\")\n    return match.groups()  # Returns tuple (date, tile)\n\ndef create_marida_df(data_path, mode='train'):\n    \"\"\"Create DataFrame from MARIDA dataset files.\"\"\"\n    # Determine split file based on mode\n    split_files = {'train': 'train_X.txt', 'val': 'val_X.txt', 'test': 'test_X.txt'}\n    items_list_path = os.path.join(data_path, 'splits', split_files[mode])\n\n    # Read items list\n    with open(items_list_path, 'r') as file:\n        items = [item.strip() for item in file]\n\n    # Base path for patches\n    items_path = os.path.join(data_path, 'patches')\n\n    # Prepare data lists\n    data = {\n        'image': [],\n        'mask': [],\n        'confidence': [],\n        'date': [],\n        'tile': []\n    }\n\n    # Process each item\n    for item in items:\n        tile = \"_\".join(item.split(\"_\")[:-1])\n        tile_path = os.path.join(items_path, f\"S2_{tile}\")\n\n        # Define file paths\n        base_name = f'S2_{item}'\n        paths = {\n            'image': os.path.join(tile_path, f'{base_name}.tif'),\n            'mask': os.path.join(tile_path, f'{base_name}_cl.tif'),\n            'confidence': os.path.join(tile_path, f'{base_name}_conf.tif')\n        }\n\n        # Check if all files exist\n        if all(os.path.exists(p) for p in paths.values()):\n            data['image'].append(paths['image'])\n            data['mask'].append(paths['mask'])\n            data['confidence'].append(paths['confidence'])\n            date, tile = extract_date_tile(item)\n            data['date'].append(date)\n            data['tile'].append(tile)\n\n    return pd.DataFrame(data)\n\n# MARIDA labels dictionary\nMARIDA_LABELS = {\n    i: label for i, label in enumerate([\n        'Marine Debris', 'Dense Sargassum', 'Sparse Sargassum', 'Natural Organic Material',\n        'Ship', 'Clouds', 'Marine Water', 'Sediment-Laden Water', 'Foam', 'Turbid Water',\n        'Shallow Water', 'Waves', 'Cloud Shadows', 'Wakes', 'Mixed Water'\n    ], 1)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:16.988380Z","iopub.execute_input":"2025-05-25T19:00:16.988622Z","iopub.status.idle":"2025-05-25T19:00:17.012058Z","shell.execute_reply.started":"2025-05-25T19:00:16.988607Z","shell.execute_reply":"2025-05-25T19:00:17.011293Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import rasterio\nimport numpy as np\n\ndef compute_invalid_pixels(image_paths, mask_paths):\n    \"\"\"\n    Compute per-band statistics for Sentinel-2 L1C ACOLITE-processed images using segmentation masks.\n    Creates a mask to exclude invalid pixels (NaNs, negative values, specified no-data value).\n    \n    Parameters:\n    - image_paths: List of paths to image files (e.g., GeoTIFF with 11 bands).\n    - mask_paths: List of paths to segmentation mask files (single-band, integer class labels).\n    - class_labels: List of mask class labels to include (e.g., [1, 2] for vegetation and water).\n                   If None, include all non-zero labels (excluding background).\n    - invalid_value: Optional value to treat as invalid in images (e.g., -9999).\n    \n    Returns:\n    - mean_per_band: List of per-band means for each image.\n    - std_per_band: List of per-band standard deviations for each image.\n    \"\"\"\n    mean_per_band = []  # Initialize as list\n    std_per_band = []   # Initialize as list\n    positive_pixels = []\n    tot_pixels = [];\n    images_with_invalid_pixels = []\n    black_list = []\n    accumulator = None\n    no_data_pixels = []\n    neg_pixels = []\n    nan_pixels = []\n    gt1_pixels = []\n    imgs_with_invalid = []\n    positive_pixels = []\n    min_vals = []\n    max_vals = []\n    for img_path, mask_path in zip(image_paths, mask_paths):\n        # Load image and mask\n        with rasterio.open(img_path) as src_img, rasterio.open(mask_path) as src_mask:\n            image = src_img.read()  # Shape: (bands, height, width)\n            mask = src_mask.read(1)  # Shape: (height, width)\n            \n            # Convert image to float for NaN handling\n            image = image.astype(float)\n\n            nan_mask = np.isnan(image)\n            neg_mask = (image < 0)\n            too_big_mask = (image > 1)\n            no_data_mask = (image == src_img.nodata)\n            nan_pixels.append(np.sum(nan_mask))\n            neg_pixels.append(np.sum(neg_mask))\n            gt1_pixels.append(np.sum(too_big_mask))\n            no_data_pixels.append(np.sum(no_data_mask))\n            imgs_with_invalid.append(img_path)\n            positive_pixels.append(np.sum(mask > 0))\n            min_vals.append(np.min(image))\n            max_vals.append(np.max(image))\n    df = pd.DataFrame({'image' : imgs_with_invalid, 'no data pixels' : no_data_pixels, 'negative pixels' : neg_pixels,\n                      'nan pixels' : nan_pixels, 'high value pixels' :  gt1_pixels, 'debris pixels' : positive_pixels,\n                      'min values' : min_vals, 'max values' : max_vals})\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.012863Z","iopub.execute_input":"2025-05-25T19:00:17.013109Z","iopub.status.idle":"2025-05-25T19:00:17.031853Z","shell.execute_reply.started":"2025-05-25T19:00:17.013095Z","shell.execute_reply":"2025-05-25T19:00:17.031302Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#Setting batch size\nbatch_size = 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.032506Z","iopub.execute_input":"2025-05-25T19:00:17.032726Z","iopub.status.idle":"2025-05-25T19:00:17.111924Z","shell.execute_reply.started":"2025-05-25T19:00:17.032709Z","shell.execute_reply":"2025-05-25T19:00:17.111295Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def compute_stats(image_files, discard_negatives = False, discard_gt_1 = False):\n    bands_std = []\n    bands_mean = []\n    valid_pixels = []\n\n    for band_idx in range(11):\n        arrays = [da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto')\n                  for f in image_files]\n        stack = da.stack(arrays)\n        #valid = (stack != rasterio.open(image_files[0]).nodata) & (stack >= 0)\n        if discard_negatives and  discard_gt_1: \n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) & \n                              (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1) \n                              for f in image_files])\n        elif discard_gt_1 :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1)  \n                              for f in image_files])\n        elif discard_negatives:\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) \n                  for f in image_files])\n        else :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  for f in image_files])\n                         \n        # Compute number of valid pixels\n        valid_count = da.sum(valid).compute()\n        valid_pixels.append(valid_count)\n        mean = da.nanmean(stack[valid]).compute()\n        std = da.nanstd(stack[valid]).compute()\n        bands_mean.append(mean)\n        bands_std.append(std)\n        print(f\"Band {band_idx} - Mean: {mean}, Std: {std}\")\n    return {'mean' : np.array(bands_mean), 'std': np.array(bands_std),'valid pixels' : np.array(valid_pixels) }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.112710Z","iopub.execute_input":"2025-05-25T19:00:17.113000Z","iopub.status.idle":"2025-05-25T19:00:17.127808Z","shell.execute_reply.started":"2025-05-25T19:00:17.112984Z","shell.execute_reply":"2025-05-25T19:00:17.127293Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def computing_labeled_pixels_stats(mask_paths):\n    arrays = [da.from_array(rasterio.open(f).read(1), chunks='auto')\n                  for f in mask_paths]\n    stack = da.stack(arrays)\n    valid = stack > 0\n    labeled_count = da.sum(valid).compute()\n    return labeled_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.128491Z","iopub.execute_input":"2025-05-25T19:00:17.128736Z","iopub.status.idle":"2025-05-25T19:00:17.144499Z","shell.execute_reply.started":"2025-05-25T19:00:17.128719Z","shell.execute_reply":"2025-05-25T19:00:17.143399Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def compute_invalid_mask(path):\n    with rasterio.open(path) as src:\n        image = src.read()\n        \n        invalid_mask = image == src.nodata\n        invalid_mask |= np.isnan(image)\n        invalid_mask |= image < 0\n        invalid_mask |= image > 1\n        invalid_mask = np.any(invalid_mask, axis=0)\n        return invalid_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.145450Z","iopub.execute_input":"2025-05-25T19:00:17.145711Z","iopub.status.idle":"2025-05-25T19:00:17.161304Z","shell.execute_reply.started":"2025-05-25T19:00:17.145690Z","shell.execute_reply":"2025-05-25T19:00:17.160784Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def get_invalid_mask(image, no_data):\n    invalid_mask = image == no_data\n    invalid_mask |= np.isnan(image)\n    invalid_mask |= image < -1.5\n    invalid_mask |= image > 1.5\n    #invalid_mask = np.any(invalid_mask, axis=0)\n    return invalid_mask  #torch.fromnumpy(invalid_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.162080Z","iopub.execute_input":"2025-05-25T19:00:17.162359Z","iopub.status.idle":"2025-05-25T19:00:17.175981Z","shell.execute_reply.started":"2025-05-25T19:00:17.162343Z","shell.execute_reply":"2025-05-25T19:00:17.174779Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def select_bg_pixels(image, debris_mask, r1=5, r2=20, target_ratio=5):\n    H, W = debris_mask.shape\n    \n    #target_ratio = 5  # Debris-to-background ratio (1:5)\n\n    # Create structuring elements (circular or square)\n    se_r1 = disk(r1) if r1 > 0 else np.ones((1, 1))  # Inner dilation kernel\n    se_r2 = disk(r2)                         # Outer dilation kernel\n    #print('before binary dilation')\n    # Dilate debris mask with r1 and r2\n    dilated_r1 = binary_dilation(debris_mask, structure=se_r1)\n    dilated_r2 = binary_dilation(debris_mask, structure=se_r2)\n    #print('before anular mask')\n    # Compute annular region: pixels in dilated_r2 but not in dilated_r1\n    annular_mask = dilated_r2 & ~dilated_r1\n\n    # Sample background pixels from annular region\n    valid_background_coords = np.where(annular_mask)\n    num_debris = np.sum(debris_mask)\n    num_background = min(len(valid_background_coords[0]), num_debris * target_ratio)\n    if num_background > 0:\n        sample_idx = np.random.choice(len(valid_background_coords[0]), size=num_background, replace=False)\n        background_coords = [(valid_background_coords[0][i], valid_background_coords[1][i]) for i in sample_idx]\n    else:\n        print(\"Warning: No valid background pixels in annular region. Increase r2 or check mask.\")\n\n    # Create background mask (optional, for visualization or training)\n    background_mask = np.zeros_like(debris_mask)\n    for x, y in background_coords:\n        background_mask[x, y] = 1\n    return background_mask\n\n# Optional: Filter by features (e.g., RGB values for water-like pixels)\n# Example: If image is RGB, filter pixels with low green channel (common for water)\n# image = ...  # Your RGB or multispectral image\n# valid_background = [coord for coord in background_coords if image[coord[0], coord[1], 1] < threshold]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.176932Z","iopub.execute_input":"2025-05-25T19:00:17.177183Z","iopub.status.idle":"2025-05-25T19:00:17.195505Z","shell.execute_reply.started":"2025-05-25T19:00:17.177162Z","shell.execute_reply":"2025-05-25T19:00:17.194649Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def batch_process_marida_masks(masks, dataset_ids, device='cpu'):\n    \"\"\"\n    Process masks for dataset_id == 0 (MARIDA) at the batch level.\n    - Set classes [1, 2, 3, 4, 9] to 2 (debris).\n    - Set class 0 to 0 (unlabeled), other classes to 1 (non-debris).\n    \n    Args:\n        masks: Tensor [batch_size, H, W] (integer-valued masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        marida_masks: Tensor [batch_size, H, W] with values 0, 1, 2\n    \"\"\"\n    batch_size, H, W = masks.shape\n    marida_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks with dataset_id == 0\n    marida_mask = (dataset_ids == 0)  # [batch_size], boolean\n    if not marida_mask.any():\n        return marida_masks\n    \n    # Select masks for dataset_id == 0\n    selected_masks = masks[marida_mask]  # [num_marida, H, W]\n    \n    # Set classes [1, 2, 3, 4, 9] to 2\n    debris_classes = torch.tensor([1, 2, 3, 4, 9], device=device)\n    is_debris = torch.isin(selected_masks, debris_classes)  # [num_marida, H, W]\n    marida_masks[marida_mask] = torch.where(\n        is_debris,\n        torch.tensor(2, dtype=torch.int64, device=device),\n        selected_masks  # Temporarily keep original values\n    )\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    # Set non-zero, non-debris pixels to 1\n    marida_masks[marida_mask] = torch.where(\n        (marida_masks[marida_mask] != 0) & (marida_masks[marida_mask] != 2),\n        torch.tensor(1, dtype=torch.int64, device=device),\n        marida_masks[marida_mask]\n    )\n    # print('only 3 values : ')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    marida_masks[marida_mask] = marida_masks[marida_mask] - 1\n    #print('after subtr')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    return marida_masks\n\n\n\n# # Custom collate function\n# def custom_collate_fn(batch):\n#     images, masks, dataset_ids = zip(*batch)\n#     images = torch.stack(images)\n#     masks = torch.stack(masks)\n#     dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)\n    \n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n#     final_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n#                                          target_ratio=5, threshold=0.5, device=device)\n    \n#     return images, masks, final_masks, dataset_ids\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.196167Z","iopub.execute_input":"2025-05-25T19:00:17.196452Z","iopub.status.idle":"2025-05-25T19:00:17.213887Z","shell.execute_reply.started":"2025-05-25T19:00:17.196430Z","shell.execute_reply":"2025-05-25T19:00:17.213107Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\ndef torch_dilate(mask, kernel_size, device='cpu'):\n    \"\"\"Apply dilation to a batch of masks using PyTorch convolution.\"\"\"\n    kernel = torch.ones(1, 1, kernel_size, kernel_size, device=device, dtype=torch.float32)\n    mask = mask.float().unsqueeze(1)  # [batch_size, 1, H, W]\n    dilated = torch.nn.functional.conv2d(mask, kernel, padding=kernel_size // 2) > 0\n    return dilated.squeeze(1).bool()  # [batch_size, H, W]\n\ndef batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, target_ratio=5, threshold=None, device='cpu'):\n    \"\"\"\n    Compute annular background masks for a batch of masks, only for dataset_id == 1.\n    - Set debris pixels (masks == 1) to 2 in bg_masks.\n    - Set randomly sampled annular pixels to 1 in bg_masks.\n    \n    Args:\n        images: Tensor [batch_size, C, H, W] \n        masks: Tensor [batch_size, H, W] (binary debris masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        r1, r2: Radii for inner and outer dilation\n        target_ratio: Debris-to-background pixel ratio\n        threshold: Optional threshold for filtering (e.g., green channel)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        bg_masks: Tensor [batch_size, H, W] with values 0 (default), 1 (background), 2 (debris)\n    \"\"\"\n\n    batch_size, H, W = masks.shape\n    # Initialize bg_masks with zeros (int64 to support values 0, 1, 2)\n    bg_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks to process (dataset_id == 1)\n    valid_mask = (dataset_ids == 1)  # [batch_size], boolean{\n    #print(f'LR indices {valid_mask}')\n    if not valid_mask.any():\n        return bg_masks  # Return zeros if no masks need processing\n    \n    # Select masks for dataset_id == 1\n    selected_masks = masks[valid_mask]  # [num_valid, H, W]\n    # for idx in range(selected_masks.shape[0]):\n    #     print(f'num debris pixels : {torch.sum(selected_masks[idx])}')\n    # Set debris pixels to 2 for selected masks\n    bg_masks[valid_mask] = selected_masks * 2  # Where selected_masks == 1, set bg_masks to 2\n    \n    # Perform dilation on selected masks\n    dilated_r1 = torch_dilate(selected_masks, 2 * r1 + 1, device=device)  # [num_valid, H, W]\n    dilated_r2 = torch_dilate(selected_masks, 2 * r2 + 1, device=device)  # [num_valid, H, W]\n    annular_masks = dilated_r2 & ~dilated_r1  # [num_valid, H, W]\n    \n    # Sample background pixels for each selected mask\n    for idx in range(annular_masks.shape[0]):\n        valid_coords = torch.where(annular_masks[idx])  # Tuple of (row, col) indices\n        #print(f'unique values in mask {idx} : {torch.unique(selected_masks[idx])}')\n        num_debris = torch.sum(selected_masks[idx] > 0).item()\n        #print(f'num debris for index {idx} : {num_debris}')\n        num_background = min(len(valid_coords[0]), int(num_debris * target_ratio))\n        \n        if num_background > 0:\n            # Randomly sample indices and set to 1\n            sample_indices = torch.randperm(len(valid_coords[0]), device=device)[:num_background]\n            bg_masks[valid_mask.nonzero(as_tuple=True)[0][idx], \n                     valid_coords[0][sample_indices], \n                     valid_coords[1][sample_indices]] = 1\n        else :\n            print(f'no background selected for index {idx}. Num debrid : {num_debris} Num background : {num_background}')\n            print(f'valid coords {len(valid_coords)}')\n            print(f'unique valus : {torch.unique(selected_masks[idx])}')\n    \n    # # Optional: Filter by image features (e.g., green channel) for dataset_id == 1\n    # if threshold is not None and images is not None:\n    #     valid_pixels = images[valid_mask, 1, :, :] < threshold  # Green channel\n    #     # Only apply filtering to background pixels (value 1), preserve debris pixels (value 2)\n    #     bg_masks[valid_mask] = torch.where(\n    #         bg_masks[valid_mask] == 1,\n    #         bg_masks[valid_mask] & valid_pixels,\n    #         bg_masks[valid_mask]\n    #     )\n    bg_masks[valid_mask] = bg_masks[valid_mask] - 1\n    return bg_masks\n\n# Custom collate function\ndef custom_collate_fn(batch):\n    # print(f'custom collate function batch {len(batch)}')\n    # print(f'custom collate function batch type {type(batch)}')\n    # print(f'custom collate function batch[1] type {type(batch[1])}')\n    # print(f'custom collate function batch[1] len  {len(batch[1])}')\n    images, masks, dataset_ids = zip(*batch)\n    images = torch.stack(images)  # [batch_size, C, H, W]\n    masks = torch.stack(masks)    # [batch_size, H, W]\n    dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)  # [batch_size]\n    \n    # Move to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n    # Compute background masks\n    lr_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n                                      target_ratio=LR_ratio, device=device)\n    marida_masks = batch_process_marida_masks(masks, dataset_ids, device=device)\n    masks = lr_masks + marida_masks\n    \n    return images, masks, dataset_ids\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.214543Z","iopub.execute_input":"2025-05-25T19:00:17.214717Z","iopub.status.idle":"2025-05-25T19:00:17.229008Z","shell.execute_reply.started":"2025-05-25T19:00:17.214702Z","shell.execute_reply":"2025-05-25T19:00:17.228379Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Seeding for reproducibility\nseed = 42\nset_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.229731Z","iopub.execute_input":"2025-05-25T19:00:17.230514Z","iopub.status.idle":"2025-05-25T19:00:17.252382Z","shell.execute_reply.started":"2025-05-25T19:00:17.230489Z","shell.execute_reply":"2025-05-25T19:00:17.251655Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# %%capture\n# # Download some pre-computed data \n\n#file_id = \"10bMAQaV2-EXCu52ON-6m0qh7u7__v-hH\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_df_invalid_info.csv', quiet=False)\n#file_id = '19VzQze4sBt76ylEcishVQNpGIFYSkseT'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_val_df_invalid_info.csv', quiet=False)\n#file_id = '1CvUC8FAqj1aUV8fwrTljU3mC-geWz0it'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_test_df_invalid_info.csv', quiet=False)\n#file_id = \"1YTJmy8X-xIo8dV7Qpq4h7wOi7kUAW4sw\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_df_invalid_info.csv', quiet=False)\n#file_id = '1CzvC9VLbzqyh9LbhyxWhtIHaz7o1hmak'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_val_df_invalid_info.csv', quiet=False)\n#file_id = '1wrD41CDQud69AMOyHigw0-DR85Id4zDM'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/global_stats.npz', quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.253007Z","iopub.execute_input":"2025-05-25T19:00:17.253227Z","iopub.status.idle":"2025-05-25T19:00:17.256792Z","shell.execute_reply.started":"2025-05-25T19:00:17.253209Z","shell.execute_reply":"2025-05-25T19:00:17.256203Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # check that the \n# ! ls /kaggle/input/litter-windrows-patches\n# # add the lr dataset to path to import code to prepare the dataset\n# sys.path.append('/kaggle/input/litter-windrows-patches')\n# # import functions to prepare dataset\n# from prepare_dataset import  get_image_and_mask_paths, split_and_save_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.260506Z","iopub.execute_input":"2025-05-25T19:00:17.260899Z","iopub.status.idle":"2025-05-25T19:00:17.274302Z","shell.execute_reply.started":"2025-05-25T19:00:17.260878Z","shell.execute_reply":"2025-05-25T19:00:17.273591Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"#! git clone https://github.com/sheikhazhanmohammed/SADMA.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.275013Z","iopub.execute_input":"2025-05-25T19:00:17.275274Z","iopub.status.idle":"2025-05-25T19:00:17.288677Z","shell.execute_reply.started":"2025-05-25T19:00:17.275232Z","shell.execute_reply":"2025-05-25T19:00:17.288137Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#sys.path.append('/kaggle/working/SADMA')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.289311Z","iopub.execute_input":"2025-05-25T19:00:17.289548Z","iopub.status.idle":"2025-05-25T19:00:17.302802Z","shell.execute_reply.started":"2025-05-25T19:00:17.289529Z","shell.execute_reply":"2025-05-25T19:00:17.302222Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# # define a variable for the lr dataset\n# LW_path = '/kaggle/input/litter-windrows-patches'\n# lr_images, lr_masks = get_image_and_mask_paths(LW_path)\n# ! mkdir ./LR_splits\n# split_and_save_data(lr_images, lr_masks, './LR_splits' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.303622Z","iopub.execute_input":"2025-05-25T19:00:17.304240Z","iopub.status.idle":"2025-05-25T19:00:17.316593Z","shell.execute_reply.started":"2025-05-25T19:00:17.304219Z","shell.execute_reply":"2025-05-25T19:00:17.315994Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# ! ls ./LR_splits/splits\n# LR_splits_path = '/kaggle/working/LR_splits/splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.317216Z","iopub.execute_input":"2025-05-25T19:00:17.317865Z","iopub.status.idle":"2025-05-25T19:00:17.330001Z","shell.execute_reply.started":"2025-05-25T19:00:17.317844Z","shell.execute_reply":"2025-05-25T19:00:17.329445Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# from IPython.display import display\n\n# with open(LR_splits_path+'/train_X.txt', \"r\") as file:\n#     display(file.read())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.330677Z","iopub.execute_input":"2025-05-25T19:00:17.330989Z","iopub.status.idle":"2025-05-25T19:00:17.343929Z","shell.execute_reply.started":"2025-05-25T19:00:17.330964Z","shell.execute_reply":"2025-05-25T19:00:17.343376Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"! ls /kaggle/input/marida-marine-debrish-dataset\nMARIDA_path = '/kaggle/input/marida-marine-debrish-dataset'\n! ls /kaggle/input/litter-windrows-patches\nLR_splits_path = '/kaggle/input/litter-windrows-patches/binary_splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.344588Z","iopub.execute_input":"2025-05-25T19:00:17.344791Z","iopub.status.idle":"2025-05-25T19:00:17.626958Z","shell.execute_reply.started":"2025-05-25T19:00:17.344770Z","shell.execute_reply":"2025-05-25T19:00:17.626298Z"}},"outputs":[{"name":"stdout","text":"labels_mapping.txt  patches  shapefiles  splits\nannotation     multiclass_splits  prepare_dataset.ipynb\nbinary_splits  patches\t\t  README.md\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# MARIDA dataframe\nmarida_df = create_marida_df(MARIDA_path)\n#marida_df_invalid = compute_invalid_pixels(marida_df['image'].tolist(), marida_df['mask'].tolist())\n#marida_df_invalid.to_csv('/kaggle/working/marida_with_invalid.csv')\nmarida_df_invalid = pd.read_csv('/kaggle/working/marida_df_invalid_info.csv')\nmarida_df_F = marida_df.drop(marida_df_invalid[marida_df_invalid['nan pixels']>0].index)\n\n# MARIDA val dataframe\nmarida_val_df = create_marida_df(MARIDA_path, 'val')\n#marida_val_df_invalid = compute_invalid_pixels(marida_val_df['image'].tolist(), marida_val_df['mask'].tolist())\n#marida_val_df_invalid.to_csv('/kaggle/working/marida_val_df_invalid.csv')\nmarida_val_df_invalid =pd.read_csv('/kaggle/working/marida_val_df_invalid_info.csv')\nmarida_val_df_F = marida_val_df.drop(marida_val_df_invalid[marida_val_df_invalid['nan pixels'] > 0].index)\n\n# MARIDA test dataframe\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\n#marida_test_df_invalid = compute_invalid_pixels(marida_test_df['image'].tolist(), marida_test_df['mask'].tolist())\n#marida_test_df_invalid.to_csv('/kaggle/working/marida_test_df_invalid.csv')\nmarida_test_df_invalid =pd.read_csv('/kaggle/working/marida_test_df_invalid_info.csv')\nmarida_test_df_F = marida_test_df.drop(marida_test_df_invalid[marida_test_df_invalid['nan pixels'] > 0].index)\n\n# LR dataframe\n\nlr_df = create_LR_dataframe(LR_splits_path)\n#lr_df_invalid = compute_invalid_pixels(lr_df['image'].tolist(), lr_df['mask'].tolist())\n#lr_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_F = lr_df.drop(lr_df_invalid[lr_df_invalid['high value pixels'] > 0].index)\n\n#LR val dataset\nlr_val_df = create_LR_dataframe(LR_splits_path, 'val')\n#lr_val_df_invalid = compute_invalid_pixels(lr_val_df['image'].tolist(), lr_val_df['mask'].tolist())\n#lr_val_df_invalid.to_csv('/kaggle/working/litter_rows_val_invalid_info.csv')\nlr_val_df_invalid = pd.read_csv('/kaggle/working/litter_rows_val_df_invalid_info.csv')\nlr_val_df_F= lr_val_df.drop(lr_val_df_invalid[lr_val_df_invalid['high value pixels']>0].index)\n\n\n#lr_test_df_invalid = compute_invalid_pixels(lr_test_df['image'].tolist(), lr_test_df['mask'].tolist())\n#lr_test_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\n#lr_test_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:17.628140Z","iopub.execute_input":"2025-05-25T19:00:17.628442Z","iopub.status.idle":"2025-05-25T19:00:27.884272Z","shell.execute_reply.started":"2025-05-25T19:00:17.628409Z","shell.execute_reply":"2025-05-25T19:00:27.883709Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# lr valid = 79495168","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.884996Z","iopub.execute_input":"2025-05-25T19:00:27.885230Z","iopub.status.idle":"2025-05-25T19:00:27.888612Z","shell.execute_reply.started":"2025-05-25T19:00:27.885207Z","shell.execute_reply":"2025-05-25T19:00:27.887997Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#lr_stats = compute_stats(lr_df_filt['image'].tolist())\n#np.savez(\"/kaggle/working/lr_stats.npz\", first=lr_stats['mean'], second=lr_stats['std'])\n#marida_stats = compute_stats(marida_df['image'].tolist())\n#np.savez(\"/kaggle/working/my_marida_stats.npz\", first=marida_stats['mean'], second=marida_stats['std'])\n#global_stats = compute_stats(marida_df['image'].tolist() + lr_df_filt['image'].to_list())\n#np.savez(\"/kaggle/working/global_stats.npz\", first=global_stats['mean'], second=global_stats['std'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.889358Z","iopub.execute_input":"2025-05-25T19:00:27.889872Z","iopub.status.idle":"2025-05-25T19:00:27.905509Z","shell.execute_reply.started":"2025-05-25T19:00:27.889854Z","shell.execute_reply":"2025-05-25T19:00:27.905040Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"global_stats = np.load('/kaggle/working/global_stats.npz')\nglobal_bands_mean = global_stats['first']\nglobal_bands_std = global_stats['second']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.906409Z","iopub.execute_input":"2025-05-25T19:00:27.906658Z","iopub.status.idle":"2025-05-25T19:00:27.922925Z","shell.execute_reply.started":"2025-05-25T19:00:27.906636Z","shell.execute_reply":"2025-05-25T19:00:27.922274Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# global_bands_mean =np.array([0.03721786, 0.03547978, 0.03033651, 0.01722546, 0.01574046,\n#         0.01738895, 0.01939084, 0.01724032, 0.01895351, 0.0109694 ,\n#         0.00784716])\n# global_bands_std = np.array([0.03185222, 0.03198375, 0.03251331, 0.03379553, 0.03407218,\n#         0.04551132, 0.05334419, 0.05064404, 0.0578197 , 0.03721222,\n#         0.02560836])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.923619Z","iopub.execute_input":"2025-05-25T19:00:27.923806Z","iopub.status.idle":"2025-05-25T19:00:27.935073Z","shell.execute_reply.started":"2025-05-25T19:00:27.923791Z","shell.execute_reply":"2025-05-25T19:00:27.934405Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"#computing_labeled_pixels_stats(lr_df_filt['mask'].tolist())\n#computing_labeled_pixels_stats(marida_df['mask'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.935834Z","iopub.execute_input":"2025-05-25T19:00:27.936385Z","iopub.status.idle":"2025-05-25T19:00:27.947454Z","shell.execute_reply.started":"2025-05-25T19:00:27.936368Z","shell.execute_reply":"2025-05-25T19:00:27.946807Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"marida_classes_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\nlr_debris_pixels = 92090\nmarida_pixels = 429412\nmarida_debris_pixels = np.sum(marida_classes_distr[[0,1,2,3,8]]) * marida_pixels\nprint(f'marida debris pixels {marida_debris_pixels}')\ntot_glob_pixels = (len(lr_df_F) + len(marida_df_F))*256**2\nmarida_debris_fraction = np.sum(marida_classes_distr[[0,1,2,3,8]])\n#debris_fraction = (lr_debris_pixels + marida_debris_pixels)/tot_glob_pixels\nprint(f'marida_debris_fraction : {marida_debris_fraction}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.948193Z","iopub.execute_input":"2025-05-25T19:00:27.948756Z","iopub.status.idle":"2025-05-25T19:00:27.961735Z","shell.execute_reply.started":"2025-05-25T19:00:27.948736Z","shell.execute_reply":"2025-05-25T19:00:27.961149Z"}},"outputs":[{"name":"stdout","text":"marida debris pixels 5092.826320000001\nmarida_debris_fraction : 0.011860000000000002\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# Computing here the percentage of debris pixels across the two datasets\n# This will be used as class distribution to generate weights for the loss function\nLR_ratio = 20 # \n\n# For MARIDA the loss function uses only pixels in the 15 classes \n# The fraction of classes assimilated to marine debris is \nmarida_debrix_pixels_distr = np.sum(marida_classes_distr[[0,1,2,3,8]])\n# For LR the DataSet will sample backgroung pixels with a given ratio, stored in the variable LR_ratio\n# Then the effective ratio \neffective_ratio = (1/LR_ratio * len(lr_df_F) + 0.011860000000000002 * len(marida_df_F))/(len(lr_df_F) + len(marida_df_F))\n#print(f'effective global ratio {effective_ratio}')\nclass_distribution = np.array([1 - effective_ratio, effective_ratio])\nprint(f'class distribution {class_distribution}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.962488Z","iopub.execute_input":"2025-05-25T19:00:27.962801Z","iopub.status.idle":"2025-05-25T19:00:27.979809Z","shell.execute_reply.started":"2025-05-25T19:00:27.962777Z","shell.execute_reply":"2025-05-25T19:00:27.979230Z"}},"outputs":[{"name":"stdout","text":"class distribution [0.96384548 0.03615452]\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# MARIDA statistics\n\nclass_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\n\nbands_mean = np.array([0.05197577, 0.04783991, 0.04056812, 0.03163572, 0.02972606, 0.03457443,\n 0.03875053, 0.03436435, 0.0392113,  0.02358126, 0.01588816]).astype(np.float32)\n\nbands_std = np.array([0.04725893, 0.04743808, 0.04699043, 0.04967381, 0.04946782, 0.06458357,\n 0.07594915, 0.07120246, 0.08251058, 0.05111466, 0.03524419]).astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.980611Z","iopub.execute_input":"2025-05-25T19:00:27.980859Z","iopub.status.idle":"2025-05-25T19:00:27.994657Z","shell.execute_reply.started":"2025-05-25T19:00:27.980838Z","shell.execute_reply":"2025-05-25T19:00:27.994029Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Other code references  \n# https://github.com/MarcCoru/marinedebrisdetector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:27.995241Z","iopub.execute_input":"2025-05-25T19:00:27.995461Z","iopub.status.idle":"2025-05-25T19:00:28.009583Z","shell.execute_reply.started":"2025-05-25T19:00:27.995446Z","shell.execute_reply":"2025-05-25T19:00:28.008979Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# MARIDA CLASSES\n# {\n#  1: \"Marine Debris\",\n#  2: \"Dense Sargassum\", \n#  3: \"Sparse Sargassum\", \n#  4: \"Natural Organic Material\", \n#  5: \"Ship\", \n#  6: \"Clouds\", \n#  7: \"Marine Water\", \n#  8: \"Sediment-Laden Water\", \n#  9: \"Foam\", \n#  10: \"Turbid Water\", \n#  11: \"Shallow Water\", \n#  12: \"Waves\", \n#  13: \"Cloud Shadows\", \n#  14: \"Wakes\", \n#  15: \"Mixed Water\"\n# }\n\n\n# From marinedebrisdetector \n# DEBRIS_CLASSES = [1,2,3,4,9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:28.010129Z","iopub.execute_input":"2025-05-25T19:00:28.010358Z","iopub.status.idle":"2025-05-25T19:00:28.027819Z","shell.execute_reply.started":"2025-05-25T19:00:28.010343Z","shell.execute_reply":"2025-05-25T19:00:28.027280Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1rntiw5BvOs80eIbpOu7dk9g1BfOVw61-?usp=drive_link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:28.028528Z","iopub.execute_input":"2025-05-25T19:00:28.028767Z","iopub.status.idle":"2025-05-25T19:00:28.041907Z","shell.execute_reply.started":"2025-05-25T19:00:28.028747Z","shell.execute_reply":"2025-05-25T19:00:28.041187Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"\nclass RandomRotationTransform:\n    \"\"\"Rotate by one of the given angles.\"\"\"\n\n    def __init__(self, angles):\n        self.angles = angles\n\n    def __call__(self, x):\n        angle = random.choice(self.angles)\n        return vF.rotate(x, angle)\n    \ndef gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)\n    \ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean, global_bands_std) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:28.042628Z","iopub.execute_input":"2025-05-25T19:00:28.042835Z","iopub.status.idle":"2025-05-25T19:00:28.057395Z","shell.execute_reply.started":"2025-05-25T19:00:28.042813Z","shell.execute_reply":"2025-05-25T19:00:28.056817Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:28.058046Z","iopub.execute_input":"2025-05-25T19:00:28.058369Z","iopub.status.idle":"2025-05-25T19:00:28.071848Z","shell.execute_reply.started":"2025-05-25T19:00:28.058353Z","shell.execute_reply":"2025-05-25T19:00:28.071160Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom torchvision import transforms\n# model import UNet, AttentionUNet, ResidualAttentionUNet  # From original script\n#f#rom dataloader import bands_mean, bands_std, RandomRotationTransform, class_distr, gen_weights\n#from metrics import Evaluation\n#from customLosses import FocalLoss\nimport pandas as pd\nfrom torch.utils.data import Dataset\n\nclass MergedSegmentationDataset_B(Dataset):\n    \"\"\"\n    df_dataset1 : MARIDA dataset\n    df_dataset2 : LR dataset\n    \"\"\"\n    def __init__(self, df_dataset1, df_dataset2, bands_mean, bands_std, selected_bands, transform=None, standardization=None):\n        \"\"\"\n        df_dataset1 : MARIDA\n        df_dataset2 : Litter Windrows\n        \"\"\"\n        self.bands_mean = bands_mean[selected_bands]\n        self.bands_std = bands_std[selected_bands]\n        self.transform = transform\n        self.standardization = standardization\n        self.image_paths = []\n        self.mask_paths = []\n        self.dataset_ids = []\n        self.image_paths = df_dataset1['image'].tolist() + df_dataset2['image'].tolist() \n        self.mask_paths =  df_dataset1['mask'].tolist() + df_dataset2['mask'].tolist() \n        self.dataset_ids = [0] * len(df_dataset1['image']) + [1] * len(df_dataset2['image'])\n        # Generate shuffled indices\n        indices = np.random.permutation(len(self.image_paths))\n        self.image_paths = np.array(self.image_paths)[indices]\n        self.mask_paths = np.array(self.mask_paths)[indices]\n        self.dataset_ids = np.array(self.dataset_ids)[indices]        \n        #print(self.dataset_ids)\n        if self.transform is None:\n            self.transform = transforms.Compose([transforms.ToTensor()])\n        ## preloading images in memory \n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        #print(f'idx {idx}') \n        max_seed = 2**32 - 1  # NumPy seed limit\n        #index_seed_seed = (42 + idx) % max_seed\n        #np.random.seed(index_seed_seed)\n        # Load Classsification Mask np.random.seed(self.seed + index)  # Deterministic per item\n        dataset_id = self.dataset_ids[idx]\n        # Open t#he GeoTIFF image file\n        #print(f'image path {self.image_paths[idx]}')\n        #print(f'mask path {self.mask_paths[idx]}')\n        with rasterio.open(self.image_paths[idx]) as src:\n            #print(f#\"Number of bands: {dataset.count}\")  # Check the number of bands\n            # Read all bands as a NumPy array\n            image = src.read()\n            # Keep the bands in selecred_bands\n            image = image[selected_bands, :, :]\n            invalid_mask = get_invalid_mask(image, src.nodata)\n            with rasterio.open(self.mask_paths[idx]) as src_mask:\n                mask = src_mask.read().astype(int)\n            debris_before_invalid = np.sum(mask)\n            invalid_pixels = np.sum(np.any(invalid_mask, axis=0))\n            mask[np.any(invalid_mask.astype(bool), axis=0, keepdims=True)] = 0 #I guess it makes sense not to feed invalid pixels to the loss function\n            #print(f'before inputing 2')\n            image[invalid_mask.astype(bool)] = np.tile(self.bands_mean[:, np.newaxis, np.newaxis], (1, 256, 256))[invalid_mask.astype(bool)]\n            #print(f'after inputing')\n            ## Since the model sees unvalid pixels anyway, it's better (?) to replace those with mean values ? \n            #print(f'mask type before transh {type(mask)} - {mask.dtype}')\n            #print(f'image type before transh {type(image)} - {image.dtype}')\n            #############\n            debris_after_invalid = np.sum(mask)\n            #############\n            if self.transform is not None:\n                # applying the same rotation on the image-mask pair\n                #print(f'transform - image shape {image.shape}')\n                #print(f'transform - mask shape {mask.shape}')\n                stack = np.concatenate([image, mask], axis=0).astype(np.float32) \n                stack = np.transpose(stack,(1, 2, 0)) #to channel last\n                #print(f'stack shape before transfrom {stack.shape}')\n                stack = self.transform(stack) #expects channel last, returns channel first\n               \n                #print(f'stack shape after transfrom {stack.shape}')\n                image = stack[:-1,:,:]\n                mask = stack[-1,:,:].long()\n                #print(f'image type {image.dtype}')\n                #print(f'image shape after transform {image.shape}')\n                #print(f'mask shape after transform {mask.shape}')\n\n                   \n            \n            if self.standardization is not None:\n                image = self.standardization(image)\n                \n            #mask = mask - 1 Moved to collate function\n            if isinstance(mask, np.ndarray):\n                mask = torch.from_numpy(mask).to(torch.long)\n            else:\n                mask = mask.to(torch.long)\n            if isinstance(image, np.ndarray):\n                image = torch.from_numpy(image).to(torch.float32)\n            else:\n                im = image.to(torch.float32)\n            if torch.sum(mask) == 0 :\n                print(f'{self.mask_paths[idx]} has no debris pixels')\n                print(f'debris pixels before invalid mask : {debris_before_invalid}')\n                print(f'debris pixels after invalid mask : {debris_after_invalid}')\n                print(f'invalid pixels : {invalid_pixels}')\n           \n        ## Add logic for transform\n\n            return image, mask, dataset_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:28.072599Z","iopub.execute_input":"2025-05-25T19:00:28.072804Z","iopub.status.idle":"2025-05-25T19:00:32.878162Z","shell.execute_reply.started":"2025-05-25T19:00:28.072781Z","shell.execute_reply":"2025-05-25T19:00:32.877171Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def conv3x3(in_channels, out_channels, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, ratio=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.mlp = nn.Sequential(nn.Conv2d(channels, channels // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(channels // 16, channels, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.mlp(self.avg_pool(x))\n        max_out = self.mlp(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inputChannel, outputChannel, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(inputChannel, outputChannel, stride)\n        self.bn1 = nn.BatchNorm2d(outputChannel)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(outputChannel, outputChannel)\n        self.bn2 = nn.BatchNorm2d(outputChannel)\n        self.downsample = downsample\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n        \n    # def forward(self, x):\n    \n    #     residual = x\n    #     out = self.conv1(x)\n    #     out = self.bn1(out)\n    #     out = self.relu(out)\n    #     out = self.conv2(out)\n    #     out = self.bn2(out)\n    #     if self.downsample:\n    #         residual = self.downsample(x)\n    #     out += residual\n    #     out = self.relu(out)\n    #     caOutput = self.ca(out)\n    #     out = caOutput * out\n    #     saOutput = self.sa(out)\n    #     out = saOutput * out\n    #     return out, saOutput\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.bn2(out)\n        out = self.relu(out)\n        caOutput = self.ca(out)\n        out = caOutput * out\n        saOutput = self.sa(out)\n        out = saOutput * out\n        return out, saOutput\n\n\nclass DownSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.AvgPool2d(2)\n        )\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self,x):\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\n    \nclass UpSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2)\n        )\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\nclass ResidualAttentionUNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n    self.downsample2 = DownSampleWithAttention(32, 64)\n    self.downsample3 = DownSampleWithAttention(64, 128)\n    self.downsample4 = DownSampleWithAttention(128, 256)\n    self.downsample5 = DownSampleWithAttention(256, 512)\n\n    self.residualBlock1 = ResidualBlock(512, 512)\n    self.residualBlock2 = ResidualBlock(512, 512)\n    self.residualBlock3 = ResidualBlock(512, 512)\n\n    self.upsample1 = UpSampleWithAttention(512, 256)\n    self.upsample2 = UpSampleWithAttention(512, 128)\n    self.upsample3 = UpSampleWithAttention(256, 64)\n    self.upsample4 = UpSampleWithAttention(128, 32)\n    self.upsample5 = UpSampleWithAttention(64, 32)\n    self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128, sa128down = self.downsample1(x)\n    scale64, sa64down = self.downsample2(scale128)\n    scale32, sa32down = self.downsample3(scale64)\n    scale16, sa64down = self.downsample4(scale32)\n    scale8, sa8down = self.downsample5(scale16)\n    scale8, sa8down = self.residualBlock1(scale8)\n    scale8, sa8down = self.residualBlock2(scale8)\n    scale8, sa8down = self.residualBlock3(scale8)\n    upscale16, sa16up = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32, sa32up = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64, sa64up = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128, sa128up = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256, sa256up = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:32.879120Z","iopub.execute_input":"2025-05-25T19:00:32.879980Z","iopub.status.idle":"2025-05-25T19:00:32.900345Z","shell.execute_reply.started":"2025-05-25T19:00:32.879951Z","shell.execute_reply":"2025-05-25T19:00:32.899317Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"def Evaluation(y_predicted, y_true):\n\n    micro_prec = precision_score(y_true, y_predicted, average='micro')\n    macro_prec = precision_score(y_true, y_predicted, average='macro')\n    weight_prec = precision_score(y_true, y_predicted, average='weighted')\n    \n    micro_rec = recall_score(y_true, y_predicted, average='micro')\n    macro_rec = recall_score(y_true, y_predicted, average='macro')\n    weight_rec = recall_score(y_true, y_predicted, average='weighted')\n        \n    macro_f1 = f1_score(y_true, y_predicted, average=\"macro\")\n    micro_f1 = f1_score(y_true, y_predicted, average=\"micro\")\n    weight_f1 = f1_score(y_true, y_predicted, average=\"weighted\")\n        \n    subset_acc = accuracy_score(y_true, y_predicted)\n    \n    iou_acc = jaccard_score(y_true, y_predicted, average='macro')\n\n    # Debris-specific metrics\n    debris_class = 1\n    debris_prec = precision_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_rec = recall_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_f1 = f1_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_iou = jaccard_score(y_true, y_predicted, labels=[debris_class], average='macro')\n\n    info = {\n            \"macroPrec\" : macro_prec,\n            \"microPrec\" : micro_prec,\n            \"weightPrec\" : weight_prec,\n            \"macroRec\" : macro_rec,\n            \"microRec\" : micro_rec,\n            \"weightRec\" : weight_rec,\n            \"macroF1\" : macro_f1,\n            \"microF1\" : micro_f1,\n            \"weightF1\" : weight_f1,\n            \"subsetAcc\" : subset_acc,\n            \"IoU\": iou_acc,\n            \"debris Prec\" : debris_prec,\n            \"debris Rec\" : debris_rec,\n            \"debris F1\" : debris_f1,\n            \"debris IoU\" : debris_iou\n            }\n    \n    return info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:32.901296Z","iopub.execute_input":"2025-05-25T19:00:32.901671Z","iopub.status.idle":"2025-05-25T19:00:32.938643Z","shell.execute_reply.started":"2025-05-25T19:00:32.901643Z","shell.execute_reply":"2025-05-25T19:00:32.938034Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"selected_bands = np.array([ 4, 6, 8, 11]) - 1 #bands conted from 0\n\ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean[selected_bands].tolist(), global_bands_std[selected_bands].tolist())\nmerged_ds = MergedSegmentationDataset_B(marida_df_F, lr_df_F, global_bands_mean, global_bands_std, selected_bands, transform=transformTrain, standardization= standardization)\nval_ds = MergedSegmentationDataset_B(marida_val_df_F, lr_val_df_F, global_bands_mean, global_bands_std,selected_bands, transform=transformTest, standardization= standardization )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:32.939385Z","iopub.execute_input":"2025-05-25T19:00:32.939635Z","iopub.status.idle":"2025-05-25T19:00:32.960161Z","shell.execute_reply.started":"2025-05-25T19:00:32.939617Z","shell.execute_reply":"2025-05-25T19:00:32.959513Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"\ntrainLoader = DataLoader(merged_ds,\n                        batch_size=batch_size, \n                        shuffle=True,  \n                        #num_workers=2, \n                        #pin_memory=True,\n                        #prefetch_factor=2,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n\n\ntestLoader = DataLoader(val_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n                        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:32.960912Z","iopub.execute_input":"2025-05-25T19:00:32.961160Z","iopub.status.idle":"2025-05-25T19:00:32.975650Z","shell.execute_reply.started":"2025-05-25T19:00:32.961138Z","shell.execute_reply":"2025-05-25T19:00:32.975007Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"model = ResidualAttentionUNet(len(selected_bands), 2).to(device)\nweight = gen_weights(torch.from_numpy(class_distribution), c = 1.03).to(device)\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean', weight=weight.to(torch.float32))\n#optimizer = torch.optim.Adam(model.parameters(), lr=8e-4, weight_decay=1e-2)\noptimizer = torch.optim.AdamW(model.parameters(), lr=8e-4, weight_decay=1e-4)\n\n\n# assuming about 40 reductions => .9 ** 40 = 1e-2, starting from 8e-4 ending with 8e-6\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5)\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) \nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:32.976290Z","iopub.execute_input":"2025-05-25T19:00:32.976494Z","iopub.status.idle":"2025-05-25T19:00:33.377572Z","shell.execute_reply.started":"2025-05-25T19:00:32.976479Z","shell.execute_reply":"2025-05-25T19:00:33.376962Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"best_metric = -float('inf')  # Initialize to negative infinity (for maximization, e.g., accuracy)\nbest_model_path = '/kaggle/working/best_model.pth'\noutput_classes = 2\nmetrics_history = []\npatience = 10  # Number of epochs to wait for improvement\nepochs_no_improve = 0  # Counter for epochs without improvement\nepochs = 50\nfor epoch in range(1, epochs+1):\n    model.train()\n    pb = tqdm(trainLoader, desc=f\"epoch {epoch}/{epochs}: \")\n    yTrue = []\n    yPredicted = []\n\n    bg_yTrue = []\n    bg_yPredicted = []\n    for image, target, _ in pb:\n        image, target = image.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        logits = model(image)\n        # print(f'logits shape : {logits.shape}')\n        # print(f'target shape : {target.shape}')\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        loss = criterion(logits, target)\n\n        loss.backward()\n        optimizer.step()\n        pb.set_postfix(loss=loss.item())\n\n        if epoch % 10 == 0:\n            with torch.no_grad():\n                logits = logits.detach()\n                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n                logits = logits.reshape((-1,output_classes))\n                target = target.reshape(-1)\n                ###################################################################################\n                mask = target != -1\n                ###################################################################################\n                \n                # bg_logits = logits[~mask]\n                # bg_target = target[~mask]\n    \n                # only considering annotated pixels\n                logits = logits[mask]\n                target = target[mask]\n    \n                probs = F.softmax(logits, dim=1).cpu().numpy()\n                target = target.cpu().numpy()\n                yPredicted += probs.argmax(1).tolist()\n                yTrue += target.tolist()\n        \n                \n                # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n                # bg_target = bg_target.cpu().numpy()\n                \n                # bg_yPredicted += bg_probs.argmax(1).tolist()\n                # bg_yTrue += bg_target.tolist()\n\n\n    if epoch % 10 == 0:\n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        acc = Evaluation(yPredicted, yTrue)\n        print(acc)\n    \n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        # print(\"background:\", bg_acc)\n\n\n    model.eval()\n    yTrue = []\n    yPredicted = []\n    testLossF = []\n    valPrecHistory = []\n    # bg_yTrue = []\n    # bg_yPredicted = []\n    iters = len(testLoader)\n    with torch.no_grad():\n        for i, (image, target, _) in enumerate(testLoader):\n\n            image, target = image.to(device), target.to(device)\n            logits = model(image)\n            # print(f'image dtype {image.dtype}')\n            # print(f'logits dtype {logits.dtype}')\n            # print(f'target dtype {target.dtype}')\n            # print(f'test - target shape {target.shape}')\n            # print(f'test - logit shape {logits.shape}')\n            loss = criterion(logits, target)\n\n            logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n            logits = logits.reshape((-1,output_classes))\n            target = target.reshape(-1)\n            ###################################################################################\n            mask = target != -1\n            ###################################################################################\n            \n            # bg_logits = logits[~mask]\n            # bg_target = target[~mask]\n            \n            logits = logits[mask]\n            target = target[mask]\n            \n\n            probs = F.softmax(logits, dim=1).cpu().numpy()\n            target = target.cpu().numpy()\n            # testBatches += target.shape[0]\n            testLossF.append((loss.data*target.shape[0]).tolist())\n            yPredicted += probs.argmax(1).tolist()\n            yTrue += target.tolist()\n\n            #scheduler.step(epoch + i/iters)\n            # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n            # bg_target = bg_target.cpu().numpy()\n\n            # bg_yPredicted += bg_probs.argmax(1).tolist()\n            # bg_yTrue += bg_target.tolist()\n        \n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        print('########### Validation Set Evaluation : #############')\n        acc = Evaluation(yPredicted, yTrue)\n        metrics_history.append(acc)\n        if acc['debris IoU'] > best_metric:\n            best_metric = acc['debris IoU']\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Saved best model with validation metric: {best_metric}\")\n            epochs_no_improve = 0  # Reset counter\n        else:\n            epochs_no_improve += 1\n            print(f\"No improvement for {epochs_no_improve}/{patience} epochs\")\n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        print(acc)\n        # Early stopping check\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered at epoch {epoch}\")\n            break\n        # print(\"background:\", bg_acc)\n    #scheduler.step(sum(testLossF) / len(testLoader.dataset))\n    scheduler.step(acc['debris Prec'])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T19:00:33.378320Z","iopub.execute_input":"2025-05-25T19:00:33.378564Z","iopub.status.idle":"2025-05-25T20:31:52.467986Z","shell.execute_reply.started":"2025-05-25T19:00:33.378540Z","shell.execute_reply":"2025-05-25T20:31:52.467298Z"}},"outputs":[{"name":"stderr","text":"epoch 1/50: 100%|██████████| 120/120 [02:47<00:00,  1.40s/it, loss=0.184]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.11067941821079896\n{'macroPrec': 0.554694903717085, 'microPrec': 0.7500274633552682, 'weightPrec': 0.9694497617677444, 'macroRec': 0.8514600190305359, 'microRec': 0.7500274633552682, 'weightRec': 0.7500274633552682, 'macroF1': 0.525597743357803, 'microF1': 0.7500274633552682, 'weightF1': 0.8307452155430837, 'subsetAcc': 0.7500274633552682, 'IoU': 0.4263402604468488, 'debris Prec': 0.11119323124773849, 'debris Rec': 0.9599229030971687, 'debris F1': 0.19930038568481478, 'debris IoU': 0.11067941821079896}\n","output_type":"stream"},{"name":"stderr","text":"epoch 2/50: 100%|██████████| 120/120 [01:24<00:00,  1.41it/s, loss=0.276] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.32212740086915403\n{'macroPrec': 0.6629131769089602, 'microPrec': 0.9351541717375149, 'weightPrec': 0.9765053507998842, 'macroRec': 0.9427235153599445, 'microRec': 0.9351541717375149, 'weightRec': 0.9351541717375149, 'macroF1': 0.7263373961690862, 'microF1': 0.9351541717375149, 'weightF1': 0.9498935554713359, 'subsetAcc': 0.9351541717375149, 'IoU': 0.6276099090048817, 'debris Prec': 0.32758581209498294, 'debris Rec': 0.9508174930214011, 'debris F1': 0.4872864758076877, 'debris IoU': 0.32212740086915403}\n","output_type":"stream"},{"name":"stderr","text":"epoch 3/50: 100%|██████████| 120/120 [01:25<00:00,  1.41it/s, loss=0.124] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.579630007958074, 'microPrec': 0.8476096110973496, 'weightPrec': 0.9689803204767132, 'macroRec': 0.8718225409608276, 'microRec': 0.8476096110973496, 'weightRec': 0.8476096110973496, 'macroF1': 0.5955811640673743, 'microF1': 0.8476096110973496, 'weightF1': 0.8941446472658943, 'subsetAcc': 0.8476096110973496, 'IoU': 0.501677040105433, 'debris Prec': 0.16329367957831617, 'debris Rec': 0.8977136780539678, 'debris F1': 0.27632413412164236, 'debris IoU': 0.16031096077384133}\n","output_type":"stream"},{"name":"stderr","text":"epoch 4/50: 100%|██████████| 120/120 [01:25<00:00,  1.41it/s, loss=0.208] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.3732914960378663\n{'macroPrec': 0.6906079218600636, 'microPrec': 0.9492347955326276, 'weightPrec': 0.9777416263760098, 'macroRec': 0.9413919190935077, 'microRec': 0.9492347955326276, 'weightRec': 0.9492347955326276, 'macroF1': 0.7583837075219382, 'microF1': 0.9492347955326276, 'weightF1': 0.9592035618738215, 'subsetAcc': 0.9492347955326276, 'IoU': 0.6604717030583919, 'debris Prec': 0.38357287283458114, 'debris Rec': 0.933005449953476, 'debris F1': 0.543644953915266, 'debris IoU': 0.3732914960378663}\n","output_type":"stream"},{"name":"stderr","text":"epoch 5/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0806]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.6835551785425663, 'microPrec': 0.9472509719873776, 'weightPrec': 0.9761743463088215, 'macroRec': 0.9240506589533961, 'microRec': 0.9472509719873776, 'weightRec': 0.9472509719873776, 'macroF1': 0.7485062965805596, 'microF1': 0.9472509719873776, 'weightF1': 0.957583907540057, 'subsetAcc': 0.9472509719873776, 'IoU': 0.6507711149344303, 'debris Prec': 0.37065446675615704, 'debris Rec': 0.8992423235411405, 'debris F1': 0.5249374381656289, 'debris IoU': 0.35587469423183143}\n","output_type":"stream"},{"name":"stderr","text":"epoch 6/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.219] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.5522335698136743\n{'macroPrec': 0.7849131734624086, 'microPrec': 0.9752571323949123, 'weightPrec': 0.9841880899500626, 'macroRec': 0.9589821571357741, 'microRec': 0.9752571323949123, 'weightRec': 0.9752571323949123, 'macroF1': 0.8493041667401042, 'microF1': 0.9752571323949123, 'weightF1': 0.9781442630273677, 'subsetAcc': 0.9752571323949123, 'IoU': 0.763355947026245, 'debris Prec': 0.5718264379414733, 'debris Rec': 0.9415791572510966, 'debris F1': 0.711534115165365, 'debris IoU': 0.5522335698136743}\n","output_type":"stream"},{"name":"stderr","text":"epoch 7/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.143] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.5887421997707688\n{'macroPrec': 0.8085207223058575, 'microPrec': 0.9791321579735275, 'weightPrec': 0.9850977321481263, 'macroRec': 0.9514132957268787, 'microRec': 0.9791321579735275, 'weightRec': 0.9791321579735275, 'macroF1': 0.8651351850096808, 'microF1': 0.9791321579735275, 'weightF1': 0.981090913821225, 'subsetAcc': 0.9791321579735275, 'IoU': 0.7836158810286704, 'debris Prec': 0.6197050938337801, 'debris Rec': 0.9217732287651202, 'debris F1': 0.7411425212419174, 'debris IoU': 0.5887421997707688}\n","output_type":"stream"},{"name":"stderr","text":"epoch 8/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.297] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6420919361121932\n{'macroPrec': 0.8509327466403733, 'microPrec': 0.9841681834336733, 'weightPrec': 0.9864340126059193, 'macroRec': 0.9320788107151021, 'microRec': 0.9841681834336733, 'weightRec': 0.9841681834336733, 'macroF1': 0.8869135805430393, 'microF1': 0.9841681834336733, 'weightF1': 0.9849881768104712, 'subsetAcc': 0.9841681834336733, 'IoU': 0.8128986557823646, 'debris Prec': 0.706039837224245, 'debris Rec': 0.8763791040808189, 'debris F1': 0.7820413973073959, 'debris IoU': 0.6420919361121932}\n","output_type":"stream"},{"name":"stderr","text":"epoch 9/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0842]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6549355019629838\n{'macroPrec': 0.8429163776078257, 'microPrec': 0.9840971018082735, 'weightPrec': 0.9876418787211828, 'macroRec': 0.9586039598930414, 'microRec': 0.9840971018082735, 'weightRec': 0.9840971018082735, 'macroF1': 0.8916134929235583, 'microF1': 0.9840971018082735, 'weightF1': 0.9852437496689042, 'subsetAcc': 0.9840971018082735, 'IoU': 0.8192688268473596, 'debris Prec': 0.6881598978539508, 'debris Rec': 0.9313438787717666, 'debris F1': 0.7914936880454122, 'debris IoU': 0.6549355019629838}\n","output_type":"stream"},{"name":"stderr","text":"epoch 10/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0457]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8456717778667626, 'microPrec': 0.9809723494268596, 'weightPrec': 0.9859181284230046, 'macroRec': 0.9735245224752371, 'microRec': 0.9809723494268596, 'weightRec': 0.9809723494268596, 'macroF1': 0.8983628040544622, 'microF1': 0.9809723494268596, 'weightF1': 0.9824551043465876, 'subsetAcc': 0.9809723494268596, 'IoU': 0.8281274494593381, 'debris Prec': 0.6928529761421283, 'debris Rec': 0.9654090315146152, 'debris F1': 0.80673200928553, 'debris IoU': 0.6760694291334328}\n########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6864666864666865\n{'macroPrec': 0.8631640550529729, 'microPrec': 0.9863566359005288, 'weightPrec': 0.988656270053002, 'macroRec': 0.9551144062242657, 'microRec': 0.9863566359005288, 'weightRec': 0.9863566359005288, 'macroF1': 0.9035035575811154, 'microF1': 0.9863566359005288, 'weightF1': 0.9871227935897895, 'subsetAcc': 0.9863566359005288, 'IoU': 0.8362016127437866, 'debris Prec': 0.7289739276703112, 'debris Rec': 0.921706765917852, 'debris F1': 0.814088641033167, 'debris IoU': 0.6864666864666865}\n","output_type":"stream"},{"name":"stderr","text":"epoch 11/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0596]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8662601877736464, 'microPrec': 0.9861390830470323, 'weightPrec': 0.987924125258783, 'macroRec': 0.9406450812620706, 'microRec': 0.9861390830470323, 'weightRec': 0.9861390830470323, 'macroF1': 0.8997175601853843, 'microF1': 0.9861390830470323, 'weightF1': 0.986777752655027, 'subsetAcc': 0.9861390830470323, 'IoU': 0.8308215265778871, 'debris Prec': 0.7361636772530306, 'debris Rec': 0.8919978731888875, 'debris F1': 0.8066231931965022, 'debris IoU': 0.675916599516519}\n","output_type":"stream"},{"name":"stderr","text":"epoch 12/50: 100%|██████████| 120/120 [01:24<00:00,  1.41it/s, loss=0.117] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6983850064799123\n{'macroPrec': 0.8670249869464892, 'microPrec': 0.9869662146880486, 'weightPrec': 0.9892068759142735, 'macroRec': 0.9600223292730882, 'microRec': 0.9869662146880486, 'weightRec': 0.9869662146880486, 'macroF1': 0.9078227784752635, 'microF1': 0.9869662146880486, 'weightF1': 0.987698625666572, 'subsetAcc': 0.9869662146880486, 'IoU': 0.8424728134717416, 'debris Prec': 0.7363746255321385, 'debris Rec': 0.9312109530772298, 'debris F1': 0.8224107064244416, 'debris IoU': 0.6983850064799123}\n","output_type":"stream"},{"name":"stderr","text":"epoch 13/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0561]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.858648520956027, 'microPrec': 0.9853291833152039, 'weightPrec': 0.9874612120654951, 'macroRec': 0.9407404615266437, 'microRec': 0.9853291833152039, 'weightRec': 0.9853291833152039, 'macroF1': 0.8950958161656861, 'microF1': 0.9853291833152039, 'weightF1': 0.9860821584137203, 'subsetAcc': 0.9853291833152039, 'IoU': 0.8242565029895812, 'debris Prec': 0.7209077740222115, 'debris Rec': 0.8930612787451815, 'debris F1': 0.797803176488051, 'debris IoU': 0.6636210983800869}\n","output_type":"stream"},{"name":"stderr","text":"epoch 14/50: 100%|██████████| 120/120 [01:26<00:00,  1.38it/s, loss=0.0775]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.7889065163356681, 'microPrec': 0.976032568308365, 'weightPrec': 0.9846709242406861, 'macroRec': 0.9627552888647142, 'microRec': 0.976032568308365, 'weightRec': 0.976032568308365, 'macroF1': 0.8534997291198279, 'microF1': 0.976032568308365, 'weightF1': 0.9787970202580074, 'subsetAcc': 0.976032568308365, 'IoU': 0.7685921427371303, 'debris Prec': 0.5795736040609137, 'debris Rec': 0.9485577562142762, 'debris F1': 0.7195180358448238, 'debris IoU': 0.561911886294736}\n","output_type":"stream"},{"name":"stderr","text":"epoch 15/50: 100%|██████████| 120/120 [01:26<00:00,  1.38it/s, loss=0.152] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8587657708789941, 'microPrec': 0.9860981572627112, 'weightPrec': 0.9887972440956013, 'macroRec': 0.9615329827313597, 'microRec': 0.9860981572627112, 'weightRec': 0.9860981572627112, 'macroF1': 0.9031187376112499, 'microF1': 0.9860981572627112, 'weightF1': 0.9869683985597213, 'subsetAcc': 0.9860981572627112, 'IoU': 0.8356165647464721, 'debris Prec': 0.719721767594108, 'debris Rec': 0.9352651867606008, 'debris F1': 0.8134574252846986, 'debris IoU': 0.6855695215823833}\n","output_type":"stream"},{"name":"stderr","text":"epoch 16/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0425]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7049122453096631\n{'macroPrec': 0.8713413939278869, 'microPrec': 0.9873970124177446, 'weightPrec': 0.9894165912752275, 'macroRec': 0.9591529186965061, 'microRec': 0.9873970124177446, 'weightRec': 0.9873970124177446, 'macroF1': 0.9101897545674851, 'microF1': 0.9873970124177446, 'weightF1': 0.9880629911571985, 'subsetAcc': 0.9873970124177446, 'IoU': 0.8459590253060826, 'debris Prec': 0.7450823604669758, 'debris Rec': 0.928951216270105, 'debris F1': 0.8269190948084603, 'debris IoU': 0.7049122453096631}\n","output_type":"stream"},{"name":"stderr","text":"epoch 17/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0303]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8771182814089121, 'microPrec': 0.9872031534393814, 'weightPrec': 0.9885381501041189, 'macroRec': 0.9397496106546962, 'microRec': 0.9872031534393814, 'weightRec': 0.9872031534393814, 'macroF1': 0.9058236037267092, 'microF1': 0.9872031534393814, 'weightF1': 0.987693623427014, 'subsetAcc': 0.9872031534393814, 'IoU': 0.8396352915967498, 'debris Prec': 0.7579758599195331, 'debris Rec': 0.8890070450618105, 'debris F1': 0.8182791423240449, 'debris IoU': 0.6924470673500026}\n","output_type":"stream"},{"name":"stderr","text":"epoch 18/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0433]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8602820990959804, 'microPrec': 0.986447103423765, 'weightPrec': 0.9891978573678613, 'macroRec': 0.9663383429521428, 'microRec': 0.986447103423765, 'weightRec': 0.986447103423765, 'macroF1': 0.9058799805071617, 'microF1': 0.986447103423765, 'weightF1': 0.9873159275909372, 'subsetAcc': 0.986447103423765, 'IoU': 0.8396059448984676, 'debris Prec': 0.7224311413761562, 'debris Rec': 0.9448358367672471, 'debris F1': 0.8187996774565143, 'debris IoU': 0.6931929003315779}\n","output_type":"stream"},{"name":"stderr","text":"epoch 19/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0756]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7084440277126635\n{'macroPrec': 0.8814577633338037, 'microPrec': 0.9879441255344584, 'weightPrec': 0.9892877691229711, 'macroRec': 0.9473270176651545, 'microRec': 0.9879441255344584, 'weightRec': 0.9879441255344584, 'macroF1': 0.9115477470115358, 'microF1': 0.9879441255344584, 'weightF1': 0.9884230880381193, 'subsetAcc': 0.9879441255344584, 'IoU': 0.8480121637492654, 'debris Prec': 0.7661540194918596, 'debris Rec': 0.9038947228499269, 'debris F1': 0.8293441473305485, 'debris IoU': 0.7084440277126635}\n","output_type":"stream"},{"name":"stderr","text":"epoch 20/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.154] \n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8632387991914148, 'microPrec': 0.9838460926403394, 'weightPrec': 0.9875585081391406, 'macroRec': 0.9773174841775037, 'microRec': 0.9838460926403394, 'weightRec': 0.9838460926403394, 'macroF1': 0.9115992414541709, 'microF1': 0.9838460926403394, 'weightF1': 0.984941154954656, 'subsetAcc': 0.9838460926403394, 'IoU': 0.8475190553960688, 'debris Prec': 0.7277743904792041, 'debris Rec': 0.970203615486712, 'debris F1': 0.8316825570421852, 'debris IoU': 0.7118635111161439}\n########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8651393036583505, 'microPrec': 0.986811127505358, 'weightPrec': 0.9891784136757695, 'macroRec': 0.9613875144231365, 'microRec': 0.986811127505358, 'weightRec': 0.986811127505358, 'macroF1': 0.9071505304316048, 'microF1': 0.986811127505358, 'weightF1': 0.9875786123983317, 'subsetAcc': 0.986811127505358, 'IoU': 0.8414825422504371, 'debris Prec': 0.7325029965084163, 'debris Rec': 0.9342017812043067, 'debris F1': 0.8211479480064262, 'debris IoU': 0.6965657366569206}\n","output_type":"stream"},{"name":"stderr","text":"epoch 21/50: 100%|██████████| 120/120 [01:26<00:00,  1.40it/s, loss=0.0625]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.7727574617557335, 'microPrec': 0.972876974938342, 'weightPrec': 0.983231921006032, 'macroRec': 0.9552791039854469, 'microRec': 0.972876974938342, 'weightRec': 0.972876974938342, 'macroF1': 0.838488117602598, 'microF1': 0.972876974938342, 'weightF1': 0.976266185358467, 'subsetAcc': 0.972876974938342, 'IoU': 0.7500496965669218, 'debris Prec': 0.547694938972246, 'debris Rec': 0.9364615180114316, 'debris F1': 0.6911606004120475, 'debris IoU': 0.528071358968593}\n","output_type":"stream"},{"name":"stderr","text":"epoch 22/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0855]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8694732374254053, 'microPrec': 0.9866064985837525, 'weightPrec': 0.9883400985558318, 'macroRec': 0.944066334182982, 'microRec': 0.9866064985837525, 'weightRec': 0.9866064985837525, 'macroF1': 0.9030459671248349, 'microF1': 0.9866064985837525, 'weightF1': 0.9872203140919786, 'subsetAcc': 0.9866064985837525, 'IoU': 0.8355889513492898, 'debris Prec': 0.7423676696683505, 'debris Rec': 0.8985776950684567, 'debris F1': 0.8130374646701546, 'debris IoU': 0.6849731482419698}\n","output_type":"stream"},{"name":"stderr","text":"epoch 23/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0882]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8420654798945764, 'microPrec': 0.9836339942488503, 'weightPrec': 0.9868650815144471, 'macroRec': 0.9473159358880108, 'microRec': 0.9836339942488503, 'weightRec': 0.9836339942488503, 'macroF1': 0.8870068343105513, 'microF1': 0.9836339942488503, 'weightF1': 0.9847242370816649, 'subsetAcc': 0.9836339942488503, 'IoU': 0.8129351933923591, 'debris Prec': 0.6872297637003519, 'debris Rec': 0.908480659311445, 'debris F1': 0.7825166017861231, 'debris IoU': 0.642732872525509}\n","output_type":"stream"},{"name":"stderr","text":"epoch 24/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0244]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.881181325680209, 'microPrec': 0.9878321181247375, 'weightPrec': 0.9891425840828733, 'macroRec': 0.9453099184321991, 'microRec': 0.9878321181247375, 'weightRec': 0.9878321181247375, 'macroF1': 0.9105420067327543, 'microF1': 0.9878321181247375, 'weightF1': 0.9883040676703472, 'subsetAcc': 0.9878321181247375, 'IoU': 0.8465319284825117, 'debris Prec': 0.7657372320570104, 'debris Rec': 0.8998404891665559, 'debris F1': 0.8273902282519021, 'debris IoU': 0.7055972482801751}\n","output_type":"stream"},{"name":"stderr","text":"epoch 25/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0785]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 6/10 epochs\n{'macroPrec': 0.8757017852349891, 'microPrec': 0.9876684149874531, 'weightPrec': 0.9893930452260995, 'macroRec': 0.9545717668870908, 'microRec': 0.9876684149874531, 'weightRec': 0.9876684149874531, 'macroF1': 0.9110600228631797, 'microF1': 0.9876684149874531, 'weightF1': 0.988253908141456, 'subsetAcc': 0.9876684149874531, 'IoU': 0.847262891447716, 'debris Prec': 0.7541305414690005, 'debris Rec': 0.9191811777216536, 'debris F1': 0.8285158005092108, 'debris IoU': 0.7072360010227563}\n","output_type":"stream"},{"name":"stderr","text":"epoch 26/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0148]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 7/10 epochs\n{'macroPrec': 0.8653815051000795, 'microPrec': 0.9871622276550602, 'weightPrec': 0.989741294841419, 'macroRec': 0.9699518353632662, 'microRec': 0.9871622276550602, 'weightRec': 0.9871622276550602, 'macroF1': 0.9105242478706912, 'microF1': 0.9871622276550602, 'weightF1': 0.9879652425551542, 'subsetAcc': 0.9871622276550602, 'IoU': 0.8464123241513047, 'debris Prec': 0.732402291794557, 'debris Rec': 0.9515485843413531, 'debris F1': 0.8277157888651211, 'debris IoU': 0.7060709177886275}\n","output_type":"stream"},{"name":"stderr","text":"epoch 27/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0545]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7214065708418891\n{'macroPrec': 0.8789640844936204, 'microPrec': 0.9883103036047, 'weightPrec': 0.9900714881177545, 'macroRec': 0.9620658544302649, 'microRec': 0.9883103036047, 'weightRec': 0.9883103036047, 'macroF1': 0.9160477910312734, 'microF1': 0.9883103036047, 'weightF1': 0.9888876024326334, 'subsetAcc': 0.9883103036047, 'IoU': 0.8546759910064372, 'debris Prec': 0.760155785146319, 'debris Rec': 0.9340023926625016, 'debris F1': 0.8381594250439866, 'debris IoU': 0.7214065708418891}\n","output_type":"stream"},{"name":"stderr","text":"epoch 28/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0555]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7250040251167283\n{'macroPrec': 0.8933737912298332, 'microPrec': 0.9889629621651894, 'weightPrec': 0.989874260279268, 'macroRec': 0.9449307282615241, 'microRec': 0.9889629621651894, 'weightRec': 0.9889629621651894, 'macroF1': 0.917433006669562, 'microF1': 0.9889629621651894, 'weightF1': 0.9893023095321188, 'subsetAcc': 0.9889629621651894, 'IoU': 0.8568181018858346, 'debris Prec': 0.7901848385587272, 'debris Rec': 0.8978466037485046, 'debris F1': 0.8405824155310808, 'debris IoU': 0.7250040251167283}\n","output_type":"stream"},{"name":"stderr","text":"epoch 29/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0537]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7335310965630114\n{'macroPrec': 0.8796744823651361, 'microPrec': 0.9887777191414201, 'weightPrec': 0.990722634176496, 'macroRec': 0.9715895949907053, 'microRec': 0.9887777191414201, 'weightRec': 0.9887777191414201, 'macroF1': 0.9202308752667265, 'microF1': 0.9887777191414201, 'weightF1': 0.9893832923704339, 'subsetAcc': 0.9887777191414201, 'IoU': 0.860975539991014, 'debris Prec': 0.7609295415959253, 'debris Rec': 0.9532101555230627, 'debris F1': 0.8462854782557385, 'debris IoU': 0.7335310965630114}\n","output_type":"stream"},{"name":"stderr","text":"epoch 30/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0386]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8724564934411042, 'microPrec': 0.9853401005259923, 'weightPrec': 0.9885496549342913, 'macroRec': 0.9808735065045471, 'microRec': 0.9853401005259923, 'weightRec': 0.9853401005259923, 'macroF1': 0.9189594414329239, 'microF1': 0.9853401005259923, 'weightF1': 0.9862705544682896, 'subsetAcc': 0.9853401005259923, 'IoU': 0.8586249724763546, 'debris Prec': 0.7459561049643383, 'debris Rec': 0.976006502525902, 'debris F1': 0.8456141914779818, 'debris IoU': 0.7325230310658769}\n########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8607383491147653, 'microPrec': 0.986806819528061, 'weightPrec': 0.9897649971115021, 'macroRec': 0.9747465243828317, 'microRec': 0.986806819528061, 'weightRec': 0.986806819528061, 'macroF1': 0.9092444020775303, 'microF1': 0.986806819528061, 'weightF1': 0.9877062620812928, 'subsetAcc': 0.986806819528061, 'IoU': 0.8445044591241199, 'debris Prec': 0.722768815861759, 'debris Rec': 0.9618503256679516, 'debris F1': 0.8253443211953577, 'debris IoU': 0.702626596106229}\n","output_type":"stream"},{"name":"stderr","text":"epoch 31/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0802]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8743773154644945, 'microPrec': 0.9881164446263369, 'weightPrec': 0.9902379802830077, 'macroRec': 0.9690959533744143, 'microRec': 0.9881164446263369, 'weightRec': 0.9881164446263369, 'macroF1': 0.9159431688365186, 'microF1': 0.9881164446263369, 'weightF1': 0.9887833362441051, 'subsetAcc': 0.9881164446263369, 'IoU': 0.8544952327980947, 'debris Prec': 0.7504863046106934, 'debris Rec': 0.9487571447560813, 'debris F1': 0.8380544221680805, 'debris IoU': 0.7212510105092966}\n","output_type":"stream"},{"name":"stderr","text":"epoch 32/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.115] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8704316497316332, 'microPrec': 0.9877567285220407, 'weightPrec': 0.9901051981815776, 'macroRec': 0.9708050540829445, 'microRec': 0.9877567285220407, 'weightRec': 0.9877567285220407, 'macroF1': 0.9140898721378221, 'microF1': 0.9877567285220407, 'weightF1': 0.9884867090250768, 'subsetAcc': 0.9877567285220407, 'IoU': 0.8517111105213999, 'debris Prec': 0.7424634828550709, 'debris Rec': 0.9526784527449156, 'debris F1': 0.8345365626455519, 'debris IoU': 0.7160555500049955}\n","output_type":"stream"},{"name":"stderr","text":"epoch 33/50: 100%|██████████| 120/120 [01:24<00:00,  1.43it/s, loss=0.0689]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7377049180327869\n{'macroPrec': 0.8825735555274734, 'microPrec': 0.9890405057565347, 'weightPrec': 0.9908440032398671, 'macroRec': 0.9706976018504581, 'microRec': 0.9890405057565347, 'weightRec': 0.9890405057565347, 'macroF1': 0.9216852148127805, 'microF1': 0.9890405057565347, 'weightF1': 0.9896061971492343, 'subsetAcc': 0.9890405057565347, 'IoU': 0.8631984346356358, 'debris Prec': 0.7667988425677849, 'debris Rec': 0.9510833444104746, 'debris F1': 0.8490566037735849, 'debris IoU': 0.7377049180327869}\n","output_type":"stream"},{"name":"stderr","text":"epoch 34/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0371]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7531601685423223\n{'macroPrec': 0.8950872103036729, 'microPrec': 0.9900313405348354, 'weightPrec': 0.9912620940866074, 'macroRec': 0.965139243679794, 'microRec': 0.9900313405348354, 'weightRec': 0.9900313405348354, 'macroF1': 0.9270178329478694, 'microF1': 0.9900313405348354, 'weightF1': 0.9904371300826328, 'subsetAcc': 0.9900313405348354, 'IoU': 0.8714393928326117, 'debris Prec': 0.7922464093357271, 'debris Rec': 0.9385218662767513, 'debris F1': 0.8592029205962883, 'debris IoU': 0.7531601685423223}\n","output_type":"stream"},{"name":"stderr","text":"epoch 35/50: 100%|██████████| 120/120 [01:26<00:00,  1.39it/s, loss=0.0207]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8833610933007141, 'microPrec': 0.9891589751322011, 'weightPrec': 0.9909496269007625, 'macroRec': 0.9715938978264104, 'microRec': 0.9891589751322011, 'weightRec': 0.9891589751322011, 'macroF1': 0.9225251424306855, 'microF1': 0.9891589751322011, 'weightF1': 0.9897181390795953, 'subsetAcc': 0.9891589751322011, 'IoU': 0.864482665467103, 'debris Prec': 0.7683155581756793, 'debris Rec': 0.9528113784394523, 'debris F1': 0.85067497403946, 'debris IoU': 0.7401517889410915}\n","output_type":"stream"},{"name":"stderr","text":"epoch 36/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0301]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7640192013964652\n{'macroPrec': 0.9038215568833708, 'microPrec': 0.9906818451066763, 'weightPrec': 0.9915899269057716, 'macroRec': 0.9617817791663529, 'microRec': 0.9906818451066763, 'weightRec': 0.9906818451066763, 'macroF1': 0.9306991474387325, 'microF1': 0.9906818451066763, 'weightF1': 0.9909937595230159, 'subsetAcc': 0.9906818451066763, 'IoU': 0.8772055922495742, 'debris Prec': 0.8099699282905389, 'debris Rec': 0.930878638840888, 'debris F1': 0.8662254932277815, 'debris IoU': 0.7640192013964652}\n","output_type":"stream"},{"name":"stderr","text":"epoch 37/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0458]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8957309499751664, 'microPrec': 0.9899301030683568, 'weightPrec': 0.9910742321165639, 'macroRec': 0.9615539103411433, 'microRec': 0.9899301030683568, 'weightRec': 0.9899301030683568, 'macroF1': 0.9259008993281828, 'microF1': 0.9899301030683568, 'weightF1': 0.9903166005397122, 'subsetAcc': 0.9899301030683568, 'IoU': 0.8697147175701531, 'debris Prec': 0.7937793892697298, 'debris Rec': 0.9312109530772298, 'debris F1': 0.8570205217604061, 'debris IoU': 0.7498126939955047}\n","output_type":"stream"},{"name":"stderr","text":"epoch 38/50: 100%|██████████| 120/120 [01:26<00:00,  1.40it/s, loss=0.0169]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8799498677074367, 'microPrec': 0.9888057209938503, 'weightPrec': 0.9907384342911725, 'macroRec': 0.9715719465139845, 'microRec': 0.9888057209938503, 'weightRec': 0.9888057209938503, 'macroF1': 0.9203960202009596, 'microF1': 0.9888057209938503, 'weightF1': 0.9894076772760377, 'subsetAcc': 0.9888057209938503, 'IoU': 0.861227215628934, 'debris Prec': 0.7614825041151171, 'debris Rec': 0.9531436926757942, 'debris F1': 0.8466011393488592, 'debris IoU': 0.7340055276896305}\n","output_type":"stream"},{"name":"stderr","text":"epoch 39/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0551]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8881983248865344, 'microPrec': 0.9895617710094667, 'weightPrec': 0.9911216353527379, 'macroRec': 0.9696179932666359, 'microRec': 0.9895617710094667, 'weightRec': 0.9895617710094667, 'macroF1': 0.9247090972386096, 'microF1': 0.9895617710094667, 'weightF1': 0.9900569640169333, 'subsetAcc': 0.9895617710094667, 'IoU': 0.867849678539735, 'debris Prec': 0.7781413612565445, 'debris Rec': 0.9482919048252028, 'debris F1': 0.8548319453597747, 'debris IoU': 0.7464685570785812}\n","output_type":"stream"},{"name":"stderr","text":"epoch 40/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0232]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8780982019016205, 'microPrec': 0.9861827548320363, 'weightPrec': 0.9890797376034597, 'macroRec': 0.9820957783029062, 'microRec': 0.9861827548320363, 'weightRec': 0.9861827548320363, 'macroF1': 0.9230724191674662, 'microF1': 0.9861827548320364, 'weightF1': 0.9870173411263389, 'subsetAcc': 0.9861827548320363, 'IoU': 0.8649419230229423, 'debris Prec': 0.7571676733549014, 'debris Rec': 0.9776424228082269, 'debris F1': 0.853395124097949, 'debris IoU': 0.7442800410442793}\n########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.9075192948555281, 'microPrec': 0.9907529267320762, 'weightPrec': 0.991478104920321, 'macroRec': 0.9563905082347819, 'microRec': 0.9907529267320762, 'weightRec': 0.9907529267320762, 'macroF1': 0.9304584328996433, 'microF1': 0.9907529267320762, 'weightF1': 0.9910144472367761, 'subsetAcc': 0.9907529267320762, 'IoU': 0.8768395011503158, 'debris Prec': 0.8177412682465576, 'debris Rec': 0.9196464176525322, 'debris F1': 0.8657052585478775, 'debris IoU': 0.7632101489244346}\n","output_type":"stream"},{"name":"stderr","text":"epoch 41/50: 100%|██████████| 120/120 [01:24<00:00,  1.43it/s, loss=0.0875]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.8952839604947613, 'microPrec': 0.9902251995131985, 'weightPrec': 0.9915214799744941, 'macroRec': 0.9690293857748016, 'microRec': 0.9902251995131985, 'weightRec': 0.9902251995131985, 'macroF1': 0.928741948105257, 'microF1': 0.9902251995131985, 'weightF1': 0.9906420844125626, 'subsetAcc': 0.9902251995131985, 'IoU': 0.874118632344659, 'debris Prec': 0.7923761825264329, 'debris Rec': 0.9463644822544198, 'debris F1': 0.8625514901865763, 'debris IoU': 0.7583213505884859}\n","output_type":"stream"},{"name":"stderr","text":"epoch 42/50: 100%|██████████| 120/120 [01:23<00:00,  1.43it/s, loss=0.0939]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7724853207485046\n{'macroPrec': 0.9068505018323982, 'microPrec': 0.9910695630634027, 'weightPrec': 0.991934982425018, 'macroRec': 0.964262534616777, 'microRec': 0.9910695630634027, 'weightRec': 0.9910695630634027, 'macroF1': 0.9335073594918097, 'microF1': 0.9910695630634027, 'weightF1': 0.9913638005313936, 'subsetAcc': 0.9910695630634027, 'IoU': 0.8816378151796849, 'debris Prec': 0.8158687840500753, 'debris Rec': 0.9355975009969427, 'debris F1': 0.871640866873065, 'debris IoU': 0.7724853207485046}\n","output_type":"stream"},{"name":"stderr","text":"epoch 43/50: 100%|██████████| 120/120 [01:24<00:00,  1.43it/s, loss=0.041] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.9004004328728443, 'microPrec': 0.9908627801531485, 'weightPrec': 0.9920525436669336, 'macroRec': 0.9724100976150197, 'microRec': 0.9908627801531485, 'weightRec': 0.9908627801531485, 'macroF1': 0.9331832593499751, 'microF1': 0.9908627801531485, 'weightF1': 0.9912396035534972, 'subsetAcc': 0.9908627801531485, 'IoU': 0.8811062525062181, 'debris Prec': 0.8023958799820868, 'debris Rec': 0.9526784527449156, 'debris F1': 0.8711030082041933, 'debris IoU': 0.771640826873385}\n","output_type":"stream"},{"name":"stderr","text":"epoch 44/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0625] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8620085478142754, 'microPrec': 0.987026526370206, 'weightPrec': 0.9899672937005716, 'macroRec': 0.9766908035736306, 'microRec': 0.987026526370206, 'weightRec': 0.987026526370206, 'macroF1': 0.9107850897172387, 'microF1': 0.987026526370206, 'weightF1': 0.9879128068239652, 'subsetAcc': 0.987026526370206, 'IoU': 0.8467729492103169, 'debris Prec': 0.7251809333666084, 'debris Rec': 0.9656387079622492, 'debris F1': 0.828311621675551, 'debris IoU': 0.7069384974698326}\n","output_type":"stream"},{"name":"stderr","text":"epoch 45/50: 100%|██████████| 120/120 [01:24<00:00,  1.42it/s, loss=0.0642]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8969738770283824, 'microPrec': 0.9903716707412952, 'weightPrec': 0.9916062246226109, 'macroRec': 0.9687196541021247, 'microRec': 0.9903716707412952, 'weightRec': 0.9903716707412952, 'macroF1': 0.9296208165289639, 'microF1': 0.9903716707412952, 'weightF1': 0.9907705440407552, 'subsetAcc': 0.9903716707412952, 'IoU': 0.8754957485713919, 'debris Prec': 0.7957825260096207, 'debris Rec': 0.9455669280871992, 'debris F1': 0.8642327785202283, 'debris IoU': 0.7609242124404985}\n","output_type":"stream"},{"name":"stderr","text":"epoch 46/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.15]  \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7822445561139029\n{'macroPrec': 0.913977861948952, 'microPrec': 0.9915994442709287, 'weightPrec': 0.9922586310088195, 'macroRec': 0.9623844194035636, 'microRec': 0.9915994442709287, 'weightRec': 0.9915994442709287, 'macroF1': 0.9367348672878955, 'microF1': 0.9915994442709287, 'weightF1': 0.9918314228216473, 'subsetAcc': 0.9915994442709287, 'IoU': 0.8867913026990908, 'debris Prec': 0.8302714234917625, 'debris Rec': 0.9311444902299615, 'debris F1': 0.8778195488721805, 'debris IoU': 0.7822445561139029}\n","output_type":"stream"},{"name":"stderr","text":"epoch 47/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0509]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8920227921590127, 'microPrec': 0.9900916522169928, 'weightPrec': 0.9915793958635847, 'macroRec': 0.9731036435050082, 'microRec': 0.9900916522169928, 'weightRec': 0.9900916522169928, 'macroF1': 0.9284361866689637, 'microF1': 0.9900916522169928, 'weightF1': 0.9905558005377626, 'subsetAcc': 0.9900916522169928, 'IoU': 0.8736307514614778, 'debris Prec': 0.7855658829961728, 'debris Rec': 0.9549381895520405, 'debris F1': 0.8620110391168707, 'debris IoU': 0.7574862927035007}\n","output_type":"stream"},{"name":"stderr","text":"epoch 48/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.106] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.9114801763291949, 'microPrec': 0.9912978858601416, 'weightPrec': 0.9919899356706094, 'macroRec': 0.9605905537785565, 'microRec': 0.9912978858601416, 'weightRec': 0.9912978858601416, 'macroF1': 0.9345389633220893, 'microF1': 0.9912978858601416, 'weightF1': 0.9915428844362503, 'subsetAcc': 0.9912978858601416, 'IoU': 0.8832856047250235, 'debris Prec': 0.8253902554399243, 'debris Rec': 0.9277548850192743, 'debris F1': 0.8735840791038239, 'debris IoU': 0.7755430857269848}\n","output_type":"stream"},{"name":"stderr","text":"epoch 49/50: 100%|██████████| 120/120 [01:25<00:00,  1.40it/s, loss=0.0932]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.903135654382996, 'microPrec': 0.9910587931201602, 'weightPrec': 0.9921424644556822, 'macroRec': 0.9711624158180606, 'microRec': 0.9910587931201602, 'weightRec': 0.9910587931201602, 'macroF1': 0.934279926534437, 'microF1': 0.9910587931201602, 'weightF1': 0.9914065557832722, 'subsetAcc': 0.9910587931201602, 'IoU': 0.8828514770316065, 'debris Prec': 0.8079597489965515, 'debris Rec': 0.9498870131596437, 'debris F1': 0.873193829234764, 'debris IoU': 0.7749281570243453}\n","output_type":"stream"},{"name":"stderr","text":"epoch 50/50: 100%|██████████| 120/120 [01:26<00:00,  1.38it/s, loss=0.00916]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8857288565050285, 'microPrec': 0.9872454896198194, 'weightPrec': 0.9897289613961839, 'macroRec': 0.982896126741839, 'microRec': 0.9872454896198194, 'weightRec': 0.9872454896198194, 'macroF1': 0.9282503790903758, 'microF1': 0.9872454896198194, 'weightF1': 0.9879583886924932, 'subsetAcc': 0.9872454896198194, 'IoU': 0.8730097176301508, 'debris Prec': 0.7724056124728842, 'debris Rec': 0.9781568631485806, 'debris F1': 0.8631898164121375, 'debris IoU': 0.7593086593294252}\n########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8782841985632883, 'microPrec': 0.9888789566078987, 'weightPrec': 0.991022252788304, 'macroRec': 0.9776159233851675, 'microRec': 0.9888789566078987, 'weightRec': 0.9888789566078987, 'macroF1': 0.9216728109931687, 'microF1': 0.9888789566078987, 'weightF1': 0.9895239253150581, 'subsetAcc': 0.9888789566078987, 'IoU': 0.8631593482084969, 'debris Prec': 0.7577322276117456, 'debris Rec': 0.9655722451149807, 'debris F1': 0.8491189105467722, 'debris IoU': 0.7377989944644762}\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"\n\n# # Save everything in a checkpoint\n# checkpoint = {\n#     'model_state_dict': model.state_dict(),\n#     'optimizer_state_dict': optimizer.state_dict(),\n#     'scheduler_state_dict': scheduler.state_dict(),\n#     'epoch': 10  # Optional: Save the epoch number\n# }\n\n# torch.save(checkpoint, 'model_checkpoint_8_epochs_bs16_iou075.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:31:52.468860Z","iopub.execute_input":"2025-05-25T20:31:52.469092Z","iopub.status.idle":"2025-05-25T20:31:52.473024Z","shell.execute_reply.started":"2025-05-25T20:31:52.469075Z","shell.execute_reply":"2025-05-25T20:31:52.472416Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"output_classes = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:31:52.473873Z","iopub.execute_input":"2025-05-25T20:31:52.474070Z","iopub.status.idle":"2025-05-25T20:31:52.487859Z","shell.execute_reply.started":"2025-05-25T20:31:52.474055Z","shell.execute_reply":"2025-05-25T20:31:52.487098Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Load the saved state_dict\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device))\nmodel = model.to(device)\n# Set the model to evaluation mode\nmodel.eval()\n\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\nempty_df =  pd.DataFrame(columns=marida_test_df.columns)\nmarida_test_ds = MergedSegmentationDataset_B(marida_test_df, empty_df, global_bands_mean, global_bands_std, selected_bands, transform=transformTest, standardization= standardization )\n\nmarida_testLoader = DataLoader(marida_test_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn,\n                        #worker_init_fn=worker_init_fn,\n                        #generator=torch.Generator().manual_seed(seed) \n                        )\n\ntest_metrics_history = []\nmodel.eval()\nyTrue = []\nyPredicted = []\ntestLossF = []\nwith torch.no_grad():\n    for image, target, _ in marida_testLoader:\n\n        image, target = image.to(device), target.to(device)\n        logits = model(image)\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        # print(f'test - target shape {target.shape}')\n        #print(f'test - logit shape {logits.shape}')\n        loss = criterion(logits, target)\n\n        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n        logits = logits.reshape((-1,output_classes))\n        target = target.reshape(-1)\n        ###################################################################################\n        mask = target != -1\n        ###################################################################################\n        \n        # bg_logits = logits[~mask]\n        # bg_target = target[~mask]\n        \n        logits = logits[mask]\n        target = target[mask]\n        \n\n        probs = F.softmax(logits, dim=1).cpu().numpy()\n        ########### threshold #########\n        probs[probs[:, 1] < 0.8] = 0.\n        ###############################\n        print(f'test - probs shape {probs.shape}')\n        target = target.cpu().numpy()\n        # testBatches += target.shape[0]\n        testLossF.append((loss.data*target.shape[0]).tolist())\n        yPredicted += probs.argmax(1).tolist()\n        yTrue += target.tolist()\n\n\n        # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n        # bg_target = bg_target.cpu().numpy()\n\n        # bg_yPredicted += bg_probs.argmax(1).tolist()\n        # bg_yTrue += bg_target.tolist()\n    \n    yPredicted = np.asarray(yPredicted)\n    yTrue = np.asarray(yTrue)\n    acc = Evaluation(yPredicted, yTrue)\n    test_metrics_history.append(acc)\n\n\n    # bg_yPredicted = np.asarray(bg_yPredicted)\n    # bg_yTrue = np.asarray(bg_yTrue)\n    # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n    print(acc)\n                    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:44:05.689420Z","iopub.execute_input":"2025-05-25T20:44:05.689893Z","iopub.status.idle":"2025-05-25T20:44:19.227238Z","shell.execute_reply.started":"2025-05-25T20:44:05.689869Z","shell.execute_reply":"2025-05-25T20:44:19.226426Z"}},"outputs":[{"name":"stdout","text":"test - probs shape (13343, 2)\ntest - probs shape (3144, 2)\ntest - probs shape (11192, 2)\ntest - probs shape (4456, 2)\ntest - probs shape (4984, 2)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1683949948.py:4: RuntimeWarning: invalid value encountered in less\n  invalid_mask |= image < -1.5\n/tmp/ipykernel_35/1683949948.py:5: RuntimeWarning: invalid value encountered in greater\n  invalid_mask |= image > 1.5\n","output_type":"stream"},{"name":"stdout","text":"test - probs shape (589, 2)\ntest - probs shape (6638, 2)\ntest - probs shape (1737, 2)\ntest - probs shape (19586, 2)\ntest - probs shape (12855, 2)\ntest - probs shape (2904, 2)\ntest - probs shape (5307, 2)\ntest - probs shape (3079, 2)\ntest - probs shape (14738, 2)\ntest - probs shape (5915, 2)\ntest - probs shape (19936, 2)\ntest - probs shape (2145, 2)\ntest - probs shape (18336, 2)\ntest - probs shape (24205, 2)\ntest - probs shape (5307, 2)\ntest - probs shape (12354, 2)\ntest - probs shape (1777, 2)\ntest - probs shape (336, 2)\n{'macroPrec': 0.9432830944027024, 'microPrec': 0.9966591913292929, 'weightPrec': 0.996584548472167, 'macroRec': 0.9195873148561116, 'microRec': 0.9966591913292929, 'weightRec': 0.9966591913292929, 'macroF1': 0.9311008973712369, 'microF1': 0.9966591913292929, 'weightF1': 0.9966133198378344, 'subsetAcc': 0.9966591913292929, 'IoU': 0.8785104443412077, 'debris Prec': 0.8886021505376344, 'debris Rec': 0.8405207485760781, 'debris F1': 0.8638929542128371, 'debris IoU': 0.7603974972396025}\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"! cp best_model.pth model_50_epochs_ratio_1_20_bs16_test_iou_debris_076_thr0.8.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:45:02.084691Z","iopub.execute_input":"2025-05-25T20:45:02.085205Z","iopub.status.idle":"2025-05-25T20:45:02.315907Z","shell.execute_reply.started":"2025-05-25T20:45:02.085182Z","shell.execute_reply":"2025-05-25T20:45:02.314855Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# All black\n# /kaggle/input/litter-windrows-patches/patches/S2A_MSIL1C_20180916T101021_R022_T33TUL/S2A_MSIL1C_20180916T101021_R022_T33TUL_366560_5053920.tif","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:32:23.233145Z","iopub.execute_input":"2025-05-25T20:32:23.233343Z","iopub.status.idle":"2025-05-25T20:32:23.247170Z","shell.execute_reply.started":"2025-05-25T20:32:23.233328Z","shell.execute_reply":"2025-05-25T20:32:23.246550Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"#Lightning implementation. To be used later.\n\n# class BinaryClassificationModel(pl.LightningModule):\n#     def __init__(self, hparams):\n#         super().__init__()\n#         self.save_hyperparameters(hparams)\n\n#         # Model selection\n#         if hparams.model_name == \"resattunet\":\n#             self.model = ResidualAttentionUNet(11, 11)\n#             # Modify for binary classification\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)  # Binary output\n#             )\n#         elif hparams.model_name == \"attunet\":\n#             self.model = AttentionUNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         elif hparams.model_name == \"unet\":\n#             self.model = UNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         else:\n#             raise ValueError(\"Invalid model name\")\n\n#         # Loss function\n#         if hparams.focal_loss:\n#             self.criterion = FocalLoss()\n#         else:\n#             weight = gen_weights(class_distr, c=1.03)[:2]  # Binary classes\n#             self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=-1)\n\n#         # Track best metrics\n#         self.best_macro_f1 = 0.0\n#         self.best_micro_f1 = 0.0\n#         self.best_weight_f1 = 0.0\n\n#     def forward(self, x):\n#         return self.model(x)\n\n#     def training_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n#         return loss\n\n#     def validation_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         probs = torch.softmax(logits, dim=1).cpu().numpy()\n#         labels = labels.cpu().numpy()\n#         preds = probs.argmax(1)\n#         return {\"loss\": loss, \"preds\": preds.tolist(), \"labels\": labels.tolist()}\n\n#     def validation_epoch_end(self, outputs):\n#         preds = np.concatenate([o[\"preds\"] for o in outputs])\n#         labels = np.concatenate([o[\"labels\"] for o in outputs])\n#         loss = torch.stack([o[\"loss\"] for o in outputs]).mean()\n#         acc = Evaluation(preds, labels)\n\n#         self.log(\"val_loss\", loss, prog_bar=True)\n#         self.log(\"val_macro_precision\", acc[\"macroPrec\"], prog_bar=True)\n#         self.log(\"val_macro_recall\", acc[\"macroRec\"])\n#         self.log(\"val_macro_f1\", acc[\"macroF1\"])\n#         self.log(\"val_micro_precision\", acc[\"microPrec\"])\n#         self.log(\"val_micro_recall\", acc[\"microRec\"])\n#         self.log(\"val_micro_f1\", acc[\"microF1\"])\n#         self.log(\"val_weight_precision\", acc[\"weightPrec\"])\n#         self.log(\"val_weight_recall\", acc[\"weightRec\"])\n#         self.log(\"val_weight_f1\", acc[\"weightF1\"])\n#         self.log(\"val_iou\", acc[\"IoU\"])\n\n#         # Update best metrics\n#         if acc[\"macroF1\"] > self.best_macro_f1:\n#             self.best_macro_f1 = acc[\"macroF1\"]\n#         if acc[\"microF1\"] > self.best_micro_f1:\n#             self.best_micro_f1 = acc[\"microF1\"]\n#         if acc[\"weightF1\"] > self.best_weight_f1:\n#             self.best_weight_f1 = acc[\"weightF1\"]\n\n#     def configure_optimizers(self):\n#         optimizer = optim.Adam(\n#             self.parameters(),\n#             lr=self.hparams.initial_lr,\n#             weight_decay=self.hparams.decay_lr\n#         )\n#         if self.hparams.scheduler_lr == \"rop\":\n#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#                 optimizer, mode=\"min\", factor=0.1, patience=10, verbose=True\n#             )\n#             return {\n#                 \"optimizer\": optimizer,\n#                 \"lr_scheduler\": scheduler,\n#                 \"monitor\": \"val_loss\"\n#             }\n#         else:\n#             scheduler = optim.lr_scheduler.MultiStepLR(\n#                 optimizer, milestones=[40, 80, 120, 160], gamma=0.5, verbose=True\n#             )\n#             return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n#     def train_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             RandomRotationTransform([-90, 0, 90, 180]),\n#             transforms.RandomHorizontalFlip(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.train_batch_size,\n#             shuffle=True,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n#     def val_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.test_batch_size,\n#             shuffle=False,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n# def seed_worker(worker_id):\n#     worker_seed = torch.initial_seed() % 2**32\n#     np.random.seed(worker_seed)\n#     random.seed(worker_seed)\n\n# def main():\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('--train_batch_size', type=int, default=8)\n#     parser.add_argument('--test_batch_size', type=int, default=4)\n#     parser.add_argument('--total_epochs', type=int, default=50)\n#     parser.add_argument('--experiment_name', type=str, required=True)\n#     parser.add_argument('--initial_lr', type=float, default=1e-3)\n#     parser.add_argument('--decay_lr', type=float, default=0)\n#     parser.add_argument('--scheduler_lr', type=str, default=\"ms\")\n#     parser.add_argument('--focal_loss', type=bool, default=False)\n#     parser.add_argument('--model_name', type=str, default=\"resattunet\")\n#     args = parser.parse_args()\n\n#     # Set seeds for reproducibility\n#     pl.seed_everything(0, workers=True)\n\n#     # Initialize model\n#     model = BinaryClassificationModel(args)\n\n#     # Logger\n#     logger = TensorBoardLogger(save_dir=args.experiment_name, name=\"logs\")\n\n#     # Callbacks for saving best models\n#     checkpoint_macro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMacroF1Model\",\n#         monitor=\"val_macro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_micro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMicroF1Model\",\n#         monitor=\"val_micro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_weight = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestWeightF1Model\",\n#         monitor=\"val_weight_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n\n#     # Trainer\n#     trainer = pl.Trainer(\n#         max_epochs=args.total_epochs,\n#         accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n#         devices=1,\n#         logger=logger,\n#         callbacks=[checkpoint_macro, checkpoint_micro, checkpoint_weight],\n#         deterministic=True\n#     )\n\n#     # Train\n#     trainer.fit(model)\n\n# # if __name__ == \"__main__\":\n# #     main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T20:32:23.247827Z","iopub.execute_input":"2025-05-25T20:32:23.247993Z","iopub.status.idle":"2025-05-25T20:32:23.261313Z","shell.execute_reply.started":"2025-05-25T20:32:23.247980Z","shell.execute_reply":"2025-05-25T20:32:23.260636Z"}},"outputs":[],"execution_count":55}]}