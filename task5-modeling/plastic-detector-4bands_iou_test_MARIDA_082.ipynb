{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9438808,"sourceType":"datasetVersion","datasetId":5735509},{"sourceId":11885707,"sourceType":"datasetVersion","datasetId":7401788}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import multiprocessing as mp\n# mp.set_start_method('spawn')  # Set before any other imports or operations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:06.192745Z","iopub.execute_input":"2025-05-27T21:18:06.193439Z","iopub.status.idle":"2025-05-27T21:18:06.196488Z","shell.execute_reply.started":"2025-05-27T21:18:06.193411Z","shell.execute_reply":"2025-05-27T21:18:06.195770Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"#bands 4.6.8.11","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:06.197439Z","iopub.execute_input":"2025-05-27T21:18:06.197720Z","iopub.status.idle":"2025-05-27T21:18:06.212781Z","shell.execute_reply.started":"2025-05-27T21:18:06.197696Z","shell.execute_reply":"2025-05-27T21:18:06.211997Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"! ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:06.213741Z","iopub.execute_input":"2025-05-27T21:18:06.213969Z","iopub.status.idle":"2025-05-27T21:18:06.369866Z","shell.execute_reply.started":"2025-05-27T21:18:06.213945Z","shell.execute_reply":"2025-05-27T21:18:06.369100Z"}},"outputs":[{"name":"stdout","text":"best_model.pth\nglobal_stats.npz\nlitter_rows_df_invalid_info.csv\nlitter_rows_val_df_invalid_info.csv\nmarida_df_invalid_info.csv\nmarida_test_df_invalid_info.csv\nmarida_val_df_invalid_info.csv\nmodel_30_epochs_ratio_1_20_bs16_iou_081.pth\nmodel_30_epochs_ratio_1_40_bs16_iou_0819.pth\nmodel_50_epochs_ratio_1_20_bs16_test_iou_debris_076_thr0.8.pth\nmodel_60_epochs_ratio_1_15_bs16_test_iou_debris_079_thr0.7.pth\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"#%%capture\n! pip install rasterio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:06.371000Z","iopub.execute_input":"2025-05-27T21:18:06.371311Z","iopub.status.idle":"2025-05-27T21:18:09.339246Z","shell.execute_reply.started":"2025-05-27T21:18:06.371276Z","shell.execute_reply":"2025-05-27T21:18:09.338522Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (1.4.3)\nRequirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.4.0)\nRequirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\nRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.1.8)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.26.4)\nRequirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio) (1.1.1)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.0.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24->rasterio) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24->rasterio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24->rasterio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24->rasterio) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24->rasterio) (2024.2.0)\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport sys\nimport shutil\nimport re\nfrom PIL import Image\nimport rasterio\nimport matplotlib.pyplot as plt\nimport dask.array as da\nfrom scipy.ndimage import binary_dilation\nfrom skimage.morphology import disk  # For circular structuring elements\nimport torch\nfrom torchvision import transforms\nimport torchvision.transforms.functional as vF\nimport torch.nn.functional as F\nimport gdown\nfrom tqdm import tqdm\nimport random\n\nfrom sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, jaccard_score, hamming_loss, label_ranking_loss, coverage_error, classification_report\nimport sklearn.metrics as metr\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.341294Z","iopub.execute_input":"2025-05-27T21:18:09.341556Z","iopub.status.idle":"2025-05-27T21:18:09.347070Z","shell.execute_reply.started":"2025-05-27T21:18:09.341527Z","shell.execute_reply":"2025-05-27T21:18:09.346570Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", None)  # Show full column values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.347965Z","iopub.execute_input":"2025-05-27T21:18:09.348365Z","iopub.status.idle":"2025-05-27T21:18:09.371478Z","shell.execute_reply.started":"2025-05-27T21:18:09.348339Z","shell.execute_reply":"2025-05-27T21:18:09.370671Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nfrom torch.utils.data import DataLoader, Dataset\n\ndef set_seed(seed):\n    \"\"\"\n    Set random seeds for NumPy, PyTorch (CPU and GPU), and Python's random module.\n    \n    Args:\n        seed (int): Seed value for RNGs\n    \"\"\"\n    # Python random\n    random.seed(seed)\n    \n    # NumPy\n    np.random.seed(seed)\n    \n    # PyTorch CPU\n    torch.manual_seed(seed)\n    \n    # PyTorch GPU (CUDA)\n    torch.cuda.manual_seed(seed)  # Current GPU\n    torch.cuda.manual_seed_all(seed)  # All GPUs\n    \n    # Ensure deterministic behavior\n    #torch.use_deterministic_algorithms(True)\n    #torch.backends.cudnn.deterministic = True\n    #torch.backends.cudnn.benchmark = False\n\ndef worker_init_fn(worker_id):\n    \"\"\"\n    Initialize random seed for DataLoader workers.\n    Ensures each worker has a unique but reproducible RNG state.\n    \n    Args:\n        worker_id (int): Worker ID\n    \"\"\"\n    max_seed = 2**32 - 1  # NumPy seed limit\n    worker_seed = (torch.initial_seed() + worker_id) % max_seed\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.372128Z","iopub.execute_input":"2025-05-27T21:18:09.372366Z","iopub.status.idle":"2025-05-27T21:18:09.387313Z","shell.execute_reply.started":"2025-05-27T21:18:09.372351Z","shell.execute_reply":"2025-05-27T21:18:09.386592Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"def create_LR_dataframe(splits_path, mode='train'):\n    split_images_files = {'train' : 'train_X.txt', 'val' : 'val_X.txt', 'test' : 'test_X.txt'}\n    split_masks_files = {'train' : 'train_masks.txt', 'val' : 'val_masks.txt', 'test' : 'test_masks.txt'}  \n    with open(os.path.join(splits_path, split_images_files[mode]), \"r\") as file:\n        images = file.readlines()  # Reads all lines into a list\n        images = [image.strip() for image in images]  # Remove any trailing newline characters\n    with open(os.path.join(splits_path, split_masks_files[mode]), \"r\") as file:\n        masks = file.readlines()  # Reads all lines into a list\n        masks = [mask.strip() for mask in masks]  # Remove any trailing newline characters\n    df = pd.DataFrame({'image' : images, 'mask' : masks})\n    return df\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.388209Z","iopub.execute_input":"2025-05-27T21:18:09.388488Z","iopub.status.idle":"2025-05-27T21:18:09.404913Z","shell.execute_reply.started":"2025-05-27T21:18:09.388466Z","shell.execute_reply":"2025-05-27T21:18:09.404422Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# from Sagar and Navodita's code\ndef compute_fdi_from_tiff(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        # Assuming band order follows your stacked TIFF (B1â€“B12, skipping B10 if needed)\n        # Band indices are 1-based in rasterio\n        R665 = src.read(4)    # B4\n        R859 = src.read(9)    # B8A\n        R1610 = src.read(10)  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        return FDI\n\ndef cvt_to_fdi(images):\n    fdi_images = []\n    batch = images.copy()\n    if len(images.shape) == 3 : \n        batch = batch[None, :]\n    for i in range(batch.shape[0]):\n        im = batch[i]\n        R665 = im[3]   # B4\n        R859 = im[8]   # B8A\n        R1610 = im[0]  # B11\n        # Convert to float and mask invalid values\n        R665 = R665.astype(np.float32)\n        R859 = R859.astype(np.float32)\n        R1610 = R1610.astype(np.float32)\n        # Calculate FDI\n        FDI = R859 - (R665 + ((R1610 - R665) * (859 - 665) / (1610 - 665)))\n        fdi_images.append(FDI)\n    return np.array(fdi_images)\n    \ndef compute_ndwi(tiff_path):\n    with rasterio.open(tiff_path) as src:\n        Rgreen = src.read(3).astype(np.float32)  # Band 3 (Green)\n        Rnir = src.read(8).astype(np.float32)    # Band 8 (NIR)\n        ndwi = (Rgreen - Rnir) / (Rgreen + Rnir + 1e-6)  # avoid divide-by-zero\n    return ndwi\ndef plot_fdi(fdi_array, ndwi, img_path, mask_path):\n    with rasterio.open(img_path) as src:\n        rgb = src.read([4, 3, 2])\n        rgb = np.transpose(rgb, (1, 2, 0))\n    # Normalization\n    rgb = rgb.astype(np.float32)\n    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n    with rasterio.open(mask_path) as src:\n        mask = src.read(1)\n    # Create binary mask\n    mask_binary = mask > 0\n    # Plot side-by-side\n    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n    axs[0].imshow(rgb)\n    axs[0].set_title(\"RGB Patch\")\n    axs[1].imshow(mask_binary)  #, cmap='gray')\n    axs[1].set_title(\"Binary Mask (._cl.tif)\")\n    axs[2].imshow(fdi_array)\n    axs[2].set_title(\"FDI\")\n    axs[3].imshow(ndwi)\n    axs[3].set_title(\"NDWI\")\n    for ax in axs:\n        ax.axis('off')\n\n    # with rasterio.open(patch_path) as patch_src:\n    #     rgb = patch_src.read([4, 3, 2])  # Use bands B4, B3, B2 for RGB\n    #     rgb = np.transpose(rgb, (1, 2, 0))\n    #     rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n    import matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\n# List of image and mask file paths (replace with your file paths)\nimage_mask_pairs = [\n    ('path_to_image1.jpg', 'path_to_mask1.png'),\n    ('path_to_image2.jpg', 'path_to_mask2.png'),\n    # Add more pairs as needed\n]\n\n\ndef cvt_RGB(images):\n    rgb_images = []\n    for i in range(images.shape[0]):\n        rgb = images[i][[4-1, 3-1, 2-1]] # Use bands B4, B3, B2 for RGB\n        rgb = np.transpose(rgb, (1, 2, 0))\n        rgb = (rgb - np.min(rgb)) / (np.max(rgb) - np.min(rgb) + 1e-6)\n        rgb_images.append(rgb)\n    return np.array(rgb_images)\n\ndef display(images, masks):\n    # Determine the number of pairs\n    num_pairs = images.shape[0]\n\n    # Calculate layout: use 2 columns per pair (image + mask), adjust rows dynamically\n    cols = 2  # One column for image, one for mask\n    rows = num_pairs  # One row per pair\n\n    # Create a figure with subplots\n    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n\n    # Handle case of single pair (axes is not a 2D array)\n    if num_pairs == 1:\n        axes = np.array([axes]).reshape(1, -1)\n\n    # Iterate through each pair and display image and mask\n    for idx, (image, mask) in enumerate(zip(images, masks)):\n\n        # Display the original image\n        axes[idx, 0].imshow(image)\n        axes[idx, 0].set_title(f'Image {idx + 1}')\n        axes[idx, 0].axis('off')  # Hide axes\n    \n        # Display the segmentation mask\n        axes[idx, 1].imshow(mask, cmap='gray')  # Adjust cmap if needed\n        axes[idx, 1].set_title(f'Mask {idx + 1}')\n        axes[idx, 1].axis('off')  # Hide axes\n\n    # Adjust layout to prevent overlap\n    plt.tight_layout()\n    \n    # Show the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.405760Z","iopub.execute_input":"2025-05-27T21:18:09.406004Z","iopub.status.idle":"2025-05-27T21:18:09.428845Z","shell.execute_reply.started":"2025-05-27T21:18:09.405986Z","shell.execute_reply":"2025-05-27T21:18:09.428289Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"\ndef extract_date_tile(filename):\n    \"\"\"Extract date and tile from filename using regex.\"\"\"\n    pattern = r'^(\\d{1,2}-\\d{1,2}-\\d{2})_([A-Z0-9]+)_\\d+$'\n    match = re.match(pattern, filename)\n    if not match:\n        raise ValueError(f\"Invalid filename format: {filename}\")\n    return match.groups()  # Returns tuple (date, tile)\n\ndef create_marida_df(data_path, mode='train'):\n    \"\"\"Create DataFrame from MARIDA dataset files.\"\"\"\n    # Determine split file based on mode\n    split_files = {'train': 'train_X.txt', 'val': 'val_X.txt', 'test': 'test_X.txt'}\n    items_list_path = os.path.join(data_path, 'splits', split_files[mode])\n\n    # Read items list\n    with open(items_list_path, 'r') as file:\n        items = [item.strip() for item in file]\n\n    # Base path for patches\n    items_path = os.path.join(data_path, 'patches')\n\n    # Prepare data lists\n    data = {\n        'image': [],\n        'mask': [],\n        'confidence': [],\n        'date': [],\n        'tile': []\n    }\n\n    # Process each item\n    for item in items:\n        tile = \"_\".join(item.split(\"_\")[:-1])\n        tile_path = os.path.join(items_path, f\"S2_{tile}\")\n\n        # Define file paths\n        base_name = f'S2_{item}'\n        paths = {\n            'image': os.path.join(tile_path, f'{base_name}.tif'),\n            'mask': os.path.join(tile_path, f'{base_name}_cl.tif'),\n            'confidence': os.path.join(tile_path, f'{base_name}_conf.tif')\n        }\n\n        # Check if all files exist\n        if all(os.path.exists(p) for p in paths.values()):\n            data['image'].append(paths['image'])\n            data['mask'].append(paths['mask'])\n            data['confidence'].append(paths['confidence'])\n            date, tile = extract_date_tile(item)\n            data['date'].append(date)\n            data['tile'].append(tile)\n\n    return pd.DataFrame(data)\n\n# MARIDA labels dictionary\nMARIDA_LABELS = {\n    i: label for i, label in enumerate([\n        'Marine Debris', 'Dense Sargassum', 'Sparse Sargassum', 'Natural Organic Material',\n        'Ship', 'Clouds', 'Marine Water', 'Sediment-Laden Water', 'Foam', 'Turbid Water',\n        'Shallow Water', 'Waves', 'Cloud Shadows', 'Wakes', 'Mixed Water'\n    ], 1)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.429407Z","iopub.execute_input":"2025-05-27T21:18:09.429612Z","iopub.status.idle":"2025-05-27T21:18:09.443411Z","shell.execute_reply.started":"2025-05-27T21:18:09.429596Z","shell.execute_reply":"2025-05-27T21:18:09.442746Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"import rasterio\nimport numpy as np\n\ndef compute_invalid_pixels(image_paths, mask_paths):\n    \"\"\"\n    Compute per-band statistics for Sentinel-2 L1C ACOLITE-processed images using segmentation masks.\n    Creates a mask to exclude invalid pixels (NaNs, negative values, specified no-data value).\n    \n    Parameters:\n    - image_paths: List of paths to image files (e.g., GeoTIFF with 11 bands).\n    - mask_paths: List of paths to segmentation mask files (single-band, integer class labels).\n    - class_labels: List of mask class labels to include (e.g., [1, 2] for vegetation and water).\n                   If None, include all non-zero labels (excluding background).\n    - invalid_value: Optional value to treat as invalid in images (e.g., -9999).\n    \n    Returns:\n    - mean_per_band: List of per-band means for each image.\n    - std_per_band: List of per-band standard deviations for each image.\n    \"\"\"\n    mean_per_band = []  # Initialize as list\n    std_per_band = []   # Initialize as list\n    positive_pixels = []\n    tot_pixels = [];\n    images_with_invalid_pixels = []\n    black_list = []\n    accumulator = None\n    no_data_pixels = []\n    neg_pixels = []\n    nan_pixels = []\n    gt1_pixels = []\n    imgs_with_invalid = []\n    positive_pixels = []\n    min_vals = []\n    max_vals = []\n    for img_path, mask_path in zip(image_paths, mask_paths):\n        # Load image and mask\n        with rasterio.open(img_path) as src_img, rasterio.open(mask_path) as src_mask:\n            image = src_img.read()  # Shape: (bands, height, width)\n            mask = src_mask.read(1)  # Shape: (height, width)\n            \n            # Convert image to float for NaN handling\n            image = image.astype(float)\n\n            nan_mask = np.isnan(image)\n            neg_mask = (image < 0)\n            too_big_mask = (image > 1)\n            no_data_mask = (image == src_img.nodata)\n            nan_pixels.append(np.sum(nan_mask))\n            neg_pixels.append(np.sum(neg_mask))\n            gt1_pixels.append(np.sum(too_big_mask))\n            no_data_pixels.append(np.sum(no_data_mask))\n            imgs_with_invalid.append(img_path)\n            positive_pixels.append(np.sum(mask > 0))\n            min_vals.append(np.min(image))\n            max_vals.append(np.max(image))\n    df = pd.DataFrame({'image' : imgs_with_invalid, 'no data pixels' : no_data_pixels, 'negative pixels' : neg_pixels,\n                      'nan pixels' : nan_pixels, 'high value pixels' :  gt1_pixels, 'debris pixels' : positive_pixels,\n                      'min values' : min_vals, 'max values' : max_vals})\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.445870Z","iopub.execute_input":"2025-05-27T21:18:09.446080Z","iopub.status.idle":"2025-05-27T21:18:09.464528Z","shell.execute_reply.started":"2025-05-27T21:18:09.446061Z","shell.execute_reply":"2025-05-27T21:18:09.463831Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#Setting batch size\nbatch_size = 16","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.465203Z","iopub.execute_input":"2025-05-27T21:18:09.465366Z","iopub.status.idle":"2025-05-27T21:18:09.484873Z","shell.execute_reply.started":"2025-05-27T21:18:09.465353Z","shell.execute_reply":"2025-05-27T21:18:09.484295Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"def compute_stats(image_files, discard_negatives = False, discard_gt_1 = False):\n    bands_std = []\n    bands_mean = []\n    valid_pixels = []\n\n    for band_idx in range(11):\n        arrays = [da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto')\n                  for f in image_files]\n        stack = da.stack(arrays)\n        #valid = (stack != rasterio.open(image_files[0]).nodata) & (stack >= 0)\n        if discard_negatives and  discard_gt_1: \n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) & \n                              (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1) \n                              for f in image_files])\n        elif discard_gt_1 :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                              & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') <= 1)  \n                              for f in image_files])\n        elif discard_negatives:\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  & (da.from_array(rasterio.open(f).read(band_idx + 1), chunks='auto') >= 0) \n                  for f in image_files])\n        else :\n            valid = da.stack([da.from_array(rasterio.open(f).read(band_idx + 1) != rasterio.open(f).nodata, chunks='auto')\n                  for f in image_files])\n                         \n        # Compute number of valid pixels\n        valid_count = da.sum(valid).compute()\n        valid_pixels.append(valid_count)\n        mean = da.nanmean(stack[valid]).compute()\n        std = da.nanstd(stack[valid]).compute()\n        bands_mean.append(mean)\n        bands_std.append(std)\n        print(f\"Band {band_idx} - Mean: {mean}, Std: {std}\")\n    return {'mean' : np.array(bands_mean), 'std': np.array(bands_std),'valid pixels' : np.array(valid_pixels) }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.485579Z","iopub.execute_input":"2025-05-27T21:18:09.485749Z","iopub.status.idle":"2025-05-27T21:18:09.500916Z","shell.execute_reply.started":"2025-05-27T21:18:09.485730Z","shell.execute_reply":"2025-05-27T21:18:09.500347Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def computing_labeled_pixels_stats(mask_paths):\n    arrays = [da.from_array(rasterio.open(f).read(1), chunks='auto')\n                  for f in mask_paths]\n    stack = da.stack(arrays)\n    valid = stack > 0\n    labeled_count = da.sum(valid).compute()\n    return labeled_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.501639Z","iopub.execute_input":"2025-05-27T21:18:09.501869Z","iopub.status.idle":"2025-05-27T21:18:09.522521Z","shell.execute_reply.started":"2025-05-27T21:18:09.501850Z","shell.execute_reply":"2025-05-27T21:18:09.521844Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def compute_invalid_mask(path):\n    with rasterio.open(path) as src:\n        image = src.read()\n        \n        invalid_mask = image == src.nodata\n        invalid_mask |= np.isnan(image)\n        invalid_mask |= image < 0\n        invalid_mask |= image > 1\n        invalid_mask = np.any(invalid_mask, axis=0)\n        return invalid_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.523252Z","iopub.execute_input":"2025-05-27T21:18:09.523518Z","iopub.status.idle":"2025-05-27T21:18:09.537997Z","shell.execute_reply.started":"2025-05-27T21:18:09.523460Z","shell.execute_reply":"2025-05-27T21:18:09.537340Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"def get_invalid_mask(image, no_data):\n    invalid_mask = image == no_data\n    invalid_mask |= np.isnan(image)\n    invalid_mask |= image < -1.5\n    invalid_mask |= image > 1.5\n    #invalid_mask = np.any(invalid_mask, axis=0)\n    return invalid_mask  #torch.fromnumpy(invalid_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.538786Z","iopub.execute_input":"2025-05-27T21:18:09.538994Z","iopub.status.idle":"2025-05-27T21:18:09.555080Z","shell.execute_reply.started":"2025-05-27T21:18:09.538974Z","shell.execute_reply":"2025-05-27T21:18:09.554414Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def select_bg_pixels(image, debris_mask, r1=5, r2=20, target_ratio=5):\n    H, W = debris_mask.shape\n    \n    #target_ratio = 5  # Debris-to-background ratio (1:5)\n\n    # Create structuring elements (circular or square)\n    se_r1 = disk(r1) if r1 > 0 else np.ones((1, 1))  # Inner dilation kernel\n    se_r2 = disk(r2)                         # Outer dilation kernel\n    #print('before binary dilation')\n    # Dilate debris mask with r1 and r2\n    dilated_r1 = binary_dilation(debris_mask, structure=se_r1)\n    dilated_r2 = binary_dilation(debris_mask, structure=se_r2)\n    #print('before anular mask')\n    # Compute annular region: pixels in dilated_r2 but not in dilated_r1\n    annular_mask = dilated_r2 & ~dilated_r1\n\n    # Sample background pixels from annular region\n    valid_background_coords = np.where(annular_mask)\n    num_debris = np.sum(debris_mask)\n    num_background = min(len(valid_background_coords[0]), num_debris * target_ratio)\n    if num_background > 0:\n        sample_idx = np.random.choice(len(valid_background_coords[0]), size=num_background, replace=False)\n        background_coords = [(valid_background_coords[0][i], valid_background_coords[1][i]) for i in sample_idx]\n    else:\n        print(\"Warning: No valid background pixels in annular region. Increase r2 or check mask.\")\n\n    # Create background mask (optional, for visualization or training)\n    background_mask = np.zeros_like(debris_mask)\n    for x, y in background_coords:\n        background_mask[x, y] = 1\n    return background_mask\n\n# Optional: Filter by features (e.g., RGB values for water-like pixels)\n# Example: If image is RGB, filter pixels with low green channel (common for water)\n# image = ...  # Your RGB or multispectral image\n# valid_background = [coord for coord in background_coords if image[coord[0], coord[1], 1] < threshold]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.555854Z","iopub.execute_input":"2025-05-27T21:18:09.556137Z","iopub.status.idle":"2025-05-27T21:18:09.569563Z","shell.execute_reply.started":"2025-05-27T21:18:09.556114Z","shell.execute_reply":"2025-05-27T21:18:09.569000Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def batch_process_marida_masks(masks, dataset_ids, device='cpu'):\n    \"\"\"\n    Process masks for dataset_id == 0 (MARIDA) at the batch level.\n    - Set classes [1, 2, 3, 4, 9] to 2 (debris).\n    - Set class 0 to 0 (unlabeled), other classes to 1 (non-debris).\n    \n    Args:\n        masks: Tensor [batch_size, H, W] (integer-valued masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        marida_masks: Tensor [batch_size, H, W] with values 0, 1, 2\n    \"\"\"\n    batch_size, H, W = masks.shape\n    marida_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks with dataset_id == 0\n    marida_mask = (dataset_ids == 0)  # [batch_size], boolean\n    if not marida_mask.any():\n        return marida_masks\n    \n    # Select masks for dataset_id == 0\n    selected_masks = masks[marida_mask]  # [num_marida, H, W]\n    \n    # Set classes [1, 2, 3, 4, 9] to 2\n    debris_classes = torch.tensor([1, 2, 3, 4, 9], device=device)\n    is_debris = torch.isin(selected_masks, debris_classes)  # [num_marida, H, W]\n    marida_masks[marida_mask] = torch.where(\n        is_debris,\n        torch.tensor(2, dtype=torch.int64, device=device),\n        selected_masks  # Temporarily keep original values\n    )\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    # Set non-zero, non-debris pixels to 1\n    marida_masks[marida_mask] = torch.where(\n        (marida_masks[marida_mask] != 0) & (marida_masks[marida_mask] != 2),\n        torch.tensor(1, dtype=torch.int64, device=device),\n        marida_masks[marida_mask]\n    )\n    # print('only 3 values : ')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    marida_masks[marida_mask] = marida_masks[marida_mask] - 1\n    #print('after subtr')\n    # for idx in range( marida_masks[marida_mask].shape[0]):\n    #     print(f' {idx} has {torch.sum(is_debris[idx])} : {torch.unique(marida_masks[marida_mask][idx])}')\n    return marida_masks\n\n\n\n# # Custom collate function\n# def custom_collate_fn(batch):\n#     images, masks, dataset_ids = zip(*batch)\n#     images = torch.stack(images)\n#     masks = torch.stack(masks)\n#     dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)\n    \n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n#     final_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n#                                          target_ratio=5, threshold=0.5, device=device)\n    \n#     return images, masks, final_masks, dataset_ids\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.570327Z","iopub.execute_input":"2025-05-27T21:18:09.570797Z","iopub.status.idle":"2025-05-27T21:18:09.589064Z","shell.execute_reply.started":"2025-05-27T21:18:09.570776Z","shell.execute_reply":"2025-05-27T21:18:09.588388Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"\ndef torch_dilate(mask, kernel_size, device='cpu'):\n    \"\"\"Apply dilation to a batch of masks using PyTorch convolution.\"\"\"\n    kernel = torch.ones(1, 1, kernel_size, kernel_size, device=device, dtype=torch.float32)\n    mask = mask.float().unsqueeze(1)  # [batch_size, 1, H, W]\n    dilated = torch.nn.functional.conv2d(mask, kernel, padding=kernel_size // 2) > 0\n    return dilated.squeeze(1).bool()  # [batch_size, H, W]\n\ndef batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, target_ratio=5, threshold=None, device='cpu'):\n    \"\"\"\n    Compute annular background masks for a batch of masks, only for dataset_id == 1.\n    - Set debris pixels (masks == 1) to 2 in bg_masks.\n    - Set randomly sampled annular pixels to 1 in bg_masks.\n    \n    Args:\n        images: Tensor [batch_size, C, H, W] \n        masks: Tensor [batch_size, H, W] (binary debris masks)\n        dataset_ids: Tensor [batch_size] (dataset IDs)\n        r1, r2: Radii for inner and outer dilation\n        target_ratio: Debris-to-background pixel ratio\n        threshold: Optional threshold for filtering (e.g., green channel)\n        device: Device for PyTorch operations ('cpu' or 'cuda')\n    \n    Returns:\n        bg_masks: Tensor [batch_size, H, W] with values 0 (default), 1 (background), 2 (debris)\n    \"\"\"\n\n    batch_size, H, W = masks.shape\n    # Initialize bg_masks with zeros (int64 to support values 0, 1, 2)\n    bg_masks = torch.zeros_like(masks, dtype=torch.int64, device=device)\n    \n    # Identify masks to process (dataset_id == 1)\n    valid_mask = (dataset_ids == 1)  # [batch_size], boolean{\n    #print(f'LR indices {valid_mask}')\n    if not valid_mask.any():\n        return bg_masks  # Return zeros if no masks need processing\n    \n    # Select masks for dataset_id == 1\n    selected_masks = masks[valid_mask]  # [num_valid, H, W]\n    # for idx in range(selected_masks.shape[0]):\n    #     print(f'num debris pixels : {torch.sum(selected_masks[idx])}')\n    # Set debris pixels to 2 for selected masks\n    bg_masks[valid_mask] = selected_masks * 2  # Where selected_masks == 1, set bg_masks to 2\n    \n    # Perform dilation on selected masks\n    dilated_r1 = torch_dilate(selected_masks, 2 * r1 + 1, device=device)  # [num_valid, H, W]\n    dilated_r2 = torch_dilate(selected_masks, 2 * r2 + 1, device=device)  # [num_valid, H, W]\n    annular_masks = dilated_r2 & ~dilated_r1  # [num_valid, H, W]\n    \n    # Sample background pixels for each selected mask\n    for idx in range(annular_masks.shape[0]):\n        valid_coords = torch.where(annular_masks[idx])  # Tuple of (row, col) indices\n        #print(f'unique values in mask {idx} : {torch.unique(selected_masks[idx])}')\n        num_debris = torch.sum(selected_masks[idx] > 0).item()\n        #print(f'num debris for index {idx} : {num_debris}')\n        num_background = min(len(valid_coords[0]), int(num_debris * target_ratio))\n        \n        if num_background > 0:\n            # Randomly sample indices and set to 1\n            sample_indices = torch.randperm(len(valid_coords[0]), device=device)[:num_background]\n            bg_masks[valid_mask.nonzero(as_tuple=True)[0][idx], \n                     valid_coords[0][sample_indices], \n                     valid_coords[1][sample_indices]] = 1\n        else :\n            print(f'no background selected for index {idx}. Num debrid : {num_debris} Num background : {num_background}')\n            print(f'valid coords {len(valid_coords)}')\n            print(f'unique valus : {torch.unique(selected_masks[idx])}')\n    \n    # # Optional: Filter by image features (e.g., green channel) for dataset_id == 1\n    # if threshold is not None and images is not None:\n    #     valid_pixels = images[valid_mask, 1, :, :] < threshold  # Green channel\n    #     # Only apply filtering to background pixels (value 1), preserve debris pixels (value 2)\n    #     bg_masks[valid_mask] = torch.where(\n    #         bg_masks[valid_mask] == 1,\n    #         bg_masks[valid_mask] & valid_pixels,\n    #         bg_masks[valid_mask]\n    #     )\n    bg_masks[valid_mask] = bg_masks[valid_mask] - 1\n    return bg_masks\n\n# Custom collate function\ndef custom_collate_fn(batch):\n    # print(f'custom collate function batch {len(batch)}')\n    # print(f'custom collate function batch type {type(batch)}')\n    # print(f'custom collate function batch[1] type {type(batch[1])}')\n    # print(f'custom collate function batch[1] len  {len(batch[1])}')\n    images, masks, dataset_ids = zip(*batch)\n    images = torch.stack(images)  # [batch_size, C, H, W]\n    masks = torch.stack(masks)    # [batch_size, H, W]\n    dataset_ids = torch.tensor(dataset_ids, dtype=torch.long)  # [batch_size]\n    \n    # Move to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    images, masks, dataset_ids = images.to(device), masks.to(device), dataset_ids.to(device)\n    \n    # Compute background masks\n    lr_masks = batch_select_bg_pixels(images, masks, dataset_ids, r1=5, r2=20, \n                                      target_ratio=LR_ratio, device=device)\n    marida_masks = batch_process_marida_masks(masks, dataset_ids, device=device)\n    masks = lr_masks + marida_masks\n    \n    return images, masks, dataset_ids\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.589841Z","iopub.execute_input":"2025-05-27T21:18:09.590500Z","iopub.status.idle":"2025-05-27T21:18:09.615078Z","shell.execute_reply.started":"2025-05-27T21:18:09.590479Z","shell.execute_reply":"2025-05-27T21:18:09.614565Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# Seeding for reproducibility\nseed = 42\nset_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.615792Z","iopub.execute_input":"2025-05-27T21:18:09.616021Z","iopub.status.idle":"2025-05-27T21:18:09.636661Z","shell.execute_reply.started":"2025-05-27T21:18:09.616006Z","shell.execute_reply":"2025-05-27T21:18:09.635983Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# %%capture\n# # Download some pre-computed data \n\n#file_id = \"10bMAQaV2-EXCu52ON-6m0qh7u7__v-hH\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_df_invalid_info.csv', quiet=False)\n#file_id = '19VzQze4sBt76ylEcishVQNpGIFYSkseT'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_val_df_invalid_info.csv', quiet=False)\n#file_id = '1CvUC8FAqj1aUV8fwrTljU3mC-geWz0it'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/marida_test_df_invalid_info.csv', quiet=False)\n#file_id = \"1YTJmy8X-xIo8dV7Qpq4h7wOi7kUAW4sw\"\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_df_invalid_info.csv', quiet=False)\n#file_id = '1CzvC9VLbzqyh9LbhyxWhtIHaz7o1hmak'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/litter_rows_val_df_invalid_info.csv', quiet=False)\n#file_id = '1wrD41CDQud69AMOyHigw0-DR85Id4zDM'\n#gdown.download(f'https://drive.google.com/uc?id={file_id}', '/kaggle/working/global_stats.npz', quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.637350Z","iopub.execute_input":"2025-05-27T21:18:09.637569Z","iopub.status.idle":"2025-05-27T21:18:09.651976Z","shell.execute_reply.started":"2025-05-27T21:18:09.637554Z","shell.execute_reply":"2025-05-27T21:18:09.651419Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# # check that the \n# ! ls /kaggle/input/litter-windrows-patches\n# # add the lr dataset to path to import code to prepare the dataset\n# sys.path.append('/kaggle/input/litter-windrows-patches')\n# # import functions to prepare dataset\n# from prepare_dataset import  get_image_and_mask_paths, split_and_save_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.652635Z","iopub.execute_input":"2025-05-27T21:18:09.652806Z","iopub.status.idle":"2025-05-27T21:18:09.672896Z","shell.execute_reply.started":"2025-05-27T21:18:09.652787Z","shell.execute_reply":"2025-05-27T21:18:09.672344Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"#! git clone https://github.com/sheikhazhanmohammed/SADMA.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.673516Z","iopub.execute_input":"2025-05-27T21:18:09.673686Z","iopub.status.idle":"2025-05-27T21:18:09.689536Z","shell.execute_reply.started":"2025-05-27T21:18:09.673674Z","shell.execute_reply":"2025-05-27T21:18:09.688891Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"#sys.path.append('/kaggle/working/SADMA')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.690110Z","iopub.execute_input":"2025-05-27T21:18:09.690310Z","iopub.status.idle":"2025-05-27T21:18:09.706326Z","shell.execute_reply.started":"2025-05-27T21:18:09.690295Z","shell.execute_reply":"2025-05-27T21:18:09.705762Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# # define a variable for the lr dataset\n# LW_path = '/kaggle/input/litter-windrows-patches'\n# lr_images, lr_masks = get_image_and_mask_paths(LW_path)\n# ! mkdir ./LR_splits\n# split_and_save_data(lr_images, lr_masks, './LR_splits' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.707344Z","iopub.execute_input":"2025-05-27T21:18:09.707548Z","iopub.status.idle":"2025-05-27T21:18:09.720819Z","shell.execute_reply.started":"2025-05-27T21:18:09.707529Z","shell.execute_reply":"2025-05-27T21:18:09.720174Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# ! ls ./LR_splits/splits\n# LR_splits_path = '/kaggle/working/LR_splits/splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.721547Z","iopub.execute_input":"2025-05-27T21:18:09.721743Z","iopub.status.idle":"2025-05-27T21:18:09.735054Z","shell.execute_reply.started":"2025-05-27T21:18:09.721729Z","shell.execute_reply":"2025-05-27T21:18:09.734425Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# from IPython.display import display\n\n# with open(LR_splits_path+'/train_X.txt', \"r\") as file:\n#     display(file.read())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.735708Z","iopub.execute_input":"2025-05-27T21:18:09.735936Z","iopub.status.idle":"2025-05-27T21:18:09.749549Z","shell.execute_reply.started":"2025-05-27T21:18:09.735917Z","shell.execute_reply":"2025-05-27T21:18:09.749000Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"! ls /kaggle/input/marida-marine-debrish-dataset\nMARIDA_path = '/kaggle/input/marida-marine-debrish-dataset'\n! ls /kaggle/input/litter-windrows-patches\nLR_splits_path = '/kaggle/input/litter-windrows-patches/binary_splits'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:09.750262Z","iopub.execute_input":"2025-05-27T21:18:09.750520Z","iopub.status.idle":"2025-05-27T21:18:10.038840Z","shell.execute_reply.started":"2025-05-27T21:18:09.750498Z","shell.execute_reply":"2025-05-27T21:18:10.037831Z"}},"outputs":[{"name":"stdout","text":"labels_mapping.txt  patches  shapefiles  splits\nannotation     multiclass_splits  prepare_dataset.ipynb\nbinary_splits  patches\t\t  README.md\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"# MARIDA dataframe\nmarida_df = create_marida_df(MARIDA_path)\n#marida_df_invalid = compute_invalid_pixels(marida_df['image'].tolist(), marida_df['mask'].tolist())\n#marida_df_invalid.to_csv('/kaggle/working/marida_with_invalid.csv')\nmarida_df_invalid = pd.read_csv('/kaggle/working/marida_df_invalid_info.csv')\nmarida_df_F = marida_df.drop(marida_df_invalid[marida_df_invalid['nan pixels']>0].index)\n\n# MARIDA val dataframe\nmarida_val_df = create_marida_df(MARIDA_path, 'val')\n#marida_val_df_invalid = compute_invalid_pixels(marida_val_df['image'].tolist(), marida_val_df['mask'].tolist())\n#marida_val_df_invalid.to_csv('/kaggle/working/marida_val_df_invalid.csv')\nmarida_val_df_invalid =pd.read_csv('/kaggle/working/marida_val_df_invalid_info.csv')\nmarida_val_df_F = marida_val_df.drop(marida_val_df_invalid[marida_val_df_invalid['nan pixels'] > 0].index)\n\n# MARIDA test dataframe\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\n#marida_test_df_invalid = compute_invalid_pixels(marida_test_df['image'].tolist(), marida_test_df['mask'].tolist())\n#marida_test_df_invalid.to_csv('/kaggle/working/marida_test_df_invalid.csv')\nmarida_test_df_invalid =pd.read_csv('/kaggle/working/marida_test_df_invalid_info.csv')\nmarida_test_df_F = marida_test_df.drop(marida_test_df_invalid[marida_test_df_invalid['nan pixels'] > 0].index)\n\n# LR dataframe\n\nlr_df = create_LR_dataframe(LR_splits_path)\n#lr_df_invalid = compute_invalid_pixels(lr_df['image'].tolist(), lr_df['mask'].tolist())\n#lr_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\nlr_df_F = lr_df.drop(lr_df_invalid[lr_df_invalid['high value pixels'] > 0].index)\n\n#LR val dataset\nlr_val_df = create_LR_dataframe(LR_splits_path, 'val')\n#lr_val_df_invalid = compute_invalid_pixels(lr_val_df['image'].tolist(), lr_val_df['mask'].tolist())\n#lr_val_df_invalid.to_csv('/kaggle/working/litter_rows_val_invalid_info.csv')\nlr_val_df_invalid = pd.read_csv('/kaggle/working/litter_rows_val_df_invalid_info.csv')\nlr_val_df_F= lr_val_df.drop(lr_val_df_invalid[lr_val_df_invalid['high value pixels']>0].index)\n\n\n#lr_test_df_invalid = compute_invalid_pixels(lr_test_df['image'].tolist(), lr_test_df['mask'].tolist())\n#lr_test_df_invalid.to_csv('/kaggle/working/litter_rows_df_invalid_info.csv')\n#lr_test_df_invalid = pd.read_csv('/kaggle/working/litter_rows_df_invalid_info.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:10.043446Z","iopub.execute_input":"2025-05-27T21:18:10.043689Z","iopub.status.idle":"2025-05-27T21:18:12.575447Z","shell.execute_reply.started":"2025-05-27T21:18:10.043666Z","shell.execute_reply":"2025-05-27T21:18:12.574826Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# lr valid = 79495168","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.576134Z","iopub.execute_input":"2025-05-27T21:18:12.576431Z","iopub.status.idle":"2025-05-27T21:18:12.579814Z","shell.execute_reply.started":"2025-05-27T21:18:12.576406Z","shell.execute_reply":"2025-05-27T21:18:12.579076Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"#lr_stats = compute_stats(lr_df_filt['image'].tolist())\n#np.savez(\"/kaggle/working/lr_stats.npz\", first=lr_stats['mean'], second=lr_stats['std'])\n#marida_stats = compute_stats(marida_df['image'].tolist())\n#np.savez(\"/kaggle/working/my_marida_stats.npz\", first=marida_stats['mean'], second=marida_stats['std'])\n#global_stats = compute_stats(marida_df['image'].tolist() + lr_df_filt['image'].to_list())\n#np.savez(\"/kaggle/working/global_stats.npz\", first=global_stats['mean'], second=global_stats['std'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.580595Z","iopub.execute_input":"2025-05-27T21:18:12.580804Z","iopub.status.idle":"2025-05-27T21:18:12.592968Z","shell.execute_reply.started":"2025-05-27T21:18:12.580788Z","shell.execute_reply":"2025-05-27T21:18:12.592230Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"global_stats = np.load('/kaggle/working/global_stats.npz')\nglobal_bands_mean = global_stats['first']\nglobal_bands_std = global_stats['second']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.593805Z","iopub.execute_input":"2025-05-27T21:18:12.594013Z","iopub.status.idle":"2025-05-27T21:18:12.607243Z","shell.execute_reply.started":"2025-05-27T21:18:12.593997Z","shell.execute_reply":"2025-05-27T21:18:12.606684Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"# global_bands_mean =np.array([0.03721786, 0.03547978, 0.03033651, 0.01722546, 0.01574046,\n#         0.01738895, 0.01939084, 0.01724032, 0.01895351, 0.0109694 ,\n#         0.00784716])\n# global_bands_std = np.array([0.03185222, 0.03198375, 0.03251331, 0.03379553, 0.03407218,\n#         0.04551132, 0.05334419, 0.05064404, 0.0578197 , 0.03721222,\n#         0.02560836])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.607950Z","iopub.execute_input":"2025-05-27T21:18:12.608139Z","iopub.status.idle":"2025-05-27T21:18:12.618516Z","shell.execute_reply.started":"2025-05-27T21:18:12.608125Z","shell.execute_reply":"2025-05-27T21:18:12.617915Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"#computing_labeled_pixels_stats(lr_df_filt['mask'].tolist())\n#computing_labeled_pixels_stats(marida_df['mask'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.619256Z","iopub.execute_input":"2025-05-27T21:18:12.619471Z","iopub.status.idle":"2025-05-27T21:18:12.631265Z","shell.execute_reply.started":"2025-05-27T21:18:12.619456Z","shell.execute_reply":"2025-05-27T21:18:12.630676Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"marida_classes_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\nlr_debris_pixels = 92090\nmarida_pixels = 429412\nmarida_debris_pixels = np.sum(marida_classes_distr[[0,1,2,3,8]]) * marida_pixels\nprint(f'marida debris pixels {marida_debris_pixels}')\ntot_glob_pixels = (len(lr_df_F) + len(marida_df_F))*256**2\nmarida_debris_fraction = np.sum(marida_classes_distr[[0,1,2,3,8]])\n#debris_fraction = (lr_debris_pixels + marida_debris_pixels)/tot_glob_pixels\nprint(f'marida_debris_fraction : {marida_debris_fraction}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.631986Z","iopub.execute_input":"2025-05-27T21:18:12.632180Z","iopub.status.idle":"2025-05-27T21:18:12.646415Z","shell.execute_reply.started":"2025-05-27T21:18:12.632158Z","shell.execute_reply":"2025-05-27T21:18:12.645859Z"}},"outputs":[{"name":"stdout","text":"marida debris pixels 5092.826320000001\nmarida_debris_fraction : 0.011860000000000002\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"# Computing here the percentage of debris pixels across the two datasets\n# This will be used as class distribution to generate weights for the loss function\nLR_ratio = 15 # \n\n# For MARIDA the loss function uses only pixels in the 15 classes \n# The fraction of classes assimilated to marine debris is \nmarida_debrix_pixels_distr = np.sum(marida_classes_distr[[0,1,2,3,8]])\n# For LR the DataSet will sample backgroung pixels with a given ratio, stored in the variable LR_ratio\n# Then the effective ratio \neffective_ratio = (1/LR_ratio * len(lr_df_F) + 0.011860000000000002 * len(marida_df_F))/(len(lr_df_F) + len(marida_df_F))\n#print(f'effective global ratio {effective_ratio}')\nclass_distribution = np.array([1 - effective_ratio, effective_ratio])\nprint(f'class distribution {class_distribution}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.647135Z","iopub.execute_input":"2025-05-27T21:18:12.647846Z","iopub.status.idle":"2025-05-27T21:18:12.662571Z","shell.execute_reply.started":"2025-05-27T21:18:12.647823Z","shell.execute_reply":"2025-05-27T21:18:12.661901Z"}},"outputs":[{"name":"stdout","text":"class distribution [0.9532291 0.0467709]\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"# MARIDA statistics\n\nclass_distr = np.array([0.00452, 0.00203, 0.00254, 0.00168, 0.00766, 0.15206, 0.20232,\n 0.35941, 0.00109, 0.20218, 0.03226, 0.00693, 0.01322, 0.01158, 0.00052])\n\nbands_mean = np.array([0.05197577, 0.04783991, 0.04056812, 0.03163572, 0.02972606, 0.03457443,\n 0.03875053, 0.03436435, 0.0392113,  0.02358126, 0.01588816]).astype(np.float32)\n\nbands_std = np.array([0.04725893, 0.04743808, 0.04699043, 0.04967381, 0.04946782, 0.06458357,\n 0.07594915, 0.07120246, 0.08251058, 0.05111466, 0.03524419]).astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.663208Z","iopub.execute_input":"2025-05-27T21:18:12.663465Z","iopub.status.idle":"2025-05-27T21:18:12.675470Z","shell.execute_reply.started":"2025-05-27T21:18:12.663450Z","shell.execute_reply":"2025-05-27T21:18:12.674888Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# Other code references  \n# https://github.com/MarcCoru/marinedebrisdetector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.676068Z","iopub.execute_input":"2025-05-27T21:18:12.676226Z","iopub.status.idle":"2025-05-27T21:18:12.688657Z","shell.execute_reply.started":"2025-05-27T21:18:12.676214Z","shell.execute_reply":"2025-05-27T21:18:12.687881Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# MARIDA CLASSES\n# {\n#  1: \"Marine Debris\",\n#  2: \"Dense Sargassum\", \n#  3: \"Sparse Sargassum\", \n#  4: \"Natural Organic Material\", \n#  5: \"Ship\", \n#  6: \"Clouds\", \n#  7: \"Marine Water\", \n#  8: \"Sediment-Laden Water\", \n#  9: \"Foam\", \n#  10: \"Turbid Water\", \n#  11: \"Shallow Water\", \n#  12: \"Waves\", \n#  13: \"Cloud Shadows\", \n#  14: \"Wakes\", \n#  15: \"Mixed Water\"\n# }\n\n\n# From marinedebrisdetector \n# DEBRIS_CLASSES = [1,2,3,4,9]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.689390Z","iopub.execute_input":"2025-05-27T21:18:12.689719Z","iopub.status.idle":"2025-05-27T21:18:12.705916Z","shell.execute_reply.started":"2025-05-27T21:18:12.689695Z","shell.execute_reply":"2025-05-27T21:18:12.705419Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# https://drive.google.com/drive/folders/1rntiw5BvOs80eIbpOu7dk9g1BfOVw61-?usp=drive_link","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.706550Z","iopub.execute_input":"2025-05-27T21:18:12.706732Z","iopub.status.idle":"2025-05-27T21:18:12.718368Z","shell.execute_reply.started":"2025-05-27T21:18:12.706718Z","shell.execute_reply":"2025-05-27T21:18:12.717759Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"\nclass RandomRotationTransform:\n    \"\"\"Rotate by one of the given angles.\"\"\"\n\n    def __init__(self, angles):\n        self.angles = angles\n\n    def __call__(self, x):\n        angle = random.choice(self.angles)\n        return vF.rotate(x, angle)\n    \ndef gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)\n    \ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean, global_bands_std) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.719088Z","iopub.execute_input":"2025-05-27T21:18:12.719325Z","iopub.status.idle":"2025-05-27T21:18:12.731045Z","shell.execute_reply.started":"2025-05-27T21:18:12.719308Z","shell.execute_reply":"2025-05-27T21:18:12.730406Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"def gen_weights(class_distribution, c = 1.02):\n    return 1/torch.log(c + class_distribution)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.731874Z","iopub.execute_input":"2025-05-27T21:18:12.732131Z","iopub.status.idle":"2025-05-27T21:18:12.742624Z","shell.execute_reply.started":"2025-05-27T21:18:12.732110Z","shell.execute_reply":"2025-05-27T21:18:12.742112Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom torchvision import transforms\n# model import UNet, AttentionUNet, ResidualAttentionUNet  # From original script\n#f#rom dataloader import bands_mean, bands_std, RandomRotationTransform, class_distr, gen_weights\n#from metrics import Evaluation\n#from customLosses import FocalLoss\nimport pandas as pd\nfrom torch.utils.data import Dataset\n\nclass MergedSegmentationDataset_B(Dataset):\n    \"\"\"\n    df_dataset1 : MARIDA dataset\n    df_dataset2 : LR dataset\n    \"\"\"\n    def __init__(self, df_dataset1, df_dataset2, bands_mean, bands_std, selected_bands, transform=None, standardization=None):\n        \"\"\"\n        df_dataset1 : MARIDA\n        df_dataset2 : Litter Windrows\n        \"\"\"\n        self.bands_mean = bands_mean[selected_bands]\n        self.bands_std = bands_std[selected_bands]\n        self.transform = transform\n        self.standardization = standardization\n        self.image_paths = []\n        self.mask_paths = []\n        self.dataset_ids = []\n        self.image_paths = df_dataset1['image'].tolist() + df_dataset2['image'].tolist() \n        self.mask_paths =  df_dataset1['mask'].tolist() + df_dataset2['mask'].tolist() \n        self.dataset_ids = [0] * len(df_dataset1['image']) + [1] * len(df_dataset2['image'])\n        # Generate shuffled indices\n        indices = np.random.permutation(len(self.image_paths))\n        self.image_paths = np.array(self.image_paths)[indices]\n        self.mask_paths = np.array(self.mask_paths)[indices]\n        self.dataset_ids = np.array(self.dataset_ids)[indices]        \n        #print(self.dataset_ids)\n        if self.transform is None:\n            self.transform = transforms.Compose([transforms.ToTensor()])\n        ## preloading images in memory \n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        #print(f'idx {idx}') \n        max_seed = 2**32 - 1  # NumPy seed limit\n        #index_seed_seed = (42 + idx) % max_seed\n        #np.random.seed(index_seed_seed)\n        # Load Classsification Mask np.random.seed(self.seed + index)  # Deterministic per item\n        dataset_id = self.dataset_ids[idx]\n        # Open t#he GeoTIFF image file\n        #print(f'image path {self.image_paths[idx]}')\n        #print(f'mask path {self.mask_paths[idx]}')\n        with rasterio.open(self.image_paths[idx]) as src:\n            #print(f#\"Number of bands: {dataset.count}\")  # Check the number of bands\n            # Read all bands as a NumPy array\n            image = src.read()\n            # Keep the bands in selecred_bands\n            image = image[selected_bands, :, :]\n            invalid_mask = get_invalid_mask(image, src.nodata)\n            with rasterio.open(self.mask_paths[idx]) as src_mask:\n                mask = src_mask.read().astype(int)\n            debris_before_invalid = np.sum(mask)\n            invalid_pixels = np.sum(np.any(invalid_mask, axis=0))\n            mask[np.any(invalid_mask.astype(bool), axis=0, keepdims=True)] = 0 #I guess it makes sense not to feed invalid pixels to the loss function\n            #print(f'before inputing 2')\n            image[invalid_mask.astype(bool)] = np.tile(self.bands_mean[:, np.newaxis, np.newaxis], (1, 256, 256))[invalid_mask.astype(bool)]\n            #print(f'after inputing')\n            ## Since the model sees unvalid pixels anyway, it's better (?) to replace those with mean values ? \n            #print(f'mask type before transh {type(mask)} - {mask.dtype}')\n            #print(f'image type before transh {type(image)} - {image.dtype}')\n            #############\n            debris_after_invalid = np.sum(mask)\n            #############\n            if self.transform is not None:\n                # applying the same rotation on the image-mask pair\n                #print(f'transform - image shape {image.shape}')\n                #print(f'transform - mask shape {mask.shape}')\n                stack = np.concatenate([image, mask], axis=0).astype(np.float32) \n                stack = np.transpose(stack,(1, 2, 0)) #to channel last\n                #print(f'stack shape before transfrom {stack.shape}')\n                stack = self.transform(stack) #expects channel last, returns channel first\n               \n                #print(f'stack shape after transfrom {stack.shape}')\n                image = stack[:-1,:,:]\n                mask = stack[-1,:,:].long()\n                #print(f'image type {image.dtype}')\n                #print(f'image shape after transform {image.shape}')\n                #print(f'mask shape after transform {mask.shape}')\n\n                   \n            \n            if self.standardization is not None:\n                image = self.standardization(image)\n                \n            #mask = mask - 1 Moved to collate function\n            if isinstance(mask, np.ndarray):\n                mask = torch.from_numpy(mask).to(torch.long)\n            else:\n                mask = mask.to(torch.long)\n            if isinstance(image, np.ndarray):\n                image = torch.from_numpy(image).to(torch.float32)\n            else:\n                im = image.to(torch.float32)\n            if torch.sum(mask) == 0 :\n                print(f'{self.mask_paths[idx]} has no debris pixels')\n                print(f'debris pixels before invalid mask : {debris_before_invalid}')\n                print(f'debris pixels after invalid mask : {debris_after_invalid}')\n                print(f'invalid pixels : {invalid_pixels}')\n           \n        ## Add logic for transform\n\n            return image, mask, dataset_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.743397Z","iopub.execute_input":"2025-05-27T21:18:12.743600Z","iopub.status.idle":"2025-05-27T21:18:12.763472Z","shell.execute_reply.started":"2025-05-27T21:18:12.743585Z","shell.execute_reply":"2025-05-27T21:18:12.762751Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"def conv3x3(in_channels, out_channels, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, channels, ratio=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.mlp = nn.Sequential(nn.Conv2d(channels, channels // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(channels // 16, channels, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.mlp(self.avg_pool(x))\n        max_out = self.mlp(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inputChannel, outputChannel, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(inputChannel, outputChannel, stride)\n        self.bn1 = nn.BatchNorm2d(outputChannel)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(outputChannel, outputChannel)\n        self.bn2 = nn.BatchNorm2d(outputChannel)\n        self.downsample = downsample\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n        \n    # def forward(self, x):\n    \n    #     residual = x\n    #     out = self.conv1(x)\n    #     out = self.bn1(out)\n    #     out = self.relu(out)\n    #     out = self.conv2(out)\n    #     out = self.bn2(out)\n    #     if self.downsample:\n    #         residual = self.downsample(x)\n    #     out += residual\n    #     out = self.relu(out)\n    #     caOutput = self.ca(out)\n    #     out = caOutput * out\n    #     saOutput = self.sa(out)\n    #     out = saOutput * out\n    #     return out, saOutput\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.bn2(out)\n        out = self.relu(out)\n        caOutput = self.ca(out)\n        out = caOutput * out\n        saOutput = self.sa(out)\n        out = saOutput * out\n        return out, saOutput\n\n\nclass DownSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.AvgPool2d(2)\n        )\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self,x):\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\n    \nclass UpSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2)\n        )\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\nclass ResidualAttentionUNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n    self.downsample2 = DownSampleWithAttention(32, 64)\n    self.downsample3 = DownSampleWithAttention(64, 128)\n    self.downsample4 = DownSampleWithAttention(128, 256)\n    self.downsample5 = DownSampleWithAttention(256, 512)\n\n    self.residualBlock1 = ResidualBlock(512, 512)\n    self.residualBlock2 = ResidualBlock(512, 512)\n    self.residualBlock3 = ResidualBlock(512, 512)\n\n    self.upsample1 = UpSampleWithAttention(512, 256)\n    self.upsample2 = UpSampleWithAttention(512, 128)\n    self.upsample3 = UpSampleWithAttention(256, 64)\n    self.upsample4 = UpSampleWithAttention(128, 32)\n    self.upsample5 = UpSampleWithAttention(64, 32)\n    self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128, sa128down = self.downsample1(x)\n    scale64, sa64down = self.downsample2(scale128)\n    scale32, sa32down = self.downsample3(scale64)\n    scale16, sa64down = self.downsample4(scale32)\n    scale8, sa8down = self.downsample5(scale16)\n    scale8, sa8down = self.residualBlock1(scale8)\n    scale8, sa8down = self.residualBlock2(scale8)\n    scale8, sa8down = self.residualBlock3(scale8)\n    upscale16, sa16up = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32, sa32up = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64, sa64up = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128, sa128up = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256, sa256up = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.764130Z","iopub.execute_input":"2025-05-27T21:18:12.764330Z","iopub.status.idle":"2025-05-27T21:18:12.783529Z","shell.execute_reply.started":"2025-05-27T21:18:12.764315Z","shell.execute_reply":"2025-05-27T21:18:12.782742Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"def Evaluation(y_predicted, y_true):\n\n    micro_prec = precision_score(y_true, y_predicted, average='micro')\n    macro_prec = precision_score(y_true, y_predicted, average='macro')\n    weight_prec = precision_score(y_true, y_predicted, average='weighted')\n    \n    micro_rec = recall_score(y_true, y_predicted, average='micro')\n    macro_rec = recall_score(y_true, y_predicted, average='macro')\n    weight_rec = recall_score(y_true, y_predicted, average='weighted')\n        \n    macro_f1 = f1_score(y_true, y_predicted, average=\"macro\")\n    micro_f1 = f1_score(y_true, y_predicted, average=\"micro\")\n    weight_f1 = f1_score(y_true, y_predicted, average=\"weighted\")\n        \n    subset_acc = accuracy_score(y_true, y_predicted)\n    \n    iou_acc = jaccard_score(y_true, y_predicted, average='macro')\n\n    # Debris-specific metrics\n    debris_class = 1\n    debris_prec = precision_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_rec = recall_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_f1 = f1_score(y_true, y_predicted, labels=[debris_class], average='macro')\n    debris_iou = jaccard_score(y_true, y_predicted, labels=[debris_class], average='macro')\n\n    info = {\n            \"macroPrec\" : macro_prec,\n            \"microPrec\" : micro_prec,\n            \"weightPrec\" : weight_prec,\n            \"macroRec\" : macro_rec,\n            \"microRec\" : micro_rec,\n            \"weightRec\" : weight_rec,\n            \"macroF1\" : macro_f1,\n            \"microF1\" : micro_f1,\n            \"weightF1\" : weight_f1,\n            \"subsetAcc\" : subset_acc,\n            \"IoU\": iou_acc,\n            \"debris Prec\" : debris_prec,\n            \"debris Rec\" : debris_rec,\n            \"debris F1\" : debris_f1,\n            \"debris IoU\" : debris_iou\n            }\n    \n    return info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:12.784189Z","iopub.execute_input":"2025-05-27T21:18:12.784419Z","iopub.status.idle":"2025-05-27T21:18:12.801503Z","shell.execute_reply.started":"2025-05-27T21:18:12.784395Z","shell.execute_reply":"2025-05-27T21:18:12.800870Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"selected_bands = np.array([ 4, 6, 8, 11]) - 1 #bands conted from 0\n\ntransformTrain = transforms.Compose([transforms.ToTensor(),\n                                    RandomRotationTransform([-90, 0, 90, 180]),\n                                    transforms.RandomHorizontalFlip()])\n    \ntransformTest = transforms.Compose([transforms.ToTensor()])\n    \nstandardization = transforms.Normalize(global_bands_mean[selected_bands].tolist(), global_bands_std[selected_bands].tolist())\nmerged_ds = MergedSegmentationDataset_B(marida_df_F, lr_df_F, global_bands_mean, global_bands_std, selected_bands, transform=transformTrain, standardization= standardization)\nval_ds = MergedSegmentationDataset_B(marida_val_df_F, lr_val_df_F, global_bands_mean, global_bands_std,selected_bands, transform=transformTest, standardization= standardization )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T22:02:20.508562Z","iopub.execute_input":"2025-05-27T22:02:20.508845Z","iopub.status.idle":"2025-05-27T22:02:20.518396Z","shell.execute_reply.started":"2025-05-27T22:02:20.508826Z","shell.execute_reply":"2025-05-27T22:02:20.517520Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"\ntrainLoader = DataLoader(merged_ds,\n                        batch_size=batch_size, \n                        shuffle=True,  \n                        #num_workers=2, \n                        #pin_memory=True,\n                        #prefetch_factor=2,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n\n\ntestLoader = DataLoader(val_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn\n                        # worker_init_fn=worker_init_fn,\n                        # generator=torch.Generator().manual_seed(seed) \n                        )\n                        \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T22:02:20.833398Z","iopub.execute_input":"2025-05-27T22:02:20.833677Z","iopub.status.idle":"2025-05-27T22:02:20.837880Z","shell.execute_reply.started":"2025-05-27T22:02:20.833658Z","shell.execute_reply":"2025-05-27T22:02:20.837149Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"model = ResidualAttentionUNet(len(selected_bands), 2).to(device)\nweight = gen_weights(torch.from_numpy(class_distribution), c = 1.03).to(device)\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean', weight=weight.to(torch.float32))\n#optimizer = torch.optim.Adam(model.parameters(), lr=8e-4, weight_decay=1e-2)\n#optimizer = torch.optim.AdamW(model.parameters(), lr=8e-4, weight_decay=1e-4) good\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4) \n\n# assuming about 40 reductions => .9 ** 40 = 1e-2, starting from 8e-4 ending with 8e-6\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5)\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3) good\n#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n# Updated ReduceLROnPlateau\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode='max',         # Monitor validation loss (lower is better)\n    factor=0.5,         # Reduce LR by 80% (more aggressive to escape plateaus)\n    patience=6,         # Wait 6 epochs for improvement to avoid premature reductions\n    min_lr=1e-6,        # Minimum learning rate\n    threshold=1e-3,     # Minimum improvement in loss\n    verbose=True        # Print LR updates\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T22:02:21.636259Z","iopub.execute_input":"2025-05-27T22:02:21.636949Z","iopub.status.idle":"2025-05-27T22:02:21.823174Z","shell.execute_reply.started":"2025-05-27T22:02:21.636918Z","shell.execute_reply":"2025-05-27T22:02:21.822631Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"best_metric = -float('inf')  # Initialize to negative infinity (for maximization, e.g., accuracy)\nbest_model_path = '/kaggle/working/best_model.pth'\noutput_classes = 2\nmetrics_history = []\npatience = 10  # Number of epochs to wait for improvement\nepochs_no_improve = 0  # Counter for epochs without improvement\nepochs = 60\nfor epoch in range(1, epochs+1):\n    model.train()\n    pb = tqdm(trainLoader, desc=f\"epoch {epoch}/{epochs}: \")\n    yTrue = []\n    yPredicted = []\n\n    bg_yTrue = []\n    bg_yPredicted = []\n    for image, target, _ in pb:\n        image, target = image.to(device), target.to(device)\n        optimizer.zero_grad()\n\n        logits = model(image)\n        # print(f'logits shape : {logits.shape}')\n        # print(f'target shape : {target.shape}')\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        loss = criterion(logits, target)\n\n        loss.backward()\n        optimizer.step()\n        pb.set_postfix(loss=loss.item())\n\n        if epoch % 10 == 0:\n            with torch.no_grad():\n                logits = logits.detach()\n                logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n                logits = logits.reshape((-1,output_classes))\n                target = target.reshape(-1)\n                ###################################################################################\n                mask = target != -1\n                ###################################################################################\n                \n                # bg_logits = logits[~mask]\n                # bg_target = target[~mask]\n    \n                # only considering annotated pixels\n                logits = logits[mask]\n                target = target[mask]\n    \n                probs = F.softmax(logits, dim=1).cpu().numpy()\n                target = target.cpu().numpy()\n                yPredicted += probs.argmax(1).tolist()\n                yTrue += target.tolist()\n        \n                \n                # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n                # bg_target = bg_target.cpu().numpy()\n                \n                # bg_yPredicted += bg_probs.argmax(1).tolist()\n                # bg_yTrue += bg_target.tolist()\n\n\n    if epoch % 10 == 0:\n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        acc = Evaluation(yPredicted, yTrue)\n        print(acc)\n    \n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        # print(\"background:\", bg_acc)\n\n\n    model.eval()\n    yTrue = []\n    yPredicted = []\n    testLossF = []\n    valPrecHistory = []\n    # bg_yTrue = []\n    # bg_yPredicted = []\n    iters = len(testLoader)\n    with torch.no_grad():\n        for i, (image, target, _) in enumerate(testLoader):\n\n            image, target = image.to(device), target.to(device)\n            logits = model(image)\n            # print(f'image dtype {image.dtype}')\n            # print(f'logits dtype {logits.dtype}')\n            # print(f'target dtype {target.dtype}')\n            # print(f'test - target shape {target.shape}')\n            # print(f'test - logit shape {logits.shape}')\n            loss = criterion(logits, target)\n\n            logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n            logits = logits.reshape((-1,output_classes))\n            target = target.reshape(-1)\n            ###################################################################################\n            mask = target != -1\n            ###################################################################################\n            \n            # bg_logits = logits[~mask]\n            # bg_target = target[~mask]\n            \n            logits = logits[mask]\n            target = target[mask]\n            \n\n            probs = F.softmax(logits, dim=1).cpu().numpy()\n            target = target.cpu().numpy()\n            # testBatches += target.shape[0]\n            testLossF.append((loss.data*target.shape[0]).tolist())\n            yPredicted += probs.argmax(1).tolist()\n            yTrue += target.tolist()\n\n            #scheduler.step(epoch + i/iters)\n            # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n            # bg_target = bg_target.cpu().numpy()\n\n            # bg_yPredicted += bg_probs.argmax(1).tolist()\n            # bg_yTrue += bg_target.tolist()\n        \n        yPredicted = np.asarray(yPredicted)\n        yTrue = np.asarray(yTrue)\n        print('########### Validation Set Evaluation : #############')\n        acc = Evaluation(yPredicted, yTrue)\n        metrics_history.append(acc)\n        if acc['debris IoU'] > best_metric:\n            best_metric = acc['debris IoU']\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Saved best model with validation metric: {best_metric}\")\n            epochs_no_improve = 0  # Reset counter\n        else:\n            epochs_no_improve += 1\n            print(f\"No improvement for {epochs_no_improve}/{patience} epochs\")\n        # bg_yPredicted = np.asarray(bg_yPredicted)\n        # bg_yTrue = np.asarray(bg_yTrue)\n        # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n        print(acc)\n        # Early stopping check\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered at epoch {epoch}\")\n            break\n        # print(\"background:\", bg_acc)\n    #scheduler.step(sum(testLossF) / len(testLoader.dataset))\n    scheduler.step(acc['debris IoU'])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T22:02:25.989874Z","iopub.execute_input":"2025-05-27T22:02:25.990515Z","iopub.status.idle":"2025-05-27T23:55:28.807119Z","shell.execute_reply.started":"2025-05-27T22:02:25.990493Z","shell.execute_reply":"2025-05-27T23:55:28.806436Z"}},"outputs":[{"name":"stderr","text":"epoch 1/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.34it/s, loss=0.259] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.5495457016385804\n{'macroPrec': 0.7834662477251042, 'microPrec': 0.9713144750506899, 'weightPrec': 0.9817105322666912, 'macroRec': 0.9565740626104935, 'microRec': 0.9713144750506899, 'weightRec': 0.9713144750506899, 'macroF1': 0.8471059901115372, 'microF1': 0.9713144750506899, 'weightF1': 0.9746589546156926, 'subsetAcc': 0.9713144750506899, 'IoU': 0.7599099492672758, 'debris Prec': 0.569285225855758, 'debris Rec': 0.9406486773893393, 'debris F1': 0.709299120455058, 'debris IoU': 0.5495457016385804}\n","output_type":"stream"},{"name":"stderr","text":"epoch 2/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0932]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6501369863013698\n{'macroPrec': 0.8364674073965365, 'microPrec': 0.9810543494387023, 'weightPrec': 0.985880886014785, 'macroRec': 0.9643477029907495, 'microRec': 0.9810543494387023, 'weightRec': 0.9810543494387023, 'macroF1': 0.8890317792672602, 'microF1': 0.9810543494387023, 'weightF1': 0.9825650625858465, 'subsetAcc': 0.9810543494387023, 'IoU': 0.8152499981919221, 'debris Prec': 0.6750426702067135, 'debris Rec': 0.9462980194071514, 'debris F1': 0.7879794122530301, 'debris IoU': 0.6501369863013698}\n","output_type":"stream"},{"name":"stderr","text":"epoch 3/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.0413]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.5938034708089082, 'microPrec': 0.8514415706443796, 'weightPrec': 0.96662953366442, 'macroRec': 0.8868459044669185, 'microRec': 0.8514415706443796, 'weightRec': 0.8514415706443796, 'macroF1': 0.6166491151876661, 'microF1': 0.8514415706443796, 'weightF1': 0.8943389568512281, 'subsetAcc': 0.8514415706443796, 'IoU': 0.5171217485742654, 'debris Prec': 0.19100614776594577, 'debris Rec': 0.9250963711285392, 'debris F1': 0.31663595623194346, 'debris IoU': 0.18809713644778983}\n","output_type":"stream"},{"name":"stderr","text":"epoch 4/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.059] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8123939771675652, 'microPrec': 0.9768977795361258, 'weightPrec': 0.9836057797294666, 'macroRec': 0.9558954896632308, 'microRec': 0.9768977795361258, 'weightRec': 0.9768977795361258, 'macroF1': 0.8691212660235097, 'microF1': 0.9768977795361258, 'weightF1': 0.9790512834628498, 'subsetAcc': 0.9768977795361258, 'IoU': 0.7882600746303878, 'debris Prec': 0.6274185620447741, 'debris Rec': 0.9332048384952811, 'debris F1': 0.7503540414161656, 'debris IoU': 0.6004533014026685}\n","output_type":"stream"},{"name":"stderr","text":"epoch 5/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.0529]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.7988365930163375, 'microPrec': 0.9745091736313733, 'weightPrec': 0.9830576099327958, 'macroRec': 0.9608208680983721, 'microRec': 0.9745091736313733, 'weightRec': 0.9745091736313733, 'macroF1': 0.860379656894511, 'microF1': 0.9745091736313733, 'weightF1': 0.977220055154771, 'subsetAcc': 0.9745091736313733, 'IoU': 0.7767704835987401, 'debris Prec': 0.5998061607180482, 'debris Rec': 0.9460321680180779, 'debris F1': 0.7341465301596307, 'debris IoU': 0.5799616998736911}\n","output_type":"stream"},{"name":"stderr","text":"epoch 6/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0753]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6692496321726337\n{'macroPrec': 0.8574782120683768, 'microPrec': 0.9833242668512933, 'weightPrec': 0.9860332333400162, 'macroRec': 0.9466137099945197, 'microRec': 0.9833242668512933, 'weightRec': 0.9833242668512933, 'macroF1': 0.896576360328458, 'microF1': 0.9833242668512933, 'weightF1': 0.984247993965116, 'subsetAcc': 0.9833242668512933, 'IoU': 0.8259957875429644, 'debris Prec': 0.7185887309110058, 'debris Rec': 0.9069520138242723, 'debris F1': 0.8018568574450583, 'debris IoU': 0.6692496321726337}\n","output_type":"stream"},{"name":"stderr","text":"epoch 7/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.34it/s, loss=0.065] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6811531218310879\n{'macroPrec': 0.8555488147502432, 'microPrec': 0.983672914297018, 'weightPrec': 0.9869897680862398, 'macroRec': 0.9614905329956027, 'microRec': 0.983672914297018, 'weightRec': 0.983672914297018, 'macroF1': 0.9009048191592262, 'microF1': 0.983672914297018, 'weightF1': 0.9847305669622575, 'subsetAcc': 0.983672914297018, 'IoU': 0.8321179865369668, 'debris Prec': 0.7135414032070413, 'debris Rec': 0.9375249235677257, 'debris F1': 0.810340370529944, 'debris IoU': 0.6811531218310879}\n","output_type":"stream"},{"name":"stderr","text":"epoch 8/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.194] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.6913598574821853\n{'macroPrec': 0.8637071155411296, 'microPrec': 0.9845779140497503, 'weightPrec': 0.987276226527586, 'macroRec': 0.9576476311410138, 'microRec': 0.9845779140497503, 'weightRec': 0.9845779140497503, 'macroF1': 0.9047341329108082, 'microF1': 0.9845779140497503, 'weightF1': 0.9854592900548789, 'subsetAcc': 0.9845779140497503, 'IoU': 0.8376929701370239, 'debris Prec': 0.7302043589609575, 'debris Rec': 0.9285524391864948, 'debris F1': 0.8175195295356797, 'debris IoU': 0.6913598574821853}\n","output_type":"stream"},{"name":"stderr","text":"epoch 9/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0194]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8534814642220412, 'microPrec': 0.9835146629741358, 'weightPrec': 0.9870727871035864, 'macroRec': 0.9645711336065005, 'microRec': 0.9835146629741358, 'weightRec': 0.9835146629741358, 'macroF1': 0.9006580504668019, 'microF1': 0.9835146629741358, 'weightF1': 0.9846329736321124, 'subsetAcc': 0.9835146629741358, 'IoU': 0.8317456982381095, 'debris Prec': 0.709150816234836, 'debris Rec': 0.944104745447295, 'debris F1': 0.8099324343586966, 'debris IoU': 0.6805768493675738}\n","output_type":"stream"},{"name":"stderr","text":"epoch 10/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.162] \n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8642989101270806, 'microPrec': 0.9800955987271022, 'weightPrec': 0.9845368517617579, 'macroRec': 0.9741259680658907, 'microRec': 0.9800955987271022, 'weightRec': 0.9800955987271022, 'macroF1': 0.9108966274641543, 'microF1': 0.9800955987271022, 'weightF1': 0.9813976540264074, 'subsetAcc': 0.9800955987271022, 'IoU': 0.8459687466774775, 'debris Prec': 0.7303796681787112, 'debris Rec': 0.9674770816828372, 'debris F1': 0.8323736262763514, 'debris IoU': 0.7128766915583185}\n########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.5777972526064388, 'microPrec': 0.814042332228871, 'weightPrec': 0.9655496934126343, 'macroRec': 0.8702989617104746, 'microRec': 0.814042332228871, 'weightRec': 0.814042332228871, 'macroF1': 0.5824256362523088, 'microF1': 0.814042332228871, 'weightF1': 0.8702791493069361, 'subsetAcc': 0.814042332228871, 'IoU': 0.48219829671253056, 'debris Prec': 0.15887362917767672, 'debris Rec': 0.9310780273826931, 'debris F1': 0.27143175455082685, 'debris IoU': 0.15702692402537718}\n","output_type":"stream"},{"name":"stderr","text":"epoch 11/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.0298]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8345457270047285, 'microPrec': 0.9809678057465011, 'weightPrec': 0.9862215642295896, 'macroRec': 0.9707241686036918, 'microRec': 0.9809678057465011, 'weightRec': 0.9809678057465011, 'macroF1': 0.8897944607189354, 'microF1': 0.9809678057465011, 'weightF1': 0.9825746694956721, 'subsetAcc': 0.9809678057465011, 'IoU': 0.816274505098604, 'debris Prec': 0.6706767615774072, 'debris Rec': 0.9596570517080951, 'debris F1': 0.7895557074504442, 'debris IoU': 0.6522858691723888}\n","output_type":"stream"},{"name":"stderr","text":"epoch 12/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.0675]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7047850770478508\n{'macroPrec': 0.8725650690427131, 'microPrec': 0.9855991296177241, 'weightPrec': 0.987778259657564, 'macroRec': 0.9560374997321595, 'microRec': 0.9855991296177241, 'weightRec': 0.9855991296177241, 'macroF1': 0.9096593832988991, 'microF1': 0.9855991296177241, 'weightF1': 0.9863241441866116, 'subsetAcc': 0.9855991296177241, 'IoU': 0.8449357377782454, 'debris Prec': 0.7480899601850856, 'debris Rec': 0.9240994284195135, 'debris F1': 0.8268315889628925, 'debris IoU': 0.7047850770478508}\n","output_type":"stream"},{"name":"stderr","text":"epoch 13/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.247] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8427368882810363, 'microPrec': 0.9819544038375946, 'weightPrec': 0.9862435638421295, 'macroRec': 0.9634094382292859, 'microRec': 0.9819544038375946, 'weightRec': 0.9819544038375946, 'macroF1': 0.8930273866879468, 'microF1': 0.9819544038375946, 'weightF1': 0.9833035002971973, 'subsetAcc': 0.9819544038375946, 'IoU': 0.8208649028095121, 'debris Prec': 0.6876937984496124, 'debris Rec': 0.9433736541273429, 'debris F1': 0.7954940312727681, 'debris IoU': 0.6604317885724921}\n","output_type":"stream"},{"name":"stderr","text":"epoch 14/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0841]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8535798958788836, 'microPrec': 0.9829657286978883, 'weightPrec': 0.9860306570310619, 'macroRec': 0.9502931383433122, 'microRec': 0.9829657286978883, 'weightRec': 0.9829657286978883, 'macroF1': 0.8954882271735138, 'microF1': 0.9829657286978883, 'weightF1': 0.9839896966195255, 'subsetAcc': 0.9829657286978883, 'IoU': 0.8244272898698327, 'debris Prec': 0.7104814986840068, 'debris Rec': 0.9149940183437458, 'debris F1': 0.799872178485315, 'debris IoU': 0.6664891556932611}\n","output_type":"stream"},{"name":"stderr","text":"epoch 15/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.999] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8520922356292662, 'microPrec': 0.9812917264230255, 'weightPrec': 0.9832012993521605, 'macroRec': 0.9129719121521848, 'microRec': 0.9812917264230255, 'weightRec': 0.9812917264230255, 'macroF1': 0.8798530314341702, 'microF1': 0.9812917264230255, 'weightF1': 0.9820358609608905, 'subsetAcc': 0.9812917264230255, 'IoU': 0.8029929893803874, 'debris Prec': 0.7104433941030835, 'debris Rec': 0.8391599096105277, 'debris F1': 0.7694557864586508, 'debris IoU': 0.625297147385103}\n","output_type":"stream"},{"name":"stderr","text":"epoch 16/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.229] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7163545700493342\n{'macroPrec': 0.8880944055790091, 'microPrec': 0.9867785965085802, 'weightPrec': 0.9879863905392974, 'macroRec': 0.9438710968946422, 'microRec': 0.9867785965085802, 'weightRec': 0.9867785965085802, 'macroF1': 0.9139267237060202, 'microF1': 0.9867785965085802, 'weightF1': 0.9872217013105696, 'subsetAcc': 0.9867785965085802, 'IoU': 0.8513382198546562, 'debris Prec': 0.7801721647697729, 'debris Rec': 0.8975142895121627, 'debris F1': 0.834739607479524, 'debris IoU': 0.7163545700493342}\n","output_type":"stream"},{"name":"stderr","text":"epoch 17/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0793]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8399761770176791, 'microPrec': 0.9810617674694624, 'weightPrec': 0.9850194516586848, 'macroRec': 0.949400213692561, 'microRec': 0.9810617674694624, 'weightRec': 0.9810617674694624, 'macroF1': 0.8862543252415009, 'microF1': 0.9810617674694624, 'weightF1': 0.9823731273527254, 'subsetAcc': 0.9810617674694624, 'IoU': 0.8114906815136448, 'debris Prec': 0.6832729618419094, 'debris Rec': 0.915193406885551, 'debris F1': 0.7824085911531578, 'debris IoU': 0.6425871482570349}\n","output_type":"stream"},{"name":"stderr","text":"epoch 18/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0805]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8762177546477833, 'microPrec': 0.9857549082636863, 'weightPrec': 0.9875979141514796, 'macroRec': 0.9500484096907947, 'microRec': 0.9857549082636863, 'weightRec': 0.9857549082636863, 'macroF1': 0.9094955410943109, 'microF1': 0.9857549082636863, 'weightF1': 0.9863911031399858, 'subsetAcc': 0.9857549082636863, 'IoU': 0.8447198749596423, 'debris Prec': 0.7558838119384886, 'debris Rec': 0.9114714874385219, 'debris F1': 0.8264183916357829, 'debris IoU': 0.7041848523748395}\n","output_type":"stream"},{"name":"stderr","text":"epoch 19/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0427]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8281859612875843, 'microPrec': 0.9798551011324861, 'weightPrec': 0.9855392363990358, 'macroRec': 0.9673988492403859, 'microRec': 0.9798551011324861, 'weightRec': 0.9798551011324861, 'macroF1': 0.8841896145756463, 'microF1': 0.9798551011324861, 'weightF1': 0.9816147649614226, 'subsetAcc': 0.9798551011324861, 'IoU': 0.8085124778278832, 'debris Prec': 0.6581831521988353, 'debris Rec': 0.9539412468430147, 'debris F1': 0.7789325156703661, 'debris IoU': 0.6379111111111111}\n","output_type":"stream"},{"name":"stderr","text":"epoch 20/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.181] \n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8661559521575233, 'microPrec': 0.9805333872904672, 'weightPrec': 0.9848972557786169, 'macroRec': 0.9759969861295186, 'microRec': 0.9805333872904672, 'weightRec': 0.9805333872904672, 'macroF1': 0.9127989211227786, 'microF1': 0.9805333872904672, 'weightF1': 0.9818013432859853, 'subsetAcc': 0.9805333872904672, 'IoU': 0.8488247365884314, 'debris Prec': 0.7339036435042968, 'debris Rec': 0.9709444095768214, 'debris F1': 0.8359450433611777, 'debris IoU': 0.7181319392126871}\n########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8755324307674864, 'microPrec': 0.9861628999554918, 'weightPrec': 0.9883202615975362, 'macroRec': 0.9606112170691736, 'microRec': 0.9861628999554918, 'weightRec': 0.9861628999554918, 'macroF1': 0.9132947126661417, 'microF1': 0.9861628999554918, 'weightF1': 0.9868665264362709, 'subsetAcc': 0.9861628999554918, 'IoU': 0.850324766873189, 'debris Prec': 0.7536776548910126, 'debris Rec': 0.933005449953476, 'debris F1': 0.8338085055832739, 'debris IoU': 0.7149842110624427}\n","output_type":"stream"},{"name":"stderr","text":"epoch 21/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.222] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.8582782431434464, 'microPrec': 0.9839053459275011, 'weightPrec': 0.986944572718176, 'macroRec': 0.9582887192021845, 'microRec': 0.9839053459275011, 'weightRec': 0.9839053459275011, 'macroF1': 0.9014991944975908, 'microF1': 0.9839053459275011, 'weightF1': 0.9848902356307823, 'subsetAcc': 0.9839053459275011, 'IoU': 0.8329931055726256, 'debris Prec': 0.7192685056762727, 'debris Rec': 0.9306127874518144, 'debris F1': 0.8114043983426534, 'debris IoU': 0.6826580859051241}\n","output_type":"stream"},{"name":"stderr","text":"epoch 22/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.036] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 6/10 epochs\n{'macroPrec': 0.8581990182601991, 'microPrec': 0.9841303595272242, 'weightPrec': 0.9873628365246745, 'macroRec': 0.9640602475149802, 'microRec': 0.9841303595272242, 'weightRec': 0.9841303595272242, 'macroF1': 0.9035780654672183, 'microF1': 0.9841303595272242, 'weightF1': 0.9851510901366133, 'subsetAcc': 0.9841303595272242, 'IoU': 0.8359774880800915, 'debris Prec': 0.7186517992904207, 'debris Rec': 0.9423767114183171, 'debris F1': 0.8154474350126524, 'debris IoU': 0.6884012234791475}\n","output_type":"stream"},{"name":"stderr","text":"epoch 23/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0342]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 7/10 epochs\n{'macroPrec': 0.8615607104151672, 'microPrec': 0.9837372038969389, 'weightPrec': 0.9861407566471673, 'macroRec': 0.9441765299446716, 'microRec': 0.9837372038969389, 'weightRec': 0.9837372038969389, 'macroF1': 0.8981846077962006, 'microF1': 0.9837372038969389, 'weightF1': 0.9845705361275077, 'subsetAcc': 0.9837372038969389, 'IoU': 0.8283044111640817, 'debris Prec': 0.7269657501205982, 'debris Rec': 0.9014355975009969, 'debris F1': 0.8048541672848115, 'debris IoU': 0.6734359483614697}\n","output_type":"stream"},{"name":"stderr","text":"epoch 24/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.208] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 8/10 epochs\n{'macroPrec': 0.8662794324127282, 'microPrec': 0.9852059739874388, 'weightPrec': 0.9879712236515773, 'macroRec': 0.9646827310518684, 'microRec': 0.9852059739874388, 'weightRec': 0.9852059739874388, 'macroF1': 0.9090360127600265, 'microF1': 0.9852059739874388, 'weightF1': 0.9860813393731044, 'subsetAcc': 0.9852059739874388, 'IoU': 0.8439757243253061, 'debris Prec': 0.7348049121716151, 'debris Rec': 0.942509637112854, 'debris F1': 0.8257970592517107, 'debris IoU': 0.7032830787542155}\n","output_type":"stream"},{"name":"stderr","text":"epoch 25/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0708]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7282675709001233\n{'macroPrec': 0.8800631021638772, 'microPrec': 0.9869220117699421, 'weightPrec': 0.988986246303633, 'macroRec': 0.9653822212230743, 'microRec': 0.9869220117699421, 'weightRec': 0.9869220117699421, 'macroF1': 0.9179745180677394, 'microF1': 0.9869220117699421, 'weightF1': 0.987581583754919, 'subsetAcc': 0.9869220117699421, 'IoU': 0.8573572732590022, 'debris Prec': 0.7623836927876082, 'debris Rec': 0.9421108600292436, 'debris F1': 0.8427717827521627, 'debris IoU': 0.7282675709001233}\n","output_type":"stream"},{"name":"stderr","text":"epoch 26/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0443]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8659399053485509, 'microPrec': 0.9851688838336383, 'weightPrec': 0.9879578429117483, 'macroRec': 0.9648232059210962, 'microRec': 0.9851688838336383, 'weightRec': 0.9851688838336383, 'macroF1': 0.9088713462164044, 'microF1': 0.9851688838336383, 'weightF1': 0.9860509291408307, 'subsetAcc': 0.9851688838336383, 'IoU': 0.8437318314215898, 'debris Prec': 0.7341130200786586, 'debris Rec': 0.9428419513491958, 'debris F1': 0.8254873436136164, 'debris IoU': 0.7028339278636544}\n","output_type":"stream"},{"name":"stderr","text":"epoch 27/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0438]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8810164790713874, 'microPrec': 0.9867860145393403, 'weightPrec': 0.9886726608834208, 'macroRec': 0.9601680779373688, 'microRec': 0.9867860145393403, 'weightRec': 0.9867860145393403, 'macroF1': 0.9164872166609603, 'microF1': 0.9867860145393403, 'weightF1': 0.9874074437265103, 'subsetAcc': 0.9867860145393403, 'IoU': 0.8551250545871819, 'debris Prec': 0.7647058823529411, 'debris Rec': 0.9314103416190349, 'debris F1': 0.8398657557233609, 'debris IoU': 0.7239384233908461}\n","output_type":"stream"},{"name":"stderr","text":"epoch 28/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0557]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8845675705107201, 'microPrec': 0.9867835418624202, 'weightPrec': 0.9883106094191769, 'macroRec': 0.9517646509827329, 'microRec': 0.9867835418624202, 'weightRec': 0.9867835418624202, 'macroF1': 0.9151939529944368, 'microF1': 0.9867835418624202, 'weightF1': 0.9873143374727883, 'subsetAcc': 0.9867835418624202, 'IoU': 0.853208395519609, 'debris Prec': 0.7724846918712431, 'debris Rec': 0.9139306127874518, 'debris F1': 0.8372758547203701, 'debris IoU': 0.7200984499371597}\n","output_type":"stream"},{"name":"stderr","text":"epoch 29/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0163]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8834626068927587, 'microPrec': 0.9869442658622224, 'weightPrec': 0.9886596674828382, 'macroRec': 0.9576305816166506, 'microRec': 0.9869442658622224, 'weightRec': 0.9869442658622224, 'macroF1': 0.9169441790770889, 'microF1': 0.9869442658622224, 'weightF1': 0.9875196875562403, 'subsetAcc': 0.9869442658622224, 'IoU': 0.8558251126849574, 'debris Prec': 0.7698088186539949, 'debris Rec': 0.9259603881430281, 'debris F1': 0.8406951484431571, 'debris IoU': 0.7251717676452217}\n","output_type":"stream"},{"name":"stderr","text":"epoch 30/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0449]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8819443501983337, 'microPrec': 0.9834686203353576, 'weightPrec': 0.986749662379853, 'macroRec': 0.9798167176176439, 'microRec': 0.9834686203353576, 'weightRec': 0.9834686203353576, 'macroF1': 0.924487905020587, 'microF1': 0.9834686203353576, 'weightF1': 0.9844065285334337, 'subsetAcc': 0.9834686203353576, 'IoU': 0.8667669088925326, 'debris Prec': 0.7652137427985863, 'debris Rec': 0.9757492823557252, 'debris F1': 0.8577514279124666, 'debris IoU': 0.7509323704777062}\n########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.8598973737572068, 'microPrec': 0.9838583650660204, 'weightPrec': 0.9866014399971189, 'macroRec': 0.9520665426954047, 'microRec': 0.9838583650660204, 'weightRec': 0.9838583650660204, 'macroF1': 0.9001916078864066, 'microF1': 0.9838583650660204, 'weightF1': 0.9847739461463275, 'subsetAcc': 0.9838583650660204, 'IoU': 0.8311403413891137, 'debris Prec': 0.723007644779558, 'debris Rec': 0.9177189950817493, 'debris F1': 0.8088097469540767, 'debris IoU': 0.6789929189614476}\n","output_type":"stream"},{"name":"stderr","text":"epoch 31/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0932]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7459641373507914\n{'macroPrec': 0.8895350037001168, 'microPrec': 0.9880544977993175, 'weightPrec': 0.9897197471902137, 'macroRec': 0.9663217651469305, 'microRec': 0.9880544977993175, 'weightRec': 0.9880544977993175, 'macroF1': 0.92413633513899, 'microF1': 0.9880544977993175, 'weightF1': 0.9885901667046649, 'subsetAcc': 0.9880544977993175, 'IoU': 0.8667921928572968, 'debris Prec': 0.7812964696811148, 'debris Rec': 0.9428419513491958, 'debris F1': 0.8545010992982561, 'debris IoU': 0.7459641373507914}\n","output_type":"stream"},{"name":"stderr","text":"epoch 32/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0388]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8460167148408451, 'microPrec': 0.9827283517135651, 'weightPrec': 0.9870778186521595, 'macroRec': 0.971638456666069, 'microRec': 0.9827283517135651, 'weightRec': 0.9827283517135651, 'macroF1': 0.8980972633287818, 'microF1': 0.9827283517135651, 'weightF1': 0.9840535361791121, 'subsetAcc': 0.9827283517135651, 'IoU': 0.8280263249678932, 'debris Prec': 0.69361579478311, 'debris Rec': 0.9596570517080951, 'debris F1': 0.8052310180408778, 'debris IoU': 0.6739637789395071}\n","output_type":"stream"},{"name":"stderr","text":"epoch 33/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:27<00:00,  1.36it/s, loss=0.0652]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8701948159210626, 'microPrec': 0.9859453043865288, 'weightPrec': 0.988654191389395, 'macroRec': 0.9702740923970548, 'microRec': 0.9859453043865288, 'weightRec': 0.9859453043865288, 'macroF1': 0.913646804554269, 'microF1': 0.9859453043865288, 'weightF1': 0.9867815136871657, 'subsetAcc': 0.9859453043865288, 'IoU': 0.8508129021752671, 'debris Prec': 0.742212563386112, 'debris Rec': 0.9533430812175994, 'debris F1': 0.8346328406842779, 'debris IoU': 0.7161973237467545}\n","output_type":"stream"},{"name":"stderr","text":"epoch 34/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0677]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8818775953823784, 'microPrec': 0.9864670392166559, 'weightPrec': 0.9880975337722007, 'macroRec': 0.9514405480335615, 'microRec': 0.9864670392166559, 'weightRec': 0.9864670392166559, 'macroF1': 0.9134607285810282, 'microF1': 0.9864670392166559, 'weightF1': 0.9870317028514333, 'subsetAcc': 0.9864670392166559, 'IoU': 0.8506102989466757, 'debris Prec': 0.7671187008203583, 'debris Rec': 0.91359829855111, 'debris F1': 0.8339754284847566, 'debris IoU': 0.7152297205890005}\n","output_type":"stream"},{"name":"stderr","text":"epoch 35/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.35it/s, loss=0.0222]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7787830807509614\n{'macroPrec': 0.9179804713313882, 'microPrec': 0.9903268878888285, 'weightPrec': 0.9908579993645246, 'macroRec': 0.954275677654439, 'microRec': 0.9903268878888285, 'weightRec': 0.9903268878888285, 'macroF1': 0.9353017733503143, 'microF1': 0.9903268878888285, 'weightF1': 0.9905281251563143, 'subsetAcc': 0.9903268878888285, 'IoU': 0.8843844751914787, 'debris Prec': 0.8392443631931749, 'debris Rec': 0.9153263325800878, 'debris F1': 0.8756358087487283, 'debris IoU': 0.7787830807509614}\n","output_type":"stream"},{"name":"stderr","text":"epoch 36/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:32<00:00,  1.30it/s, loss=0.0486]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8923097767927319, 'microPrec': 0.9880841699223579, 'weightPrec': 0.989513948537982, 'macroRec': 0.9608102896609402, 'microRec': 0.9880841699223579, 'weightRec': 0.9880841699223579, 'macroF1': 0.9235352343235823, 'microF1': 0.9880841699223579, 'weightF1': 0.988562413129526, 'subsetAcc': 0.9880841699223579, 'IoU': 0.8658811243618431, 'debris Prec': 0.7872914208663409, 'debris Rec': 0.9313438787717666, 'debris F1': 0.853280560207033, 'debris IoU': 0.7441057774001699}\n","output_type":"stream"},{"name":"stderr","text":"epoch 37/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:31<00:00,  1.31it/s, loss=0.0458]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.8995759195438442, 'microPrec': 0.9893254537362148, 'weightPrec': 0.9906722053705164, 'macroRec': 0.9696973203956676, 'microRec': 0.9893254537362148, 'weightRec': 0.9893254537362148, 'macroF1': 0.9315285943667917, 'microF1': 0.9893254537362148, 'weightF1': 0.9897558646509103, 'subsetAcc': 0.9893254537362148, 'IoU': 0.8783441929564507, 'debris Prec': 0.8011564587660698, 'debris Rec': 0.9484912933670079, 'debris F1': 0.8686204692778235, 'debris IoU': 0.7677533892834086}\n","output_type":"stream"},{"name":"stderr","text":"epoch 38/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0414]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.8729968037919301, 'microPrec': 0.9863063152168537, 'weightPrec': 0.9888681083952892, 'macroRec': 0.9705254674367139, 'microRec': 0.9863063152168537, 'weightRec': 0.9863063152168537, 'macroF1': 0.9155313452187486, 'microF1': 0.9863063152168537, 'weightF1': 0.9870974409248745, 'subsetAcc': 0.9863063152168537, 'IoU': 0.8536436522950697, 'debris Prec': 0.7478106755629691, 'debris Rec': 0.9534760069121361, 'debris F1': 0.8382120946538124, 'debris IoU': 0.7214846107423054}\n","output_type":"stream"},{"name":"stderr","text":"epoch 39/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0568]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.877508495615061, 'microPrec': 0.9867761238316601, 'weightPrec': 0.9890539481983838, 'macroRec': 0.9687567681968912, 'microRec': 0.9867761238316601, 'weightRec': 0.9867761238316601, 'macroF1': 0.9177028538644945, 'microF1': 0.9867761238316601, 'weightF1': 0.987488657603892, 'subsetAcc': 0.9867761238316601, 'IoU': 0.8569328651409068, 'debris Prec': 0.7569959720161119, 'debris Rec': 0.9492888475342284, 'debris F1': 0.8423070118535119, 'debris IoU': 0.7275737354184708}\n","output_type":"stream"},{"name":"stderr","text":"epoch 40/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.196] \n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.88874702432685, 'microPrec': 0.9846416624403165, 'weightPrec': 0.987499923407684, 'macroRec': 0.9809556314791028, 'microRec': 0.9846416624403165, 'weightRec': 0.9846416624403165, 'macroF1': 0.9292398498762104, 'microF1': 0.9846416624403165, 'weightF1': 0.9854551987462771, 'subsetAcc': 0.9846416624403165, 'IoU': 0.8742403911134728, 'debris Prec': 0.7787575051674924, 'debris Rec': 0.9768501846840821, 'debris F1': 0.8666280253207308, 'debris IoU': 0.7646457162186105}\n########### Validation Set Evaluation : #############\nNo improvement for 5/10 epochs\n{'macroPrec': 0.8820550324165173, 'microPrec': 0.9869071757084219, 'weightPrec': 0.9887478670977146, 'macroRec': 0.9601990521360926, 'microRec': 0.9869071757084219, 'weightRec': 0.9869071757084219, 'macroF1': 0.9171317590139106, 'microF1': 0.9869071757084219, 'weightF1': 0.9875143043196729, 'subsetAcc': 0.9869071757084219, 'IoU': 0.8560992866692705, 'debris Prec': 0.7667852257181943, 'debris Rec': 0.9313438787717666, 'debris F1': 0.8410912037453858, 'debris IoU': 0.7257613424487259}\n","output_type":"stream"},{"name":"stderr","text":"epoch 41/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0321]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 6/10 epochs\n{'macroPrec': 0.8760063597552865, 'microPrec': 0.9865511102319371, 'weightPrec': 0.9888795679308855, 'macroRec': 0.967809283873337, 'microRec': 0.9865511102319371, 'weightRec': 0.9865511102319371, 'macroF1': 0.9163944409481132, 'microF1': 0.9865511102319371, 'weightF1': 0.9872822816995842, 'subsetAcc': 0.9865511102319371, 'IoU': 0.8549561156955308, 'debris Prec': 0.754059343100439, 'debris Rec': 0.9475608135052506, 'debris F1': 0.8398079698406622, 'debris IoU': 0.7238525588952072}\n","output_type":"stream"},{"name":"stderr","text":"epoch 42/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:33<00:00,  1.28it/s, loss=0.146] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 7/10 epochs\n{'macroPrec': 0.89273465780712, 'microPrec': 0.9876563968151921, 'weightPrec': 0.9888664938732362, 'macroRec': 0.9514831545192782, 'microRec': 0.9876563968151921, 'weightRec': 0.9876563968151921, 'macroF1': 0.9198620522384806, 'microF1': 0.9876563968151921, 'weightF1': 0.988085793317678, 'subsetAcc': 0.9876563968151921, 'IoU': 0.860278002450353, 'debris Prec': 0.7888748419721872, 'debris Rec': 0.9124019673002791, 'debris F1': 0.8461538461538461, 'debris IoU': 0.7333333333333333}\n","output_type":"stream"},{"name":"stderr","text":"epoch 43/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:33<00:00,  1.28it/s, loss=0.0802]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 8/10 epochs\n{'macroPrec': 0.9086590149031274, 'microPrec': 0.9892537461055338, 'weightPrec': 0.9899618072256516, 'macroRec': 0.9510347987126616, 'microRec': 0.9892537461055338, 'weightRec': 0.9892537461055338, 'macroF1': 0.9287024153297727, 'microF1': 0.9892537461055338, 'weightF1': 0.9895185682112722, 'subsetAcc': 0.9892537461055338, 'IoU': 0.8739440220958763, 'debris Prec': 0.8208203406092588, 'debris Rec': 0.9097434534095441, 'debris F1': 0.8629972889477334, 'debris IoU': 0.7590107574581346}\n","output_type":"stream"},{"name":"stderr","text":"epoch 44/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0336]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 9/10 epochs\n{'macroPrec': 0.9040770966761651, 'microPrec': 0.9895232678898175, 'weightPrec': 0.9906120987000494, 'macroRec': 0.9644967957343933, 'microRec': 0.9895232678898175, 'weightRec': 0.9895232678898175, 'macroF1': 0.9319802660448373, 'microF1': 0.9895232678898175, 'weightF1': 0.9898875786579242, 'subsetAcc': 0.9895232678898175, 'IoU': 0.8790723871228354, 'debris Prec': 0.8105855985288202, 'debris Rec': 0.9374584607204572, 'debris F1': 0.86941781982926, 'debris IoU': 0.7690001090393632}\n","output_type":"stream"},{"name":"stderr","text":"epoch 45/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0618]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7836696644000878\n{'macroPrec': 0.9077824742272932, 'microPrec': 0.9902452895504673, 'weightPrec': 0.9913322707787093, 'macroRec': 0.9708139564497511, 'microRec': 0.9902452895504673, 'weightRec': 0.9902452895504673, 'macroF1': 0.9368172151682874, 'microF1': 0.9902452895504673, 'weightF1': 0.9905951142611249, 'subsetAcc': 0.9902452895504673, 'IoU': 0.8867788122681752, 'debris Prec': 0.8175161604027229, 'debris Rec': 0.9498205503123753, 'debris F1': 0.8787161435115443, 'debris IoU': 0.7836696644000878}\n","output_type":"stream"},{"name":"stderr","text":"epoch 46/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:35<00:00,  1.26it/s, loss=0.02]  \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.9178652016436601, 'microPrec': 0.9905049206270709, 'weightPrec': 0.9910894186082269, 'macroRec': 0.9575948121805244, 'microRec': 0.9905049206270709, 'weightRec': 0.9905049206270709, 'macroF1': 0.9367433406794063, 'microF1': 0.9905049206270709, 'weightF1': 0.9907203510879242, 'subsetAcc': 0.9905049206270709, 'IoU': 0.8866888541862217, 'debris Prec': 0.8387545344619105, 'debris Rec': 0.9220390801541938, 'debris F1': 0.8784271512695497, 'debris IoU': 0.7832100716987523}\n","output_type":"stream"},{"name":"stderr","text":"epoch 47/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:35<00:00,  1.26it/s, loss=0.0339]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.9135094755219699, 'microPrec': 0.9899065328124227, 'weightPrec': 0.9905453289727723, 'macroRec': 0.9543449043391052, 'microRec': 0.9899065328124227, 'weightRec': 0.9899065328124227, 'macroF1': 0.9328750936742451, 'microF1': 0.9899065328124227, 'weightF1': 0.990143975119713, 'subsetAcc': 0.9899065328124227, 'IoU': 0.8805167040514662, 'debris Prec': 0.8302807567176769, 'debris Rec': 0.9159244982055031, 'debris F1': 0.8710024017191251, 'debris IoU': 0.7714829535912221}\n","output_type":"stream"},{"name":"stderr","text":"epoch 48/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0344] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.9151360076107714, 'microPrec': 0.9901092923198654, 'weightPrec': 0.9907215235295688, 'macroRec': 0.955184989717074, 'microRec': 0.9901092923198654, 'weightRec': 0.9901092923198654, 'macroF1': 0.9341516455306117, 'microF1': 0.9901092923198654, 'weightF1': 0.9903368380869882, 'subsetAcc': 0.9901092923198654, 'IoU': 0.8825455751351556, 'debris Prec': 0.8334742180896028, 'debris Rec': 0.9174531436926758, 'debris F1': 0.8734497595545432, 'debris IoU': 0.7753313862053471}\n","output_type":"stream"},{"name":"stderr","text":"epoch 49/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0364]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.9054452896546126, 'microPrec': 0.9897210820434202, 'weightPrec': 0.9907857633176135, 'macroRec': 0.9655579440657769, 'microRec': 0.9897210820434202, 'weightRec': 0.9897210820434202, 'macroF1': 0.9332251256730411, 'microF1': 0.9897210820434202, 'weightF1': 0.9900757071522929, 'subsetAcc': 0.9897210820434202, 'IoU': 0.8810454957891697, 'debris Prec': 0.8132443472757609, 'debris Rec': 0.9394523461385086, 'debris F1': 0.8718043605637278, 'debris IoU': 0.7727421823748086}\n","output_type":"stream"},{"name":"stderr","text":"epoch 50/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:35<00:00,  1.26it/s, loss=0.0155]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8976601098587045, 'microPrec': 0.9861326662269511, 'weightPrec': 0.9884951572644509, 'macroRec': 0.9825443979593373, 'microRec': 0.9861326662269511, 'weightRec': 0.9861326662269511, 'macroF1': 0.9354149827689056, 'microF1': 0.9861326662269511, 'weightF1': 0.9868009037700917, 'subsetAcc': 0.9861326662269511, 'IoU': 0.8841117967830093, 'debris Prec': 0.7964893768476413, 'debris Rec': 0.9785478378072495, 'debris F1': 0.8781821035816844, 'debris IoU': 0.7828205508090934}\n########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7857344712598203\n{'macroPrec': 0.9185506620674351, 'microPrec': 0.9906260817961525, 'weightPrec': 0.9912095611259647, 'macroRec': 0.958584205714859, 'microRec': 0.9906260817961525, 'weightRec': 0.9906260817961525, 'macroF1': 0.937567588148706, 'microF1': 0.9906260817961525, 'weightF1': 0.9908399808532226, 'subsetAcc': 0.9906260817961525, 'IoU': 0.8880134260743967, 'debris Prec': 0.8400507583539791, 'debris Rec': 0.9239665027249767, 'debris F1': 0.8800126602310493, 'debris IoU': 0.7857344712598203}\n","output_type":"stream"},{"name":"stderr","text":"epoch 51/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0369]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7931380753138075\n{'macroPrec': 0.9147288538332881, 'microPrec': 0.9908313139805153, 'weightPrec': 0.9916740921782843, 'macroRec': 0.9687541900718877, 'microRec': 0.9908313139805153, 'weightRec': 0.9908313139805153, 'macroF1': 0.9399314336628364, 'microF1': 0.9908313139805153, 'weightF1': 0.991111601170871, 'subsetAcc': 0.9908313139805153, 'IoU': 0.8918176646536209, 'debris Prec': 0.8315980346279832, 'debris Rec': 0.9449022996145154, 'debris F1': 0.8846369236512974, 'debris IoU': 0.7931380753138075}\n","output_type":"stream"},{"name":"stderr","text":"epoch 52/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.26it/s, loss=0.0371]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8931102683734833, 'microPrec': 0.9875080361999901, 'weightPrec': 0.98862565873905, 'macroRec': 0.9477960616083143, 'microRec': 0.9875080361999901, 'weightRec': 0.9875080361999901, 'macroF1': 0.9184992443415031, 'microF1': 0.9875080361999901, 'weightF1': 0.9879141469819314, 'subsetAcc': 0.9875080361999901, 'IoU': 0.8582174062578957, 'debris Prec': 0.7899164539336273, 'debris Rec': 0.9048916655589525, 'debris F1': 0.8435041199430022, 'debris IoU': 0.7293619756790057}\n","output_type":"stream"},{"name":"stderr","text":"epoch 53/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:34<00:00,  1.27it/s, loss=0.0293]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 2/10 epochs\n{'macroPrec': 0.9059629238648346, 'microPrec': 0.9898076257356214, 'weightPrec': 0.9908673202817407, 'macroRec': 0.966177939602794, 'microRec': 0.9898076257356214, 'weightRec': 0.9898076257356214, 'macroF1': 0.9337892955106084, 'microF1': 0.9898076257356214, 'weightF1': 0.9901594043206599, 'subsetAcc': 0.9898076257356214, 'IoU': 0.8819419822853256, 'debris Prec': 0.8142331147163733, 'debris Rec': 0.9406486773893393, 'debris F1': 0.8728876279758233, 'debris IoU': 0.7744459644322845}\n","output_type":"stream"},{"name":"stderr","text":"epoch 54/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.34it/s, loss=0.0196]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 3/10 epochs\n{'macroPrec': 0.9018554302057484, 'microPrec': 0.9896839918896198, 'weightPrec': 0.9909927334711923, 'macroRec': 0.9718961973052884, 'microRec': 0.9896839918896198, 'weightRec': 0.9896839918896198, 'macroF1': 0.9337917582279593, 'microF1': 0.9896839918896198, 'weightF1': 0.9900973399118552, 'subsetAcc': 0.9896839918896198, 'IoU': 0.8819322623977086, 'debris Prec': 0.8055524334045184, 'debris Rec': 0.9526784527449156, 'debris F1': 0.8729598051157126, 'debris IoU': 0.7745596022911488}\n","output_type":"stream"},{"name":"stderr","text":"epoch 55/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.14]  \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 4/10 epochs\n{'macroPrec': 0.8991192702880517, 'microPrec': 0.9896122842589388, 'weightPrec': 0.9911088773728562, 'macroRec': 0.9761398977433828, 'microRec': 0.9896122842589388, 'weightRec': 0.9896122842589388, 'macroF1': 0.9339037762908913, 'microF1': 0.9896122842589388, 'weightF1': 0.9900691659550106, 'subsetAcc': 0.9896122842589388, 'IoU': 0.8821007179787401, 'debris Prec': 0.7997346747001272, 'debris Rec': 0.961584474278878, 'debris F1': 0.8732232851495306, 'debris IoU': 0.7749745567518346}\n","output_type":"stream"},{"name":"stderr","text":"epoch 56/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:30<00:00,  1.32it/s, loss=0.0494]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.794729862192239\n{'macroPrec': 0.9269497183060338, 'microPrec': 0.9911972701646803, 'weightPrec': 0.991554181831912, 'macroRec': 0.9550791056588963, 'microRec': 0.9911972701646803, 'weightRec': 0.9911972701646803, 'macroF1': 0.9405243232037903, 'microF1': 0.9911972701646803, 'weightF1': 0.9913376309182887, 'subsetAcc': 0.9911972701646803, 'IoU': 0.8928082710767153, 'debris Prec': 0.8571517412935323, 'debris Rec': 0.9160574239000399, 'debris F1': 0.8856261646212169, 'debris IoU': 0.794729862192239}\n","output_type":"stream"},{"name":"stderr","text":"epoch 57/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:29<00:00,  1.35it/s, loss=0.152] \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.7965491198512752\n{'macroPrec': 0.9300429660762664, 'microPrec': 0.9913406854260423, 'weightPrec': 0.9916143888291024, 'macroRec': 0.9528533777753654, 'microRec': 0.9913406854260423, 'weightRec': 0.9913406854260423, 'macroF1': 0.9411264264202949, 'microF1': 0.9913406854260423, 'weightF1': 0.9914525427511347, 'subsetAcc': 0.9913406854260423, 'IoU': 0.8937929636481011, 'debris Prec': 0.8635218541378007, 'debris Rec': 0.9112720988967168, 'debris F1': 0.8867546242400726, 'debris IoU': 0.7965491198512752}\n","output_type":"stream"},{"name":"stderr","text":"epoch 58/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.129]  \n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.8922425118114765, 'microPrec': 0.988091587953118, 'weightPrec': 0.9895303948836375, 'macroRec': 0.961101667798965, 'microRec': 0.988091587953118, 'weightRec': 0.988091587953118, 'macroF1': 0.9236162429407977, 'microF1': 0.988091587953118, 'weightF1': 0.9885719081032798, 'subsetAcc': 0.988091587953118, 'IoU': 0.8660052024155709, 'debris Prec': 0.7871337150555743, 'debris Rec': 0.931942044397182, 'debris F1': 0.8534388314059647, 'debris IoU': 0.7443465336022932}\n","output_type":"stream"},{"name":"stderr","text":"epoch 59/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:28<00:00,  1.36it/s, loss=0.0671]\n","output_type":"stream"},{"name":"stdout","text":"########### Validation Set Evaluation : #############\nSaved best model with validation metric: 0.8039484194910419\n{'macroPrec': 0.9239335273631798, 'microPrec': 0.9915038821027644, 'weightPrec': 0.9920585967150416, 'macroRec': 0.965046160136762, 'microRec': 0.9915038821027644, 'weightRec': 0.9915038821027644, 'macroF1': 0.943449994131507, 'microF1': 0.9915038821027644, 'weightF1': 0.9917003234640915, 'subsetAcc': 0.9915038821027644, 'IoU': 0.8975728058052652, 'debris Prec': 0.8503319251659626, 'debris Rec': 0.9364615180114316, 'debris F1': 0.8913208502024292, 'debris IoU': 0.8039484194910419}\n","output_type":"stream"},{"name":"stderr","text":"epoch 60/60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:27<00:00,  1.36it/s, loss=0.0666]\n","output_type":"stream"},{"name":"stdout","text":"{'macroPrec': 0.8974782066761803, 'microPrec': 0.9860748550121009, 'weightPrec': 0.9884343187204635, 'macroRec': 0.9821050680592618, 'microRec': 0.9860748550121009, 'weightRec': 0.9860748550121009, 'macroF1': 0.9351294132989213, 'microF1': 0.9860748550121009, 'weightF1': 0.9867443179631256, 'subsetAcc': 0.9860748550121009, 'IoU': 0.8836523439628364, 'debris Prec': 0.7961726336603799, 'debris Rec': 0.9776835780354552, 'debris F1': 0.877641495492833, 'debris IoU': 0.7819618169848584}\n########### Validation Set Evaluation : #############\nNo improvement for 1/10 epochs\n{'macroPrec': 0.899302817487563, 'microPrec': 0.9894565056129766, 'weightPrec': 0.9908763643084209, 'macroRec': 0.9727684256069478, 'microRec': 0.9894565056129766, 'weightRec': 0.9894565056129766, 'macroF1': 0.9326342226767574, 'microF1': 0.9894565056129766, 'weightF1': 0.989900465554071, 'subsetAcc': 0.9894565056129766, 'IoU': 0.8800888843462348, 'debris Prec': 0.8003677289948741, 'debris Rec': 0.9547388010102352, 'debris F1': 0.8707643814026793, 'debris IoU': 0.771109560362875}\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"\n\n# # Save everything in a checkpoint\n# checkpoint = {\n#     'model_state_dict': model.state_dict(),\n#     'optimizer_state_dict': optimizer.state_dict(),\n#     'scheduler_state_dict': scheduler.state_dict(),\n#     'epoch': 10  # Optional: Save the epoch number\n# }\n\n# torch.save(checkpoint, 'model_checkpoint_8_epochs_bs16_iou075.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:13.094349Z","iopub.status.idle":"2025-05-27T21:18:13.094616Z","shell.execute_reply.started":"2025-05-27T21:18:13.094507Z","shell.execute_reply":"2025-05-27T21:18:13.094517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_classes = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:13.096247Z","iopub.status.idle":"2025-05-27T21:18:13.096585Z","shell.execute_reply.started":"2025-05-27T21:18:13.096431Z","shell.execute_reply":"2025-05-27T21:18:13.096447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the saved state_dict\nmodel.load_state_dict(torch.load(\"/kaggle/working/best_model.pth\", map_location=device))\nmodel = model.to(device)\n# Set the model to evaluation mode\nmodel.eval()\n\nmarida_test_df = create_marida_df(MARIDA_path, 'test')\nempty_df =  pd.DataFrame(columns=marida_test_df.columns)\nmarida_test_ds = MergedSegmentationDataset_B(marida_test_df, empty_df, global_bands_mean, global_bands_std, selected_bands, transform=transformTest, standardization= standardization )\n\nmarida_testLoader = DataLoader(marida_test_ds, \n                        batch_size=batch_size, \n                        shuffle=False,\n                        collate_fn=custom_collate_fn,\n                        #worker_init_fn=worker_init_fn,\n                        #generator=torch.Generator().manual_seed(seed) \n                        )\n\ntest_metrics_history = []\nmodel.eval()\nyTrue = []\nyPredicted = []\ntestLossF = []\nwith torch.no_grad():\n    for image, target, _ in marida_testLoader:\n\n        image, target = image.to(device), target.to(device)\n        logits = model(image)\n        # print(f'image dtype {image.dtype}')\n        # print(f'logits dtype {logits.dtype}')\n        # print(f'target dtype {target.dtype}')\n        # print(f'test - target shape {target.shape}')\n        #print(f'test - logit shape {logits.shape}')\n        loss = criterion(logits, target)\n\n        logits = torch.movedim(logits, (0,1,2,3), (0,3,1,2))\n        logits = logits.reshape((-1,output_classes))\n        target = target.reshape(-1)\n        ###################################################################################\n        mask = target != -1\n        ###################################################################################\n        \n        # bg_logits = logits[~mask]\n        # bg_target = target[~mask]\n        \n        logits = logits[mask]\n        target = target[mask]\n        \n\n        probs = F.softmax(logits, dim=1).cpu().numpy()\n        ########### threshold #########\n        probs[probs[:, 1] < 0.7] = 0.\n        ###############################\n        print(f'test - probs shape {probs.shape}')\n        target = target.cpu().numpy()\n        # testBatches += target.shape[0]\n        testLossF.append((loss.data*target.shape[0]).tolist())\n        yPredicted += probs.argmax(1).tolist()\n        yTrue += target.tolist()\n\n\n        # bg_probs = torch.nn.functional.softmax(bg_logits, dim=1).cpu().numpy()\n        # bg_target = bg_target.cpu().numpy()\n\n        # bg_yPredicted += bg_probs.argmax(1).tolist()\n        # bg_yTrue += bg_target.tolist()\n    \n    yPredicted = np.asarray(yPredicted)\n    yTrue = np.asarray(yTrue)\n    acc = Evaluation(yPredicted, yTrue)\n    test_metrics_history.append(acc)\n\n\n    # bg_yPredicted = np.asarray(bg_yPredicted)\n    # bg_yTrue = np.asarray(bg_yTrue)\n    # bg_acc = Evaluation(bg_yPredicted, bg_yTrue)\n    print(acc)\n                    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T23:58:14.356848Z","iopub.execute_input":"2025-05-27T23:58:14.357461Z","iopub.status.idle":"2025-05-27T23:58:44.980064Z","shell.execute_reply.started":"2025-05-27T23:58:14.357440Z","shell.execute_reply":"2025-05-27T23:58:44.979399Z"}},"outputs":[{"name":"stdout","text":"test - probs shape (6701, 2)\ntest - probs shape (4274, 2)\ntest - probs shape (2632, 2)\ntest - probs shape (2981, 2)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1683949948.py:4: RuntimeWarning: invalid value encountered in less\n  invalid_mask |= image < -1.5\n/tmp/ipykernel_35/1683949948.py:5: RuntimeWarning: invalid value encountered in greater\n  invalid_mask |= image > 1.5\n","output_type":"stream"},{"name":"stdout","text":"test - probs shape (2323, 2)\ntest - probs shape (11784, 2)\ntest - probs shape (12697, 2)\ntest - probs shape (3607, 2)\ntest - probs shape (3627, 2)\ntest - probs shape (1759, 2)\ntest - probs shape (680, 2)\ntest - probs shape (4146, 2)\ntest - probs shape (3081, 2)\ntest - probs shape (2428, 2)\ntest - probs shape (19717, 2)\ntest - probs shape (32025, 2)\ntest - probs shape (10837, 2)\ntest - probs shape (29673, 2)\ntest - probs shape (2746, 2)\ntest - probs shape (8051, 2)\ntest - probs shape (24429, 2)\ntest - probs shape (3605, 2)\ntest - probs shape (1060, 2)\n{'macroPrec': 0.9443095166894561, 'microPrec': 0.9974392265335132, 'weightPrec': 0.9974700122501167, 'macroRec': 0.9541214986551223, 'microRec': 0.9974392265335132, 'weightRec': 0.9974392265335132, 'macroF1': 0.949160426963765, 'microF1': 0.9974392265335132, 'weightF1': 0.9974532099239476, 'subsetAcc': 0.9974392265335132, 'IoU': 0.9074798877435679, 'debris Prec': 0.8897731794667728, 'debris Rec': 0.9096826688364524, 'debris F1': 0.899617783142225, 'debris IoU': 0.8175502742230347}\n","output_type":"stream"}],"execution_count":103},{"cell_type":"code","source":"! cp best_model.pth model_60_epochs_ratio_1_15_bs16_test_iou_debris_081_thr0.7.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:13.099322Z","iopub.status.idle":"2025-05-27T21:18:13.100025Z","shell.execute_reply.started":"2025-05-27T21:18:13.099842Z","shell.execute_reply":"2025-05-27T21:18:13.099859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# All black\n# /kaggle/input/litter-windrows-patches/patches/S2A_MSIL1C_20180916T101021_R022_T33TUL/S2A_MSIL1C_20180916T101021_R022_T33TUL_366560_5053920.tif","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:13.101090Z","iopub.status.idle":"2025-05-27T21:18:13.101356Z","shell.execute_reply.started":"2025-05-27T21:18:13.101241Z","shell.execute_reply":"2025-05-27T21:18:13.101253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lightning implementation. To be used later.\n\n# class BinaryClassificationModel(pl.LightningModule):\n#     def __init__(self, hparams):\n#         super().__init__()\n#         self.save_hyperparameters(hparams)\n\n#         # Model selection\n#         if hparams.model_name == \"resattunet\":\n#             self.model = ResidualAttentionUNet(11, 11)\n#             # Modify for binary classification\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)  # Binary output\n#             )\n#         elif hparams.model_name == \"attunet\":\n#             self.model = AttentionUNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         elif hparams.model_name == \"unet\":\n#             self.model = UNet(11, 11)\n#             self.model.decoder = nn.Sequential(\n#                 self.model.decoder,\n#                 nn.AdaptiveAvgPool2d(1),\n#                 nn.Flatten(),\n#                 nn.Linear(11, 2)\n#             )\n#         else:\n#             raise ValueError(\"Invalid model name\")\n\n#         # Loss function\n#         if hparams.focal_loss:\n#             self.criterion = FocalLoss()\n#         else:\n#             weight = gen_weights(class_distr, c=1.03)[:2]  # Binary classes\n#             self.criterion = nn.CrossEntropyLoss(weight=weight, ignore_index=-1)\n\n#         # Track best metrics\n#         self.best_macro_f1 = 0.0\n#         self.best_micro_f1 = 0.0\n#         self.best_weight_f1 = 0.0\n\n#     def forward(self, x):\n#         return self.model(x)\n\n#     def training_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n#         return loss\n\n#     def validation_step(self, batch, batch_idx):\n#         images, labels, _ = batch\n#         logits = self(images)\n#         loss = self.criterion(logits, labels)\n#         probs = torch.softmax(logits, dim=1).cpu().numpy()\n#         labels = labels.cpu().numpy()\n#         preds = probs.argmax(1)\n#         return {\"loss\": loss, \"preds\": preds.tolist(), \"labels\": labels.tolist()}\n\n#     def validation_epoch_end(self, outputs):\n#         preds = np.concatenate([o[\"preds\"] for o in outputs])\n#         labels = np.concatenate([o[\"labels\"] for o in outputs])\n#         loss = torch.stack([o[\"loss\"] for o in outputs]).mean()\n#         acc = Evaluation(preds, labels)\n\n#         self.log(\"val_loss\", loss, prog_bar=True)\n#         self.log(\"val_macro_precision\", acc[\"macroPrec\"], prog_bar=True)\n#         self.log(\"val_macro_recall\", acc[\"macroRec\"])\n#         self.log(\"val_macro_f1\", acc[\"macroF1\"])\n#         self.log(\"val_micro_precision\", acc[\"microPrec\"])\n#         self.log(\"val_micro_recall\", acc[\"microRec\"])\n#         self.log(\"val_micro_f1\", acc[\"microF1\"])\n#         self.log(\"val_weight_precision\", acc[\"weightPrec\"])\n#         self.log(\"val_weight_recall\", acc[\"weightRec\"])\n#         self.log(\"val_weight_f1\", acc[\"weightF1\"])\n#         self.log(\"val_iou\", acc[\"IoU\"])\n\n#         # Update best metrics\n#         if acc[\"macroF1\"] > self.best_macro_f1:\n#             self.best_macro_f1 = acc[\"macroF1\"]\n#         if acc[\"microF1\"] > self.best_micro_f1:\n#             self.best_micro_f1 = acc[\"microF1\"]\n#         if acc[\"weightF1\"] > self.best_weight_f1:\n#             self.best_weight_f1 = acc[\"weightF1\"]\n\n#     def configure_optimizers(self):\n#         optimizer = optim.Adam(\n#             self.parameters(),\n#             lr=self.hparams.initial_lr,\n#             weight_decay=self.hparams.decay_lr\n#         )\n#         if self.hparams.scheduler_lr == \"rop\":\n#             scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n#                 optimizer, mode=\"min\", factor=0.1, patience=10, verbose=True\n#             )\n#             return {\n#                 \"optimizer\": optimizer,\n#                 \"lr_scheduler\": scheduler,\n#                 \"monitor\": \"val_loss\"\n#             }\n#         else:\n#             scheduler = optim.lr_scheduler.MultiStepLR(\n#                 optimizer, milestones=[40, 80, 120, 160], gamma=0.5, verbose=True\n#             )\n#             return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n\n#     def train_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             RandomRotationTransform([-90, 0, 90, 180]),\n#             transforms.RandomHorizontalFlip(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.train_batch_size,\n#             shuffle=True,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n#     def val_dataloader(self):\n#         transform = transforms.Compose([\n#             transforms.ToTensor(),\n#             transforms.Normalize(bands_mean, bands_std)\n#         ])\n#         dataset = MergedSegmentationDataset(\n#             dataset1_paths=(\"path/to/dataset1/images\", \"path/to/dataset1/masks\"),\n#             dataset2_paths=(\"path/to/dataset2/images\", \"path/to/dataset2/masks\"),\n#             transform=transform\n#         )\n#         return DataLoader(\n#             dataset,\n#             batch_size=self.hparams.test_batch_size,\n#             shuffle=False,\n#             num_workers=4,\n#             worker_init_fn=seed_worker,\n#             generator=torch.Generator().manual_seed(0)\n#         )\n\n# def seed_worker(worker_id):\n#     worker_seed = torch.initial_seed() % 2**32\n#     np.random.seed(worker_seed)\n#     random.seed(worker_seed)\n\n# def main():\n#     parser = argparse.ArgumentParser()\n#     parser.add_argument('--train_batch_size', type=int, default=8)\n#     parser.add_argument('--test_batch_size', type=int, default=4)\n#     parser.add_argument('--total_epochs', type=int, default=50)\n#     parser.add_argument('--experiment_name', type=str, required=True)\n#     parser.add_argument('--initial_lr', type=float, default=1e-3)\n#     parser.add_argument('--decay_lr', type=float, default=0)\n#     parser.add_argument('--scheduler_lr', type=str, default=\"ms\")\n#     parser.add_argument('--focal_loss', type=bool, default=False)\n#     parser.add_argument('--model_name', type=str, default=\"resattunet\")\n#     args = parser.parse_args()\n\n#     # Set seeds for reproducibility\n#     pl.seed_everything(0, workers=True)\n\n#     # Initialize model\n#     model = BinaryClassificationModel(args)\n\n#     # Logger\n#     logger = TensorBoardLogger(save_dir=args.experiment_name, name=\"logs\")\n\n#     # Callbacks for saving best models\n#     checkpoint_macro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMacroF1Model\",\n#         monitor=\"val_macro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_micro = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestMicroF1Model\",\n#         monitor=\"val_micro_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n#     checkpoint_weight = ModelCheckpoint(\n#         dirpath=args.experiment_name,\n#         filename=\"bestWeightF1Model\",\n#         monitor=\"val_weight_f1\",\n#         mode=\"max\",\n#         save_top_k=1\n#     )\n\n#     # Trainer\n#     trainer = pl.Trainer(\n#         max_epochs=args.total_epochs,\n#         accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n#         devices=1,\n#         logger=logger,\n#         callbacks=[checkpoint_macro, checkpoint_micro, checkpoint_weight],\n#         deterministic=True\n#     )\n\n#     # Train\n#     trainer.fit(model)\n\n# # if __name__ == \"__main__\":\n# #     main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T21:18:13.102726Z","iopub.status.idle":"2025-05-27T21:18:13.102956Z","shell.execute_reply.started":"2025-05-27T21:18:13.102854Z","shell.execute_reply":"2025-05-27T21:18:13.102864Z"}},"outputs":[],"execution_count":null}]}